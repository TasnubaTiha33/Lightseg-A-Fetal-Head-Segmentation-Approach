{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-06T08:33:04.281920Z",
     "iopub.status.busy": "2025-04-06T08:33:04.281920Z",
     "iopub.status.idle": "2025-04-06T08:41:44.788228Z",
     "shell.execute_reply": "2025-04-06T08:41:44.788228Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import re\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ‚úÖ Constants for 224x224\n",
    "IMG_HEIGHT = 224  # Ensure height is 224\n",
    "IMG_WIDTH = 224   # Ensure width is 224\n",
    "CHANNELS = 3  # RGB images\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "# ‚úÖ Class mapping from RGB to class index\n",
    "CLASS_MAP = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0,  # Background\n",
    "}\n",
    "\n",
    "image_dir = r\"D:\\augmented_dataset\\images\"\n",
    "mask_dir = r\"D:\\augmented_dataset\\masks\"\n",
    "\n",
    "# ‚úÖ Define destination directories\n",
    "train_image_dir = r\"D:\\Updated\\train\\images\"\n",
    "train_mask_dir = r\"D:\\Updated\\train\\masks\"\n",
    "val_image_dir = r\"D:\\Updated\\val\\images\"\n",
    "val_mask_dir = r\"D:\\Updated\\val\\masks\"\n",
    "test_image_dir = r\"D:\\Updated\\test\\images\"\n",
    "test_mask_dir = r\"D:\\Updated\\test\\masks\"\n",
    "\n",
    "# ‚úÖ Fix sorting issue using natural sorting\n",
    "def natural_sort_key(s):\n",
    "    \"\"\"Sort filenames numerically instead of lexicographically.\"\"\"\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "# ‚úÖ Convert RGB mask to class index mask\n",
    "def rgb_to_class(mask_array):\n",
    "    \"\"\"Convert RGB mask to single-channel class index mask.\"\"\"\n",
    "    height, width, _ = mask_array.shape\n",
    "    class_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    for rgb, class_idx in CLASS_MAP.items():\n",
    "        matches = np.all(mask_array == rgb, axis=-1)  # Ensure exact match\n",
    "        class_mask[matches] = class_idx\n",
    "\n",
    "    return class_mask\n",
    "\n",
    "# ‚úÖ Preprocess Filtered Dataset for 224x224\n",
    "def preprocess_filtered_dataset(image_dir, mask_dir):\n",
    "    \"\"\"Preprocess images & masks: normalize, resize, and convert masks to one-hot encoding.\"\"\"\n",
    "\n",
    "    # ‚úÖ Load and sort filenames correctly\n",
    "    image_filenames = sorted(os.listdir(image_dir), key=natural_sort_key)\n",
    "    mask_filenames = sorted(os.listdir(mask_dir), key=natural_sort_key)\n",
    "\n",
    "    valid_image_paths = []\n",
    "    valid_mask_paths = []\n",
    "\n",
    "    # ‚úÖ Ensure each image has a corresponding mask\n",
    "    for img_file, mask_file in zip(image_filenames, mask_filenames):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "        if os.path.exists(img_path) and os.path.exists(mask_path):\n",
    "            valid_image_paths.append(img_path)\n",
    "            valid_mask_paths.append(mask_path)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Skipping {img_file}: Missing image or mask\")\n",
    "\n",
    "    num_images = len(valid_image_paths)\n",
    "\n",
    "    # ‚úÖ Initialize arrays\n",
    "    X = np.zeros((num_images, IMG_HEIGHT, IMG_WIDTH, CHANNELS), dtype=np.float32)\n",
    "    y = np.zeros((num_images, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES), dtype=np.float32)  # One-hot encoded masks\n",
    "\n",
    "    print(f\"üöÄ Processing {num_images} filtered images and masks...\")\n",
    "\n",
    "    for idx, (img_path, mask_path) in enumerate(zip(valid_image_paths, valid_mask_paths)):\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"‚úÖ Processed {idx}/{num_images} images\")\n",
    "\n",
    "        # ‚úÖ Load and Resize Image\n",
    "        img = cv2.imread(img_path)  # Read image in BGR format\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))  # Resize to (224,224)\n",
    "        img = img.astype(np.float32) / 255.0  # Normalize\n",
    "\n",
    "        # ‚úÖ Load and Resize Mask\n",
    "        mask = cv2.imread(mask_path)  # Read mask in BGR format\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)  # Resize mask correctly\n",
    "\n",
    "        # ‚úÖ Convert RGB mask to class mask\n",
    "        class_mask = rgb_to_class(mask)\n",
    "\n",
    "        # ‚úÖ One-hot encode the class mask\n",
    "        one_hot_mask = to_categorical(class_mask, num_classes=NUM_CLASSES)\n",
    "\n",
    "        # ‚úÖ Store preprocessed data\n",
    "        X[idx] = img\n",
    "        y[idx] = one_hot_mask\n",
    "\n",
    "        # ‚úÖ Clear memory to prevent memory leaks\n",
    "        del img, mask, class_mask, one_hot_mask\n",
    "        gc.collect()\n",
    "\n",
    "    return X, y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ‚úÖ Process dataset splits\n",
    "X_train, y_train = preprocess_filtered_dataset(train_image_dir, train_mask_dir)\n",
    "X_val, y_val = preprocess_filtered_dataset(val_image_dir, val_mask_dir)\n",
    "X_test, y_test = preprocess_filtered_dataset(test_image_dir, test_mask_dir)\n",
    "\n",
    "# ‚úÖ Print dataset information\n",
    "print(\"\\n‚úÖ Dataset Splits:\")\n",
    "print(f\"  - Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"  - Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"  - Test set: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T08:41:44.790228Z",
     "iopub.status.busy": "2025-04-06T08:41:44.790228Z",
     "iopub.status.idle": "2025-04-06T08:41:45.246616Z",
     "shell.execute_reply": "2025-04-06T08:41:45.246616Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data Augmentation configuration for the training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "# Fit the augmentation parameters on the training data\n",
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T08:41:45.249617Z",
     "iopub.status.busy": "2025-04-06T08:41:45.248617Z",
     "iopub.status.idle": "2025-04-06T08:41:50.639579Z",
     "shell.execute_reply": "2025-04-06T08:41:50.639579Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Unique values in y_train:\", np.unique(np.argmax(y_train, axis=-1)))\n",
    "print(\"Unique values in y_val:\", np.unique(np.argmax(y_val, axis=-1)))\n",
    "print(\"Unique values in y_test:\", np.unique(np.argmax(y_test, axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T08:41:50.641580Z",
     "iopub.status.busy": "2025-04-06T08:41:50.641580Z",
     "iopub.status.idle": "2025-04-06T08:41:53.028195Z",
     "shell.execute_reply": "2025-04-06T08:41:53.028195Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2DTranspose, Conv2D, Concatenate, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Multiply, Layer, Resizing\n",
    "from tensorflow.keras.layers import Dropout, Add\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "\n",
    "# Custom resize layer to replace tf.image.resize\n",
    "class ResizeLayer(Layer):\n",
    "    def __init__(self, target_size, **kwargs):\n",
    "        super(ResizeLayer, self).__init__(**kwargs)\n",
    "        self.target_size = target_size\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.image.resize(inputs, self.target_size)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.target_size[0], self.target_size[1], input_shape[3])\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(ResizeLayer, self).get_config()\n",
    "        config.update({'target_size': self.target_size})\n",
    "        return config\n",
    "\n",
    "# Constants for image size and classes\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "def find_best_skip_layers(base_model, target_sizes):\n",
    "    \"\"\"Finds the best matching layers for skip connections based on spatial size & channels.\"\"\"\n",
    "    layer_dict = {layer.name: layer.output.shape for layer in base_model.layers}\n",
    "    skip_connections = []\n",
    "    for target_size in target_sizes:\n",
    "        best_match = None\n",
    "        min_diff = float('inf')\n",
    "        for layer_name, shape in layer_dict.items():\n",
    "            if len(shape) == 4:  # Ensure it's a conv layer\n",
    "                h, w, c = shape[1], shape[2], shape[3]  # Extract spatial dims & channels\n",
    "                # Calculate difference, weighting spatial dimensions more than channels\n",
    "                diff = abs(h - target_size[0]) + abs(w - target_size[1]) + (abs(c - target_size[2]) * 0.1)\n",
    "                if diff < min_diff:\n",
    "                    min_diff = diff\n",
    "                    best_match = layer_name\n",
    "        skip_connections.append(best_match)\n",
    "    return skip_connections\n",
    "\n",
    "def convolution_block(inputs, filters, kernel_size=3, strides=1, padding='same'):\n",
    "    \"\"\"Standard convolution block with batch normalization and ReLU activation\"\"\"\n",
    "    x = Conv2D(filters, kernel_size, strides=strides, padding=padding)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def dilated_conv_block(inputs, filters, kernel_size=3, dilation_rate=2):\n",
    "    \"\"\"Dilated convolution block to increase receptive field\"\"\"\n",
    "    x = Conv2D(filters, kernel_size, padding='same', dilation_rate=dilation_rate)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def attention_gate(x, g, inter_channels):\n",
    "    \"\"\"\n",
    "    Attention Gate with optimal parameters for ~10M model\n",
    "    x: Skip connection input (from encoder)\n",
    "    g: Gating signal (from previous decoder layer)\n",
    "    inter_channels: Number of intermediate channels\n",
    "    \"\"\"\n",
    "    # Get shape information\n",
    "    x_shape = tf.keras.backend.int_shape(x)\n",
    "    g_shape = tf.keras.backend.int_shape(g)\n",
    "    \n",
    "    # Reshape g to match x's spatial dimensions if needed\n",
    "    if x_shape[1] != g_shape[1] or x_shape[2] != g_shape[2]:\n",
    "        g = Resizing(x_shape[1], x_shape[2])(g)\n",
    "    \n",
    "    # Feature extraction\n",
    "    theta_x = Conv2D(inter_channels, kernel_size=1, padding='same')(x)\n",
    "    phi_g = Conv2D(inter_channels, kernel_size=1, padding='same')(g)\n",
    "    \n",
    "    # Combine x and g\n",
    "    f = Activation('relu')(Add()([theta_x, phi_g]))\n",
    "    \n",
    "    # Attention coefficients\n",
    "    psi_f = Conv2D(1, kernel_size=1, padding='same')(f)\n",
    "    attention_coefficients = Activation('sigmoid')(psi_f)\n",
    "    \n",
    "    # Apply attention\n",
    "    attended_features = Multiply()([x, attention_coefficients])\n",
    "    \n",
    "    return attended_features\n",
    "\n",
    "def build_optimized_attention_unet(input_shape=(224, 224, 3), num_classes=4):\n",
    "    \"\"\"Build optimized Attention U-Net with MobileNetV3Large backbone (~10M parameters)\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # MobileNetV3Large backbone\n",
    "    base_model = MobileNetV3Large(\n",
    "        input_tensor=inputs,\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        alpha=1.0  # Full size model (~5.4M parameters)\n",
    "    )\n",
    "    \n",
    "    # Don't freeze any layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    # Expected target sizes for MobileNetV3Large\n",
    "    target_skip_sizes = [\n",
    "        (112, 112, 16),  # Early layer\n",
    "        (56, 56, 24),    # Mid layer\n",
    "        (28, 28, 40),    # Mid layer\n",
    "        (14, 14, 112)    # Deep layer\n",
    "    ]\n",
    "    \n",
    "    # Find the best matching layers\n",
    "    skip_layers = find_best_skip_layers(base_model, target_skip_sizes)\n",
    "    print(\"Selected skip layers:\", skip_layers)\n",
    "    \n",
    "    # Get skip connections\n",
    "    skip_connections = [base_model.get_layer(name).output for name in skip_layers]\n",
    "    \n",
    "    # Enhanced Bottleneck with dilated convolutions (adds ~0.5M parameters)\n",
    "    bottleneck = base_model.output\n",
    "    b1 = dilated_conv_block(bottleneck, 192, dilation_rate=1)\n",
    "    b2 = dilated_conv_block(bottleneck, 192, dilation_rate=6)\n",
    "    bottleneck = Concatenate()([b1, b2])\n",
    "    bottleneck = convolution_block(bottleneck, 384, kernel_size=1)\n",
    "    \n",
    "    # Decoder with attention gates - optimized filter counts for ~10M total\n",
    "    # ~4M parameters in the decoder\n",
    "    up_filters = [384, 192, 96, 48]\n",
    "    \n",
    "    up = bottleneck\n",
    "    for i in range(4):\n",
    "        # Upsampling block\n",
    "        up = Conv2DTranspose(up_filters[i], (3, 3), strides=(2, 2), padding=\"same\")(up)\n",
    "        up = BatchNormalization()(up)\n",
    "        up = Activation('relu')(up)\n",
    "        \n",
    "        # Get skip connection\n",
    "        skip = skip_connections[i]\n",
    "        \n",
    "        # Apply attention gate\n",
    "        att_skip = attention_gate(skip, up, up_filters[i] // 4)\n",
    "        \n",
    "        # Ensure dimensions match for concatenation\n",
    "        skip_shape = tf.keras.backend.int_shape(att_skip)\n",
    "        up_shape = tf.keras.backend.int_shape(up)\n",
    "        \n",
    "        if up_shape[1] != skip_shape[1] or up_shape[2] != skip_shape[2]:\n",
    "            up = Resizing(skip_shape[1], skip_shape[2])(up)\n",
    "        \n",
    "        # Concatenate with attention-weighted skip connection\n",
    "        up = Concatenate()([up, att_skip])\n",
    "        \n",
    "        # Convolution blocks - two per level for better feature extraction\n",
    "        up = convolution_block(up, up_filters[i])\n",
    "        up = convolution_block(up, up_filters[i])\n",
    "    \n",
    "    # Final upsampling to match input size\n",
    "    up = Conv2DTranspose(48, (3, 3), strides=(2, 2), padding=\"same\")(up)\n",
    "    up = BatchNormalization()(up)\n",
    "    up = Activation('relu')(up)\n",
    "    \n",
    "    # Final processing\n",
    "    up = convolution_block(up, 32, kernel_size=3)\n",
    "    \n",
    "    # Ensure exact output size\n",
    "    up_shape = tf.keras.backend.int_shape(up)\n",
    "    if up_shape[1] != input_shape[0] or up_shape[2] != input_shape[1]:\n",
    "        up = Resizing(input_shape[0], input_shape[1])(up)\n",
    "    \n",
    "    # Final layer\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(up)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build and summarize model\n",
    "model = build_optimized_attention_unet(\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), \n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T08:41:53.141221Z",
     "iopub.status.busy": "2025-04-06T08:41:53.141221Z",
     "iopub.status.idle": "2025-04-06T10:10:10.109263Z",
     "shell.execute_reply": "2025-04-06T10:10:10.109263Z"
    }
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# # ‚úÖ Dice Coefficient Metric\n",
    "# def dice_coefficient(y_true, y_pred):\n",
    "#     smooth = 1e-15\n",
    "#     y_true = tf.cast(y_true, tf.float32)\n",
    "#     y_pred = tf.cast(y_pred, tf.float32)\n",
    "#     intersection = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "#     union = tf.reduce_sum(y_true, axis=[1,2,3]) + tf.reduce_sum(y_pred, axis=[1,2,3])\n",
    "#     dice = (2. * intersection + smooth) / (union + smooth)\n",
    "#     return tf.reduce_mean(dice)\n",
    "\n",
    "# def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "#     class_weights = tf.constant([0.3794, 0.7521, 69.7061, 49.3458], dtype=tf.float32)\n",
    "\n",
    "#     # Ensure y_true has the same shape as y_pred\n",
    "#     y_true = tf.cast(y_true, tf.float32)  # Make sure it's float32 for numerical stability\n",
    "#     y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)  # Avoid log(0)\n",
    "\n",
    "#     # Compute categorical cross-entropy\n",
    "#     loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)  # Sum over the last axis (class axis)\n",
    "\n",
    "#     # Reshape the class weights to match the loss shape\n",
    "#     class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))  # [1, 1, 1, 4]\n",
    "\n",
    "#     # Apply the class weights\n",
    "#     weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)  # Broadcast weights over the batch and spatial dimensions\n",
    "\n",
    " #     return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# # ‚úÖ Dice Loss\n",
    "# def dice_loss(y_true, y_pred):\n",
    "#     smooth = 1e-6\n",
    "#     y_true = tf.cast(y_true, y_pred.dtype)\n",
    "#     intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "#     union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "#     dice = (2. * intersection + smooth) / (union + smooth)\n",
    "#     return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# # ‚úÖ Combined Loss Function\n",
    "# def combined_loss(y_true, y_pred):\n",
    "#     return weighted_categorical_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "# # ‚úÖ Custom Dice Coefficient Metric for Each Class\n",
    "# class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "#     def __init__(self, class_idx, name=None, **kwargs):  \n",
    "#         if name is None:\n",
    "#             name = f\"DiceClass{class_idx}\"  \n",
    "#         super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "#         self.class_idx = class_idx\n",
    "#         self.dice = self.add_weight(name=\"dice\", initializer=\"zeros\")\n",
    "\n",
    "#     def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "#         y_true_class = y_true[..., self.class_idx]\n",
    "#         y_pred_class = y_pred[..., self.class_idx]\n",
    "\n",
    "#         intersection = tf.reduce_sum(y_true_class * y_pred_class, axis=[1, 2])\n",
    "#         union = tf.reduce_sum(y_true_class, axis=[1, 2]) + tf.reduce_sum(y_pred_class, axis=[1, 2])\n",
    "\n",
    "#         dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "#         self.dice.assign(tf.reduce_mean(dice))\n",
    "\n",
    "#     def result(self):\n",
    "#         return self.dice\n",
    "\n",
    "# # ‚úÖ Function to Get Class-wise Metrics\n",
    "# def class_wise_metrics(num_classes=4):\n",
    "#     return [DiceCoefficient(i) for i in range(num_classes)] + [tf.keras.metrics.MeanIoU(num_classes=num_classes)]\n",
    "\n",
    "# # ‚úÖ Compile the Model\n",
    "# model.compile(\n",
    "#     optimizer=Adam(learning_rate=1e-4),\n",
    "#     loss=combined_loss,\n",
    "#     metrics=class_wise_metrics(4)  # Number of classes (adjust if needed)\n",
    "# )\n",
    "\n",
    "# # ‚úÖ Train the Model with the **Filtered Dataset**\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,  # Use the loaded and split data\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     epochs=50,\n",
    "#     batch_size=16,  # Adjust based on available resources\n",
    "#     callbacks=[\n",
    "#         EarlyStopping(\n",
    "#             monitor='val_loss', \n",
    "#             patience=7, \n",
    "#             restore_best_weights=True\n",
    "#         ),\n",
    "#         ReduceLROnPlateau(\n",
    "#             monitor='val_loss', \n",
    "#             factor=0.5, \n",
    "#             patience=3, \n",
    "#             min_lr=1e-6\n",
    "#         ),\n",
    "#         ModelCheckpoint(\n",
    "#             '/kaggle/working/best_unet_model_filtered.keras',  # Save in Kaggle working directory with .keras extension\n",
    "#             monitor='val_loss',\n",
    "#             save_best_only=True\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ‚úÖ Dice Coefficient Metric\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1,2,3]) + tf.reduce_sum(y_pred, axis=[1,2,3])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Weighted Categorical Crossentropy\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    class_weights = tf.constant([0.3776, 0.7605, 65.8554, 46.2381], dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "    class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))\n",
    "    weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)\n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# ‚úÖ Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Custom Dice Coefficient Metric for Each Class\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_idx, name=None, **kwargs):  \n",
    "        if name is None:\n",
    "            name = f\"DiceClass{class_idx}\"  \n",
    "        super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        self.class_idx = class_idx\n",
    "        self.dice = self.add_weight(name=\"dice\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_class = y_true[..., self.class_idx]\n",
    "        y_pred_class = y_pred[..., self.class_idx]\n",
    "        intersection = tf.reduce_sum(y_true_class * y_pred_class, axis=[1, 2])\n",
    "        union = tf.reduce_sum(y_true_class, axis=[1, 2]) + tf.reduce_sum(y_pred_class, axis=[1, 2])\n",
    "        dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "        self.dice.assign(tf.reduce_mean(dice))\n",
    "\n",
    "    def result(self):\n",
    "        return self.dice\n",
    "\n",
    "# ‚úÖ Function to Get Class-wise Metrics\n",
    "def class_wise_metrics(num_classes=4):\n",
    "    return [DiceCoefficient(i) for i in range(num_classes)] + [tf.keras.metrics.MeanIoU(num_classes=num_classes)]\n",
    "\n",
    "# ‚úÖ Create Data Generator\n",
    "def create_train_generator(X, y, batch_size=16):\n",
    "    data_gen_args = dict(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    \n",
    "    seed = 42\n",
    "    image_generator = image_datagen.flow(X, batch_size=batch_size, seed=seed)\n",
    "    mask_generator = mask_datagen.flow(y, batch_size=batch_size, seed=seed)\n",
    "    \n",
    "    while True:\n",
    "        X_batch = next(image_generator)\n",
    "        y_batch = next(mask_generator)\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "# ‚úÖ Create the generator\n",
    "train_generator = create_train_generator(X_train, y_train, batch_size=8)\n",
    "\n",
    "# ‚úÖ Compile the Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def lovasz_softmax_loss(y_true, y_pred, ignore_background=False):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    num_classes = tf.shape(y_true)[-1]\n",
    "    start_class = tf.constant(1 if ignore_background else 0)\n",
    "\n",
    "    def compute_class_loss(c):\n",
    "        y_true_class = y_true[..., c]\n",
    "        y_pred_class = y_pred[..., c]\n",
    "\n",
    "        y_true_flat = tf.reshape(y_true_class, [-1])\n",
    "        y_pred_flat = tf.reshape(y_pred_class, [-1])\n",
    "\n",
    "        errors = tf.abs(y_true_flat - y_pred_flat)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], sorted=True)\n",
    "        y_true_sorted = tf.gather(y_true_flat, perm)\n",
    "\n",
    "        gts = tf.reduce_sum(y_true_sorted)\n",
    "        intersection = gts - tf.cumsum(y_true_sorted)\n",
    "        union = gts + tf.cumsum(1. - y_true_sorted)\n",
    "        jaccard = 1. - intersection / union\n",
    "        grad = tf.concat([[jaccard[0]], jaccard[1:] - jaccard[:-1]], 0)\n",
    "\n",
    "        return tf.tensordot(errors_sorted, grad, axes=1)\n",
    "\n",
    "    # Loop through each class using tf.while_loop\n",
    "    losses = tf.TensorArray(dtype=tf.float32, size=num_classes)\n",
    "\n",
    "    def loop_cond(c, losses):\n",
    "        return tf.less(c, num_classes)\n",
    "\n",
    "    def loop_body(c, losses):\n",
    "        loss_c = compute_class_loss(c)\n",
    "        losses = losses.write(c, loss_c)\n",
    "        return c + 1, losses\n",
    "\n",
    "    _, losses = tf.while_loop(loop_cond, loop_body, [start_class, losses])\n",
    "    return tf.reduce_mean(losses.stack())\n",
    "\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss_val = 1 - tf.reduce_mean(dice)\n",
    "\n",
    "    lovasz_loss_val = lovasz_softmax_loss(y_true, tf.nn.softmax(y_pred), ignore_background=False)\n",
    "\n",
    "    return lovasz_loss_val + dice_loss_val\n",
    "\n",
    "\n",
    "# Usage in model compilation\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(4)  # Number of classes\n",
    ")\n",
    "\n",
    "# ‚úÖ Train the Model with the Data Generator\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(X_train) // 16,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=10, \n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss', \n",
    "            factor=0.5, \n",
    "            patience=3, \n",
    "            min_lr=1e-6\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            'lovaszloss_attentionunet-mobilenetv3.keras',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T10:10:10.111263Z",
     "iopub.status.busy": "2025-04-06T10:10:10.111263Z",
     "iopub.status.idle": "2025-04-06T10:10:10.490136Z",
     "shell.execute_reply": "2025-04-06T10:10:10.490136Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extracting data from the history object\n",
    "history_dict = history.history\n",
    "\n",
    "# Plotting the training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plotting loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_dict['loss'], label='Training Loss')\n",
    "plt.plot(history_dict['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# If accuracy is available, plot training and validation accuracy\n",
    "if 'accuracy' in history_dict:\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_dict['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history_dict['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Curves')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T10:10:10.492137Z",
     "iopub.status.busy": "2025-04-06T10:10:10.492137Z",
     "iopub.status.idle": "2025-04-06T10:10:10.506140Z",
     "shell.execute_reply": "2025-04-06T10:10:10.506140Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y_test.shape)  # Should be (num_samples, 128, 128, 3)\n",
    "print(X_test.shape)  # Should be (num_samples, 128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T10:10:10.508140Z",
     "iopub.status.busy": "2025-04-06T10:10:10.508140Z",
     "iopub.status.idle": "2025-04-06T10:11:17.439151Z",
     "shell.execute_reply": "2025-04-06T10:11:17.439151Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ‚úÖ RGB to Class Index Conversion (for the test masks)\n",
    "RGB_TO_CLASS = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0     # Background\n",
    "}\n",
    "\n",
    "# ‚úÖ Function to convert RGB masks to class index masks\n",
    "def rgb_to_class_mask(rgb_mask):\n",
    "    # Create a mask initialized with zeros (for background class)\n",
    "    class_mask = np.zeros(rgb_mask.shape[:2], dtype=int)\n",
    "\n",
    "    # Loop through the RGB_TO_CLASS dictionary\n",
    "    for rgb, class_idx in RGB_TO_CLASS.items():\n",
    "        # Identify the pixels with the current RGB value and assign them the class index\n",
    "        match_mask = np.all(rgb_mask == np.array(rgb), axis=-1)\n",
    "        class_mask[match_mask] = class_idx\n",
    "\n",
    "    return class_mask\n",
    "\n",
    "# ‚úÖ Function to calculate Dice Similarity Coefficient (DSC)\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# ‚úÖ Function to calculate IoU (Intersection over Union)\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-15)\n",
    "\n",
    "# ‚úÖ Function to calculate Hausdorff Distance\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')  # Return inf if no points for either true or pred class\n",
    "\n",
    "    forward_hausdorff = directed_hausdorff(true_points, pred_points)[0]\n",
    "    reverse_hausdorff = directed_hausdorff(pred_points, true_points)[0]\n",
    "    return max(forward_hausdorff, reverse_hausdorff)\n",
    "\n",
    "# ‚úÖ Function to calculate Average Surface Distance (ASD)\n",
    "def average_surface_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')  # Return inf if no points for either true or pred class\n",
    "\n",
    "    distances = []\n",
    "    for true_point in true_points:\n",
    "        distances.append(np.min(np.linalg.norm(pred_points - true_point, axis=1)))\n",
    "    return np.mean(distances)\n",
    "\n",
    "# ‚úÖ Function to evaluate the model on the test set class-wise\n",
    "def evaluate_classwise_metrics(model, X_test, y_test, num_classes=4, batch_size=16):\n",
    "    # Predict in batches\n",
    "    y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)  # Convert to class index prediction\n",
    "\n",
    "    # Convert y_test to class index format (since it's one-hot encoded)\n",
    "    y_test_class = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    # Initialize lists to store class-wise metrics\n",
    "    class_metrics = {i: {'dice': [], 'iou': [], 'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'hausdorff': [], 'asd': []} for i in range(num_classes)}\n",
    "\n",
    "    # Calculate metrics for each test sample\n",
    "    for i in range(len(X_test)):\n",
    "        true_mask = y_test_class[i]  # one-hot -> class index\n",
    "        pred_mask = y_pred[i]\n",
    "\n",
    "        # For each class (0: Background, 1: Brain, 2: CSP, 3: LV)\n",
    "        for class_idx in range(num_classes):\n",
    "            true_class_mask = (true_mask == class_idx).astype(int)\n",
    "            pred_class_mask = (pred_mask == class_idx).astype(int)\n",
    "\n",
    "            # Dice Coefficient\n",
    "            class_metrics[class_idx]['dice'].append(dice_coefficient(true_class_mask, pred_class_mask))\n",
    "            # IoU\n",
    "            class_metrics[class_idx]['iou'].append(iou(true_class_mask, pred_class_mask))\n",
    "            # Precision\n",
    "            class_metrics[class_idx]['precision'].append(precision_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # Recall\n",
    "            class_metrics[class_idx]['recall'].append(recall_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # F1 Score\n",
    "            class_metrics[class_idx]['f1'].append(f1_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # Accuracy\n",
    "            class_metrics[class_idx]['accuracy'].append(accuracy_score(true_class_mask.flatten(), pred_class_mask.flatten()))\n",
    "            # # Hausdorff Distance\n",
    "            # class_metrics[class_idx]['hausdorff'].append(hausdorff_distance(true_class_mask, pred_class_mask))\n",
    "            # # Average Surface Distance\n",
    "            # class_metrics[class_idx]['asd'].append(average_surface_distance(true_class_mask, pred_class_mask))\n",
    "\n",
    "    # Print class-wise metrics in percentage\n",
    "    print(f\"{'Class':<10}{'Dice Coefficient (%)':<20}{'IoU (%)':<20}{'Precision (%)':<20}{'Recall (%)':<20}{'F1 Score (%)':<20}{'Accuracy (%)':<20}{'Hausdorff Distance':<20}{'Avg Surface Distance':<20}\")\n",
    "    print('-' * 180)\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        print(f\"Class {class_idx}:\")\n",
    "        print(f\"  Dice Coefficient: {np.mean(class_metrics[class_idx]['dice']) * 100:.2f}%\")\n",
    "        print(f\"  IoU: {np.mean(class_metrics[class_idx]['iou']) * 100:.2f}%\")\n",
    "        print(f\"  Precision: {np.mean(class_metrics[class_idx]['precision']) * 100:.2f}%\")\n",
    "        print(f\"  Recall: {np.mean(class_metrics[class_idx]['recall']) * 100:.2f}%\")\n",
    "        print(f\"  F1 Score: {np.mean(class_metrics[class_idx]['f1']) * 100:.2f}%\")\n",
    "        print(f\"  Accuracy: {np.mean(class_metrics[class_idx]['accuracy']) * 100:.2f}%\")\n",
    "        # print(f\"  Hausdorff Distance: {np.mean(class_metrics[class_idx]['hausdorff']):.4f}\")\n",
    "        # print(f\"  Average Surface Distance: {np.mean(class_metrics[class_idx]['asd']):.4f}\")\n",
    "        print(\"-\" * 180)\n",
    "\n",
    "    # Evaluate on test set to print overall test accuracy and loss\n",
    "    test_loss, *test_metrics = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    for metric, value in zip(model.metrics_names[1:], test_metrics):\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# ‚úÖ Call the evaluation function on the test set class-wise\n",
    "evaluate_classwise_metrics(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6984035,
     "sourceId": 11187746,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
