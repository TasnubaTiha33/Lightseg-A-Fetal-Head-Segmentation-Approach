{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import re\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ‚úÖ Constants for 224x224\n",
    "IMG_HEIGHT = 224  # Ensure height is 224\n",
    "IMG_WIDTH = 224   # Ensure width is 224\n",
    "CHANNELS = 3  # RGB images\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "# ‚úÖ Class mapping from RGB to class index\n",
    "CLASS_MAP = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0,  # Background\n",
    "}\n",
    "\n",
    "image_dir = r\"D:\\augmented_dataset\\images\"\n",
    "mask_dir = r\"D:\\augmented_dataset\\masks\"\n",
    "\n",
    "# ‚úÖ Define destination directories\n",
    "train_image_dir = r\"D:\\Updated\\train\\images\"\n",
    "train_mask_dir = r\"D:\\Updated\\train\\masks\"\n",
    "val_image_dir = r\"D:\\Updated\\val\\images\"\n",
    "val_mask_dir = r\"D:\\Updated\\val\\masks\"\n",
    "test_image_dir = r\"D:\\Updated\\test\\images\"\n",
    "test_mask_dir = r\"D:\\Updated\\test\\masks\"\n",
    "\n",
    "# ‚úÖ Fix sorting issue using natural sorting\n",
    "def natural_sort_key(s):\n",
    "    \"\"\"Sort filenames numerically instead of lexicographically.\"\"\"\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "# ‚úÖ Convert RGB mask to class index mask\n",
    "def rgb_to_class(mask_array):\n",
    "    \"\"\"Convert RGB mask to single-channel class index mask.\"\"\"\n",
    "    height, width, _ = mask_array.shape\n",
    "    class_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    for rgb, class_idx in CLASS_MAP.items():\n",
    "        matches = np.all(mask_array == rgb, axis=-1)  # Ensure exact match\n",
    "        class_mask[matches] = class_idx\n",
    "\n",
    "    return class_mask\n",
    "\n",
    "# ‚úÖ Preprocess Filtered Dataset for 224x224\n",
    "def preprocess_filtered_dataset(image_dir, mask_dir):\n",
    "    \"\"\"Preprocess images & masks: normalize, resize, and convert masks to one-hot encoding.\"\"\"\n",
    "\n",
    "    # ‚úÖ Load and sort filenames correctly\n",
    "    image_filenames = sorted(os.listdir(image_dir), key=natural_sort_key)\n",
    "    mask_filenames = sorted(os.listdir(mask_dir), key=natural_sort_key)\n",
    "\n",
    "    valid_image_paths = []\n",
    "    valid_mask_paths = []\n",
    "\n",
    "    # ‚úÖ Ensure each image has a corresponding mask\n",
    "    for img_file, mask_file in zip(image_filenames, mask_filenames):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "        if os.path.exists(img_path) and os.path.exists(mask_path):\n",
    "            valid_image_paths.append(img_path)\n",
    "            valid_mask_paths.append(mask_path)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Skipping {img_file}: Missing image or mask\")\n",
    "\n",
    "    num_images = len(valid_image_paths)\n",
    "\n",
    "    # ‚úÖ Initialize arrays\n",
    "    X = np.zeros((num_images, IMG_HEIGHT, IMG_WIDTH, CHANNELS), dtype=np.float32)\n",
    "    y = np.zeros((num_images, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES), dtype=np.float32)  # One-hot encoded masks\n",
    "\n",
    "    print(f\"üöÄ Processing {num_images} filtered images and masks...\")\n",
    "\n",
    "    for idx, (img_path, mask_path) in enumerate(zip(valid_image_paths, valid_mask_paths)):\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"‚úÖ Processed {idx}/{num_images} images\")\n",
    "\n",
    "        # ‚úÖ Load and Resize Image\n",
    "        img = cv2.imread(img_path)  # Read image in BGR format\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))  # Resize to (224,224)\n",
    "        img = img.astype(np.float32) / 255.0  # Normalize\n",
    "\n",
    "        # ‚úÖ Load and Resize Mask\n",
    "        mask = cv2.imread(mask_path)  # Read mask in BGR format\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)  # Resize mask correctly\n",
    "\n",
    "        # ‚úÖ Convert RGB mask to class mask\n",
    "        class_mask = rgb_to_class(mask)\n",
    "\n",
    "        # ‚úÖ One-hot encode the class mask\n",
    "        one_hot_mask = to_categorical(class_mask, num_classes=NUM_CLASSES)\n",
    "\n",
    "        # ‚úÖ Store preprocessed data\n",
    "        X[idx] = img\n",
    "        y[idx] = one_hot_mask\n",
    "\n",
    "        # ‚úÖ Clear memory to prevent memory leaks\n",
    "        del img, mask, class_mask, one_hot_mask\n",
    "        gc.collect()\n",
    "\n",
    "    return X, y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ‚úÖ Process dataset splits\n",
    "X_train, y_train = preprocess_filtered_dataset(train_image_dir, train_mask_dir)\n",
    "X_val, y_val = preprocess_filtered_dataset(val_image_dir, val_mask_dir)\n",
    "X_test, y_test = preprocess_filtered_dataset(test_image_dir, test_mask_dir)\n",
    "\n",
    "# ‚úÖ Print dataset information\n",
    "print(\"\\n‚úÖ Dataset Splits:\")\n",
    "print(f\"  - Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"  - Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"  - Test set: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data Augmentation configuration for the training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "# Fit the augmentation parameters on the training data\n",
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique values in y_train:\", np.unique(np.argmax(y_train, axis=-1)))\n",
    "print(\"Unique values in y_val:\", np.unique(np.argmax(y_val, axis=-1)))\n",
    "print(\"Unique values in y_test:\", np.unique(np.argmax(y_test, axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Dense\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Concatenate, Dropout\n",
    "\n",
    "# Constants for 224x224 images\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "# =========================================================================\n",
    "# Helper functions for purely functional approach (no custom layer classes)\n",
    "# =========================================================================\n",
    "\n",
    "def convolution_block(inputs, filters, kernel_size=3, strides=1, padding='same', use_bias=False, dilation_rate=1):\n",
    "    \"\"\"Standard convolution block with batch normalization and activation\"\"\"\n",
    "    x = Conv2D(\n",
    "        filters, \n",
    "        kernel_size, \n",
    "        strides=strides,\n",
    "        padding=padding,\n",
    "        use_bias=use_bias,\n",
    "        dilation_rate=dilation_rate\n",
    "    )(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('gelu')(x)\n",
    "    return x\n",
    "\n",
    "def mlp_block(inputs, hidden_dim, dropout_rate=0.0):\n",
    "    \"\"\"MLP block for transformer\"\"\"\n",
    "    x = Dense(hidden_dim, activation='gelu')(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "def window_attention_block(inputs, num_heads):\n",
    "    \"\"\"Simplified window attention using standard Keras MultiHeadAttention\"\"\"\n",
    "    # Extract input dimensions\n",
    "    input_shape = tf.keras.backend.int_shape(inputs)\n",
    "    B, H, W, C = input_shape[0], input_shape[1], input_shape[2], input_shape[3]\n",
    "    \n",
    "    # Reshape to sequence for attention\n",
    "    x_flat = Reshape((-1, C))(inputs)  # [B, H*W, C]\n",
    "    \n",
    "    # Apply multi-head attention\n",
    "    attn_output = layers.MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=C // num_heads,\n",
    "    )(x_flat, x_flat)\n",
    "    \n",
    "    # Reshape back to original dimensions\n",
    "    output = Reshape((H, W, C))(attn_output)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def swin_transformer_block(inputs, dim, num_heads, mlp_ratio=4.0, dropout_rate=0.0):\n",
    "    \"\"\"Functional Swin Transformer block\"\"\"\n",
    "    # Layer norm 1\n",
    "    norm1 = layers.LayerNormalization(epsilon=1e-5)(inputs)\n",
    "    \n",
    "    # Window attention\n",
    "    attn_output = window_attention_block(norm1, num_heads)\n",
    "    \n",
    "    # First residual connection\n",
    "    res1 = layers.add([inputs, attn_output])\n",
    "    \n",
    "    # Layer norm 2\n",
    "    norm2 = layers.LayerNormalization(epsilon=1e-5)(res1)\n",
    "    \n",
    "    # MLP block\n",
    "    mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "    mlp_output = Reshape((-1, dim))(norm2)\n",
    "    mlp_output = mlp_block(mlp_output, mlp_hidden_dim, dropout_rate)\n",
    "    mlp_output = Reshape(tf.keras.backend.int_shape(norm2)[1:-1] + (dim,))(mlp_output)\n",
    "    \n",
    "    # Second residual connection\n",
    "    res2 = layers.add([res1, mlp_output])\n",
    "    \n",
    "    return res2\n",
    "\n",
    "def downsample_block(inputs, out_dim):\n",
    "    \"\"\"Downsample resolution by 2x and increase channels\"\"\"\n",
    "    x = layers.LayerNormalization(epsilon=1e-5)(inputs)\n",
    "    x = Conv2D(out_dim, kernel_size=2, strides=2, padding='same')(x)\n",
    "    return x\n",
    "\n",
    "def swin_transformer_stage(inputs, dim, depth, num_heads, downsample=True):\n",
    "    \"\"\"Functional implementation of a Swin Transformer stage\"\"\"\n",
    "    x = inputs\n",
    "    \n",
    "    # Apply transformer blocks\n",
    "    for i in range(depth):\n",
    "        x = swin_transformer_block(\n",
    "            x, dim=dim, num_heads=num_heads, \n",
    "            mlp_ratio=4.0, dropout_rate=0.1\n",
    "        )\n",
    "    \n",
    "    # Store output before downsampling\n",
    "    stage_output = x\n",
    "    \n",
    "    # Apply downsampling if needed\n",
    "    if downsample:\n",
    "        x = downsample_block(x, dim * 2)\n",
    "        return x, stage_output\n",
    "    else:\n",
    "        return x, stage_output\n",
    "\n",
    "def patch_embedding(inputs, embed_dim=128):\n",
    "    \"\"\"Patch embedding layer\"\"\"\n",
    "    x = Conv2D(embed_dim, kernel_size=4, strides=4, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('gelu')(x)\n",
    "    return x\n",
    "\n",
    "def ASPP(inputs):\n",
    "    \"\"\"Atrous Spatial Pyramid Pooling for DeepLabV3+\"\"\"\n",
    "    input_shape = tf.keras.backend.int_shape(inputs)\n",
    "    \n",
    "    # ASPP with different dilation rates\n",
    "    b0 = convolution_block(inputs, 512, kernel_size=1)\n",
    "    \n",
    "    b1 = convolution_block(inputs, 512, kernel_size=3, dilation_rate=6)\n",
    "    b2 = convolution_block(inputs, 512, kernel_size=3, dilation_rate=12)\n",
    "    b3 = convolution_block(inputs, 512, kernel_size=3, dilation_rate=18)\n",
    "    b4 = convolution_block(inputs, 512, kernel_size=3, dilation_rate=24)  # Extra branch\n",
    "    \n",
    "    # Global context\n",
    "    b5 = GlobalAveragePooling2D()(inputs)\n",
    "    b5 = Reshape((1, 1, input_shape[3]))(b5)\n",
    "    b5 = convolution_block(b5, 512, kernel_size=1)\n",
    "    b5 = layers.UpSampling2D(size=(input_shape[1], input_shape[2]), interpolation='bilinear')(b5)\n",
    "    \n",
    "    # Concatenate all branches\n",
    "    x = Concatenate()([b0, b1, b2, b3, b4, b5])\n",
    "    \n",
    "    # Project to output channels with more filters\n",
    "    x = convolution_block(x, 512, kernel_size=1)\n",
    "    x = convolution_block(x, 512, kernel_size=3)  # Extra conv\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_deeplabv3_plus_swinv2_functional(input_shape, num_classes):\n",
    "    \"\"\"DeepLabV3+ with SwinV2 backbone using functional API only\"\"\"\n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # SwinV2-Base configuration\n",
    "    embed_dim = 128\n",
    "    depths = [2, 2, 18, 2]  # Standard Swin-Base depth\n",
    "    num_heads = [4, 8, 16, 32]\n",
    "    \n",
    "    # Patch embedding\n",
    "    x = patch_embedding(inputs, embed_dim=embed_dim)\n",
    "    \n",
    "    # Store low-level features for skip connection\n",
    "    low_level_features = x  # 56x56\n",
    "    \n",
    "    # Apply transformer stages\n",
    "    features = {}\n",
    "    features[\"low_level\"] = low_level_features\n",
    "    \n",
    "    # Apply stages\n",
    "    current_dim = embed_dim\n",
    "    for i in range(len(depths)):\n",
    "        if i < len(depths) - 1:\n",
    "            x, stage_output = swin_transformer_stage(\n",
    "                x, dim=current_dim, depth=depths[i],\n",
    "                num_heads=num_heads[i], downsample=True\n",
    "            )\n",
    "            current_dim *= 2\n",
    "        else:\n",
    "            x, stage_output = swin_transformer_stage(\n",
    "                x, dim=current_dim, depth=depths[i],\n",
    "                num_heads=num_heads[i], downsample=False\n",
    "            )\n",
    "        \n",
    "        features[f\"stage{i+1}\"] = stage_output\n",
    "    \n",
    "    # ASPP module on final features\n",
    "    x = ASPP(x)\n",
    "    \n",
    "    # Process low-level features\n",
    "    low_level_features = convolution_block(low_level_features, 128, kernel_size=1)\n",
    "    \n",
    "    # Upsample ASPP output to match low-level features size\n",
    "    low_level_shape = tf.keras.backend.int_shape(low_level_features)\n",
    "    x = layers.Conv2DTranspose(\n",
    "        512, \n",
    "        kernel_size=3, \n",
    "        strides=4, \n",
    "        padding='same'\n",
    "    )(x)\n",
    "    \n",
    "    # Ensure right size\n",
    "    x = layers.Resizing(low_level_shape[1], low_level_shape[2])(x)\n",
    "    \n",
    "    # Concatenate features\n",
    "    x = Concatenate()([x, low_level_features])\n",
    "    \n",
    "    # Decoder convolutions\n",
    "    x = convolution_block(x, 512, kernel_size=3)\n",
    "    x = convolution_block(x, 512, kernel_size=3)\n",
    "    x = convolution_block(x, 256, kernel_size=3)  # Extra conv\n",
    "    \n",
    "    # Final upsampling to original resolution\n",
    "    x = layers.Conv2DTranspose(\n",
    "        256, \n",
    "        kernel_size=3, \n",
    "        strides=4, \n",
    "        padding='same'\n",
    "    )(x)\n",
    "    \n",
    "    # Final processing\n",
    "    x = layers.Resizing(input_shape[0], input_shape[1])(x)\n",
    "    x = convolution_block(x, 128, kernel_size=3)  # Extra conv\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Conv2D(\n",
    "        num_classes, \n",
    "        kernel_size=1, \n",
    "        padding='same', \n",
    "        activation='softmax'\n",
    "    )(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "model = build_deeplabv3_plus_swinv2_functional(\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS),\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ‚úÖ Dice Coefficient Metric\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1,2,3]) + tf.reduce_sum(y_pred, axis=[1,2,3])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Weighted Categorical Crossentropy\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    class_weights = tf.constant([0.3776, 0.7605, 65.8554, 46.2381], dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "    class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))\n",
    "    weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)\n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# ‚úÖ Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Combined Loss Function\n",
    "def combined_loss(y_true, y_pred):\n",
    "    return weighted_categorical_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "# ‚úÖ Custom Dice Coefficient Metric for Each Class\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_idx, name=None, **kwargs):  \n",
    "        if name is None:\n",
    "            name = f\"DiceClass{class_idx}\"  \n",
    "        super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        self.class_idx = class_idx\n",
    "        self.dice = self.add_weight(name=\"dice\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_class = y_true[..., self.class_idx]\n",
    "        y_pred_class = y_pred[..., self.class_idx]\n",
    "        intersection = tf.reduce_sum(y_true_class * y_pred_class, axis=[1, 2])\n",
    "        union = tf.reduce_sum(y_true_class, axis=[1, 2]) + tf.reduce_sum(y_pred_class, axis=[1, 2])\n",
    "        dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "        self.dice.assign(tf.reduce_mean(dice))\n",
    "\n",
    "    def result(self):\n",
    "        return self.dice\n",
    "\n",
    "# ‚úÖ Function to Get Class-wise Metrics\n",
    "def class_wise_metrics(num_classes=4):\n",
    "    return [DiceCoefficient(i) for i in range(num_classes)] + [tf.keras.metrics.MeanIoU(num_classes=num_classes)]\n",
    "\n",
    "# ‚úÖ Create Data Generator\n",
    "def create_train_generator(X, y, batch_size=6):\n",
    "    data_gen_args = dict(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    \n",
    "    seed = 42\n",
    "    image_generator = image_datagen.flow(X, batch_size=batch_size, seed=seed)\n",
    "    mask_generator = mask_datagen.flow(y, batch_size=batch_size, seed=seed)\n",
    "    \n",
    "    while True:\n",
    "        X_batch = next(image_generator)\n",
    "        y_batch = next(mask_generator)\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "# ‚úÖ Create the generator\n",
    "train_generator = create_train_generator(X_train, y_train, batch_size=3)\n",
    "\n",
    "# ‚úÖ Compile the Model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(4)\n",
    ")\n",
    "\n",
    "# ‚úÖ Train the Model with the Data Generator\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(X_train) // 16,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=7, \n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss', \n",
    "            factor=0.5, \n",
    "            patience=3, \n",
    "            min_lr=1e-6\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            'best_DeepLabV3+_Mobilevit.keras',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extracting data from the history object\n",
    "history_dict = history.history\n",
    "\n",
    "# Plotting the training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plotting loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_dict['loss'], label='Training Loss')\n",
    "plt.plot(history_dict['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# If accuracy is available, plot training and validation accuracy\n",
    "if 'accuracy' in history_dict:\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_dict['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history_dict['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Curves')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)  # Should be (num_samples, 128, 128, 3)\n",
    "print(X_test.shape)  # Should be (num_samples, 128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ‚úÖ RGB to Class Index Conversion (for the test masks)\n",
    "RGB_TO_CLASS = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0     # Background\n",
    "}\n",
    "\n",
    "# ‚úÖ Function to convert RGB masks to class index masks\n",
    "def rgb_to_class_mask(rgb_mask):\n",
    "    # Create a mask initialized with zeros (for background class)\n",
    "    class_mask = np.zeros(rgb_mask.shape[:2], dtype=int)\n",
    "\n",
    "    # Loop through the RGB_TO_CLASS dictionary\n",
    "    for rgb, class_idx in RGB_TO_CLASS.items():\n",
    "        # Identify the pixels with the current RGB value and assign them the class index\n",
    "        match_mask = np.all(rgb_mask == np.array(rgb), axis=-1)\n",
    "        class_mask[match_mask] = class_idx\n",
    "\n",
    "    return class_mask\n",
    "\n",
    "# ‚úÖ Function to calculate Dice Similarity Coefficient (DSC)\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# ‚úÖ Function to calculate IoU (Intersection over Union)\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-15)\n",
    "\n",
    "# ‚úÖ Function to calculate Hausdorff Distance\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')  # Return inf if no points for either true or pred class\n",
    "\n",
    "    forward_hausdorff = directed_hausdorff(true_points, pred_points)[0]\n",
    "    reverse_hausdorff = directed_hausdorff(pred_points, true_points)[0]\n",
    "    return max(forward_hausdorff, reverse_hausdorff)\n",
    "\n",
    "# ‚úÖ Function to calculate Average Surface Distance (ASD)\n",
    "def average_surface_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')  # Return inf if no points for either true or pred class\n",
    "\n",
    "    distances = []\n",
    "    for true_point in true_points:\n",
    "        distances.append(np.min(np.linalg.norm(pred_points - true_point, axis=1)))\n",
    "    return np.mean(distances)\n",
    "\n",
    "# ‚úÖ Function to evaluate the model on the test set class-wise\n",
    "def evaluate_classwise_metrics(model, X_test, y_test, num_classes=4, batch_size=16):\n",
    "    # Predict in batches\n",
    "    y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)  # Convert to class index prediction\n",
    "\n",
    "    # Convert y_test to class index format (since it's one-hot encoded)\n",
    "    y_test_class = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    # Initialize lists to store class-wise metrics\n",
    "    class_metrics = {i: {'dice': [], 'iou': [], 'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'hausdorff': [], 'asd': []} for i in range(num_classes)}\n",
    "\n",
    "    # Calculate metrics for each test sample\n",
    "    for i in range(len(X_test)):\n",
    "        true_mask = y_test_class[i]  # one-hot -> class index\n",
    "        pred_mask = y_pred[i]\n",
    "\n",
    "        # For each class (0: Background, 1: Brain, 2: CSP, 3: LV)\n",
    "        for class_idx in range(num_classes):\n",
    "            true_class_mask = (true_mask == class_idx).astype(int)\n",
    "            pred_class_mask = (pred_mask == class_idx).astype(int)\n",
    "\n",
    "            # Dice Coefficient\n",
    "            class_metrics[class_idx]['dice'].append(dice_coefficient(true_class_mask, pred_class_mask))\n",
    "            # IoU\n",
    "            class_metrics[class_idx]['iou'].append(iou(true_class_mask, pred_class_mask))\n",
    "            # Precision\n",
    "            class_metrics[class_idx]['precision'].append(precision_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # Recall\n",
    "            class_metrics[class_idx]['recall'].append(recall_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # F1 Score\n",
    "            class_metrics[class_idx]['f1'].append(f1_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # Accuracy\n",
    "            class_metrics[class_idx]['accuracy'].append(accuracy_score(true_class_mask.flatten(), pred_class_mask.flatten()))\n",
    "            # # Hausdorff Distance\n",
    "            # class_metrics[class_idx]['hausdorff'].append(hausdorff_distance(true_class_mask, pred_class_mask))\n",
    "            # # Average Surface Distance\n",
    "            # class_metrics[class_idx]['asd'].append(average_surface_distance(true_class_mask, pred_class_mask))\n",
    "\n",
    "    # Print class-wise metrics in percentage\n",
    "    print(f\"{'Class':<10}{'Dice Coefficient (%)':<20}{'IoU (%)':<20}{'Precision (%)':<20}{'Recall (%)':<20}{'F1 Score (%)':<20}{'Accuracy (%)':<20}{'Hausdorff Distance':<20}{'Avg Surface Distance':<20}\")\n",
    "    print('-' * 180)\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        print(f\"Class {class_idx}:\")\n",
    "        print(f\"  Dice Coefficient: {np.mean(class_metrics[class_idx]['dice']) * 100:.2f}%\")\n",
    "        print(f\"  IoU: {np.mean(class_metrics[class_idx]['iou']) * 100:.2f}%\")\n",
    "        print(f\"  Precision: {np.mean(class_metrics[class_idx]['precision']) * 100:.2f}%\")\n",
    "        print(f\"  Recall: {np.mean(class_metrics[class_idx]['recall']) * 100:.2f}%\")\n",
    "        print(f\"  F1 Score: {np.mean(class_metrics[class_idx]['f1']) * 100:.2f}%\")\n",
    "        print(f\"  Accuracy: {np.mean(class_metrics[class_idx]['accuracy']) * 100:.2f}%\")\n",
    "        # print(f\"  Hausdorff Distance: {np.mean(class_metrics[class_idx]['hausdorff']):.4f}\")\n",
    "        # print(f\"  Average Surface Distance: {np.mean(class_metrics[class_idx]['asd']):.4f}\")\n",
    "        print(\"-\" * 180)\n",
    "\n",
    "    # Evaluate on test set to print overall test accuracy and loss\n",
    "    test_loss, *test_metrics = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    for metric, value in zip(model.metrics_names[1:], test_metrics):\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# ‚úÖ Call the evaluation function on the test set class-wise\n",
    "evaluate_classwise_metrics(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6984035,
     "sourceId": 11187746,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
