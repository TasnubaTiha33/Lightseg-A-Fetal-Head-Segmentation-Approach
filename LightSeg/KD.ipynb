{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import re\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ‚úÖ Constants for 224x224\n",
    "IMG_HEIGHT = 224  # Ensure height is 224\n",
    "IMG_WIDTH = 224   # Ensure width is 224\n",
    "CHANNELS = 3  # RGB images\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "# ‚úÖ Class mapping from RGB to class index\n",
    "CLASS_MAP = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0,  # Background\n",
    "}\n",
    "\n",
    "image_dir = r\"D:\\augmented_dataset\\images\"\n",
    "mask_dir = r\"D:\\augmented_dataset\\masks\"\n",
    "\n",
    "# # ‚úÖ Define destination directories\n",
    "train_image_dir = r\"D:\\Updated\\train\\images\"\n",
    "train_mask_dir = r\"D:\\Updated\\train\\masks\"\n",
    "val_image_dir = r\"D:\\Updated\\val\\images\"\n",
    "val_mask_dir = r\"D:\\Updated\\val\\masks\"\n",
    "test_image_dir = r\"D:\\Updated\\test\\images\"\n",
    "test_mask_dir = r\"D:\\Updated\\test\\masks\"\n",
    "\n",
    "# ‚úÖ Fix sorting issue using natural sorting\n",
    "def natural_sort_key(s):\n",
    "    \"\"\"Sort filenames numerically instead of lexicographically.\"\"\"\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "# ‚úÖ Convert RGB mask to class index mask\n",
    "def rgb_to_class(mask_array):\n",
    "    \"\"\"Convert RGB mask to single-channel class index mask.\"\"\"\n",
    "    height, width, _ = mask_array.shape\n",
    "    class_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    for rgb, class_idx in CLASS_MAP.items():\n",
    "        matches = np.all(mask_array == rgb, axis=-1)  # Ensure exact match\n",
    "        class_mask[matches] = class_idx\n",
    "\n",
    "    return class_mask\n",
    "\n",
    "# ‚úÖ Preprocess Filtered Dataset for 224x224\n",
    "def preprocess_filtered_dataset(image_dir, mask_dir):\n",
    "    \"\"\"Preprocess images & masks: normalize, resize, and convert masks to one-hot encoding.\"\"\"\n",
    "\n",
    "    # ‚úÖ Load and sort filenames correctly\n",
    "    image_filenames = sorted(os.listdir(image_dir), key=natural_sort_key)\n",
    "    mask_filenames = sorted(os.listdir(mask_dir), key=natural_sort_key)\n",
    "\n",
    "    valid_image_paths = []\n",
    "    valid_mask_paths = []\n",
    "\n",
    "    # ‚úÖ Ensure each image has a corresponding mask\n",
    "    for img_file, mask_file in zip(image_filenames, mask_filenames):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "        if os.path.exists(img_path) and os.path.exists(mask_path):\n",
    "            valid_image_paths.append(img_path)\n",
    "            valid_mask_paths.append(mask_path)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Skipping {img_file}: Missing image or mask\")\n",
    "\n",
    "    num_images = len(valid_image_paths)\n",
    "\n",
    "    # ‚úÖ Initialize arrays\n",
    "    X = np.zeros((num_images, IMG_HEIGHT, IMG_WIDTH, CHANNELS), dtype=np.float32)\n",
    "    y = np.zeros((num_images, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES), dtype=np.float32)  # One-hot encoded masks\n",
    "\n",
    "    print(f\"üöÄ Processing {num_images} filtered images and masks...\")\n",
    "\n",
    "    for idx, (img_path, mask_path) in enumerate(zip(valid_image_paths, valid_mask_paths)):\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"‚úÖ Processed {idx}/{num_images} images\")\n",
    "\n",
    "        # ‚úÖ Load and Resize Image\n",
    "        img = cv2.imread(img_path)  # Read image in BGR format\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))  # Resize to (224,224)\n",
    "        img = img.astype(np.float32) / 255.0  # Normalize\n",
    "\n",
    "        # ‚úÖ Load and Resize Mask\n",
    "        mask = cv2.imread(mask_path)  # Read mask in BGR format\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)  # Resize mask correctly\n",
    "\n",
    "        # ‚úÖ Convert RGB mask to class mask\n",
    "        class_mask = rgb_to_class(mask)\n",
    "\n",
    "        # ‚úÖ One-hot encode the class mask\n",
    "        one_hot_mask = to_categorical(class_mask, num_classes=NUM_CLASSES)\n",
    "\n",
    "        # ‚úÖ Store preprocessed data\n",
    "        X[idx] = img\n",
    "        y[idx] = one_hot_mask\n",
    "\n",
    "        # ‚úÖ Clear memory to prevent memory leaks\n",
    "        del img, mask, class_mask, one_hot_mask\n",
    "        gc.collect()\n",
    "\n",
    "    return X, y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # ‚úÖ Process dataset splits\n",
    "# X_train, y_train = preprocess_filtered_dataset(train_image_dir, train_mask_dir)\n",
    "# X_val, y_val = preprocess_filtered_dataset(val_image_dir, val_mask_dir)\n",
    "X_test, y_test = preprocess_filtered_dataset(test_image_dir, test_mask_dir)\n",
    "\n",
    "# ‚úÖ Print dataset information\n",
    "print(\"\\n‚úÖ Dataset Splits:\")\n",
    "# print(f\"  - Training set: {X_train.shape}, {y_train.shape}\")\n",
    "# print(f\"  - Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"  - Test set: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import re\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ‚úÖ Constants for 224x224\n",
    "IMG_HEIGHT = 224  # Ensure height is 224\n",
    "IMG_WIDTH = 224   # Ensure width is 224\n",
    "CHANNELS = 3  # RGB images\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "# ‚úÖ Class mapping from RGB to class index\n",
    "CLASS_MAP = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0,  # Background\n",
    "}\n",
    "\n",
    "image_dir = r\"D:\\augmented_dataset\\images\"\n",
    "mask_dir = r\"D:\\augmented_dataset\\masks\"\n",
    "\n",
    "# # ‚úÖ Define destination directories\n",
    "train_image_dir = r\"D:\\Updated\\train\\images\"\n",
    "train_mask_dir = r\"D:\\Updated\\train\\masks\"\n",
    "val_image_dir = r\"D:\\Updated\\val\\images\"\n",
    "val_mask_dir = r\"D:\\Updated\\val\\masks\"\n",
    "test_image_dir = r\"D:\\Updated\\test\\images\"\n",
    "test_mask_dir = r\"D:\\Updated\\test\\masks\"\n",
    "\n",
    "# ‚úÖ Fix sorting issue using natural sorting\n",
    "def natural_sort_key(s):\n",
    "    \"\"\"Sort filenames numerically instead of lexicographically.\"\"\"\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "# ‚úÖ Convert RGB mask to class index mask\n",
    "def rgb_to_class(mask_array):\n",
    "    \"\"\"Convert RGB mask to single-channel class index mask.\"\"\"\n",
    "    height, width, _ = mask_array.shape\n",
    "    class_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    for rgb, class_idx in CLASS_MAP.items():\n",
    "        matches = np.all(mask_array == rgb, axis=-1)  # Ensure exact match\n",
    "        class_mask[matches] = class_idx\n",
    "\n",
    "    return class_mask\n",
    "\n",
    "# ‚úÖ Preprocess Filtered Dataset for 224x224\n",
    "def preprocess_filtered_dataset(image_dir, mask_dir):\n",
    "    \"\"\"Preprocess images & masks: normalize, resize, and convert masks to one-hot encoding.\"\"\"\n",
    "\n",
    "    # ‚úÖ Load and sort filenames correctly\n",
    "    image_filenames = sorted(os.listdir(image_dir), key=natural_sort_key)\n",
    "    mask_filenames = sorted(os.listdir(mask_dir), key=natural_sort_key)\n",
    "\n",
    "    valid_image_paths = []\n",
    "    valid_mask_paths = []\n",
    "\n",
    "    # ‚úÖ Ensure each image has a corresponding mask\n",
    "    for img_file, mask_file in zip(image_filenames, mask_filenames):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "        if os.path.exists(img_path) and os.path.exists(mask_path):\n",
    "            valid_image_paths.append(img_path)\n",
    "            valid_mask_paths.append(mask_path)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Skipping {img_file}: Missing image or mask\")\n",
    "\n",
    "    num_images = len(valid_image_paths)\n",
    "\n",
    "    # ‚úÖ Initialize arrays\n",
    "    X = np.zeros((num_images, IMG_HEIGHT, IMG_WIDTH, CHANNELS), dtype=np.float32)\n",
    "    y = np.zeros((num_images, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES), dtype=np.float32)  # One-hot encoded masks\n",
    "\n",
    "    print(f\"üöÄ Processing {num_images} filtered images and masks...\")\n",
    "\n",
    "    for idx, (img_path, mask_path) in enumerate(zip(valid_image_paths, valid_mask_paths)):\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"‚úÖ Processed {idx}/{num_images} images\")\n",
    "\n",
    "        # ‚úÖ Load and Resize Image\n",
    "        img = cv2.imread(img_path)  # Read image in BGR format\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))  # Resize to (224,224)\n",
    "        img = img.astype(np.float32) / 255.0  # Normalize\n",
    "\n",
    "        # ‚úÖ Load and Resize Mask\n",
    "        mask = cv2.imread(mask_path)  # Read mask in BGR format\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)  # Resize mask correctly\n",
    "\n",
    "        # ‚úÖ Convert RGB mask to class mask\n",
    "        class_mask = rgb_to_class(mask)\n",
    "\n",
    "        # ‚úÖ One-hot encode the class mask\n",
    "        one_hot_mask = to_categorical(class_mask, num_classes=NUM_CLASSES)\n",
    "\n",
    "        # ‚úÖ Store preprocessed data\n",
    "        X[idx] = img\n",
    "        y[idx] = one_hot_mask\n",
    "\n",
    "        # ‚úÖ Clear memory to prevent memory leaks\n",
    "        del img, mask, class_mask, one_hot_mask\n",
    "        gc.collect()\n",
    "\n",
    "    return X, y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # # ‚úÖ Process dataset splits\n",
    "X_train, y_train = preprocess_filtered_dataset(train_image_dir, train_mask_dir)\n",
    "X_val, y_val = preprocess_filtered_dataset(val_image_dir, val_mask_dir)\n",
    "# X_test, y_test = preprocess_filtered_dataset(test_image_dir, test_mask_dir)\n",
    "\n",
    "# # ‚úÖ Print dataset information\n",
    "# print(\"\\n‚úÖ Dataset Splits:\")\n",
    "# print(f\"  - Training set: {X_train.shape}, {y_train.shape}\")\n",
    "# print(f\"  - Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "# print(f\"  - Test set: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 4\n",
    "\n",
    "# ‚úÖ Dice Coefficient (Mean across all classes)\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Weighted Categorical Crossentropy\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    class_weights = tf.constant([0.3776, 0.7605, 65.8554, 46.2381], dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "    class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))\n",
    "    weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)\n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# ‚úÖ Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Lov√°sz-Softmax Loss\n",
    "def lovasz_softmax_loss(y_true, y_pred, ignore_background=False):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    num_classes = tf.shape(y_true)[-1]\n",
    "    start_class = tf.constant(1 if ignore_background else 0)\n",
    "\n",
    "    def compute_class_loss(c):\n",
    "        y_true_class = y_true[..., c]\n",
    "        y_pred_class = y_pred[..., c]\n",
    "\n",
    "        y_true_flat = tf.reshape(y_true_class, [-1])\n",
    "        y_pred_flat = tf.reshape(y_pred_class, [-1])\n",
    "\n",
    "        errors = tf.abs(y_true_flat - y_pred_flat)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], sorted=True)\n",
    "        y_true_sorted = tf.gather(y_true_flat, perm)\n",
    "\n",
    "        gts = tf.reduce_sum(y_true_sorted)\n",
    "        intersection = gts - tf.cumsum(y_true_sorted)\n",
    "        union = gts + tf.cumsum(1. - y_true_sorted)\n",
    "        jaccard = 1. - intersection / union\n",
    "        grad = tf.concat([[jaccard[0]], jaccard[1:] - jaccard[:-1]], 0)\n",
    "\n",
    "        return tf.tensordot(errors_sorted, grad, axes=1)\n",
    "\n",
    "    # Loop through classes using tf.while_loop\n",
    "    losses = tf.TensorArray(dtype=tf.float32, size=num_classes)\n",
    "\n",
    "    def loop_cond(c, losses):\n",
    "        return tf.less(c, num_classes)\n",
    "\n",
    "    def loop_body(c, losses):\n",
    "        loss_c = compute_class_loss(c)\n",
    "        losses = losses.write(c, loss_c)\n",
    "        return c + 1, losses\n",
    "\n",
    "    _, losses = tf.while_loop(loop_cond, loop_body, [start_class, losses])\n",
    "    return tf.reduce_mean(losses.stack())\n",
    "\n",
    "# ‚úÖ Combined Loss\n",
    "def combined_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice_loss_val = 1 - (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss_val = tf.reduce_mean(dice_loss_val)\n",
    "    \n",
    "    lovasz_loss_val = lovasz_softmax_loss(y_true, tf.nn.softmax(y_pred), ignore_background=False)\n",
    "    return lovasz_loss_val + dice_loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import re\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ‚úÖ Constants for 224x224\n",
    "IMG_HEIGHT = 224  # Ensure height is 224\n",
    "IMG_WIDTH = 224   # Ensure width is 224\n",
    "CHANNELS = 3  # RGB images\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "# ‚úÖ Class mapping from RGB to class index\n",
    "CLASS_MAP = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0,  # Background\n",
    "}\n",
    "\n",
    "test_image_blur_40_dir = r\"D:\\Updated\\test\\images - (Blur 40%)\"\n",
    "test_image_blur_20_dir = r\"D:\\Updated\\test\\images - (Blur 20%)\"\n",
    "test_image_bright_dir = r\"D:\\Updated\\test\\images - (Brightess enhanced)\"\n",
    "test_image_dark_dir = r\"D:\\Updated\\test\\images - (Brightess reduction)\"\n",
    "test_mask_dir = r\"D:\\Updated\\test\\masks\"\n",
    "\n",
    "# ‚úÖ Fix sorting issue using natural sorting\n",
    "def natural_sort_key(s):\n",
    "    \"\"\"Sort filenames numerically instead of lexicographically.\"\"\"\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "# ‚úÖ Convert RGB mask to class index mask\n",
    "def rgb_to_class(mask_array):\n",
    "    \"\"\"Convert RGB mask to single-channel class index mask.\"\"\"\n",
    "    height, width, _ = mask_array.shape\n",
    "    class_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    for rgb, class_idx in CLASS_MAP.items():\n",
    "        matches = np.all(mask_array == rgb, axis=-1)  # Ensure exact match\n",
    "        class_mask[matches] = class_idx\n",
    "\n",
    "    return class_mask\n",
    "\n",
    "# ‚úÖ Preprocess Filtered Dataset for 224x224\n",
    "def preprocess_filtered_dataset(image_dir, mask_dir):\n",
    "    \"\"\"Preprocess images & masks: normalize, resize, and convert masks to one-hot encoding.\"\"\"\n",
    "\n",
    "    # ‚úÖ Load and sort filenames correctly\n",
    "    image_filenames = sorted(os.listdir(image_dir), key=natural_sort_key)\n",
    "    mask_filenames = sorted(os.listdir(mask_dir), key=natural_sort_key)\n",
    "\n",
    "    valid_image_paths = []\n",
    "    valid_mask_paths = []\n",
    "\n",
    "    # ‚úÖ Ensure each image has a corresponding mask\n",
    "    for img_file, mask_file in zip(image_filenames, mask_filenames):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "        if os.path.exists(img_path) and os.path.exists(mask_path):\n",
    "            valid_image_paths.append(img_path)\n",
    "            valid_mask_paths.append(mask_path)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Skipping {img_file}: Missing image or mask\")\n",
    "\n",
    "    num_images = len(valid_image_paths)\n",
    "\n",
    "    # ‚úÖ Initialize arrays\n",
    "    X = np.zeros((num_images, IMG_HEIGHT, IMG_WIDTH, CHANNELS), dtype=np.float32)\n",
    "    y = np.zeros((num_images, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES), dtype=np.float32)  # One-hot encoded masks\n",
    "\n",
    "    print(f\"üöÄ Processing {num_images} filtered images and masks...\")\n",
    "\n",
    "    for idx, (img_path, mask_path) in enumerate(zip(valid_image_paths, valid_mask_paths)):\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"‚úÖ Processed {idx}/{num_images} images\")\n",
    "\n",
    "        # ‚úÖ Load and Resize Image\n",
    "        img = cv2.imread(img_path)  # Read image in BGR format\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))  # Resize to (224,224)\n",
    "        img = img.astype(np.float32) / 255.0  # Normalize\n",
    "\n",
    "        # ‚úÖ Load and Resize Mask\n",
    "        mask = cv2.imread(mask_path)  # Read mask in BGR format\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)  # Resize mask correctly\n",
    "\n",
    "        # ‚úÖ Convert RGB mask to class mask\n",
    "        class_mask = rgb_to_class(mask)\n",
    "\n",
    "        # ‚úÖ One-hot encode the class mask\n",
    "        one_hot_mask = to_categorical(class_mask, num_classes=NUM_CLASSES)\n",
    "\n",
    "        # ‚úÖ Store preprocessed data\n",
    "        X[idx] = img\n",
    "        y[idx] = one_hot_mask\n",
    "\n",
    "        # ‚úÖ Clear memory to prevent memory leaks\n",
    "        del img, mask, class_mask, one_hot_mask\n",
    "        gc.collect()\n",
    "\n",
    "    return X, y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_test_blur_40, y_test = preprocess_filtered_dataset(test_image_blur_40_dir, test_mask_dir)\n",
    "X_test_blur_20, y_test = preprocess_filtered_dataset(test_image_blur_20_dir, test_mask_dir)\n",
    "X_test_bright, y_test = preprocess_filtered_dataset(test_image_bright_dir, test_mask_dir)\n",
    "X_test_dark, y_test = preprocess_filtered_dataset(test_image_dark_dir, test_mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ‚úÖ Folder names and the corresponding transformation to apply\n",
    "variant_transforms = {\n",
    "    \"images - (Blur 20%)\": lambda img: cv2.GaussianBlur(img, (5, 5), 0),\n",
    "    \"images - (Blur 40%)\": lambda img: cv2.GaussianBlur(img, (11, 11), 0),\n",
    "    \"images - (Brightess reduction)\": lambda img: cv2.convertScaleAbs(img, alpha=0.7, beta=0),\n",
    "    \"images - (Brightess enhanced)\": lambda img: cv2.convertScaleAbs(img, alpha=1.3, beta=0),\n",
    "}\n",
    "\n",
    "# ‚úÖ Base path to your dataset\n",
    "base_dir = r\"D:\\Updated\\test\"\n",
    "\n",
    "# ‚úÖ Process each folder individually\n",
    "for folder_name, transform_fn in variant_transforms.items():\n",
    "    folder_path = os.path.join(base_dir, folder_name)\n",
    "    image_filenames = sorted(os.listdir(folder_path))\n",
    "    total = len(image_filenames)\n",
    "\n",
    "    print(f\"\\nüîß Updating: {folder_name} ({total} images)\")\n",
    "    for filename in tqdm(image_filenames):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"‚ö†Ô∏è Skipping unreadable image: {filename}\")\n",
    "            continue\n",
    "\n",
    "        transformed_img = transform_fn(img)\n",
    "        success = cv2.imwrite(img_path, transformed_img)\n",
    "\n",
    "        if not success:\n",
    "            print(f\"‚ùå Failed to overwrite: {filename}\")\n",
    "\n",
    "print(\"\\n‚úÖ All folders updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Constants for 224x224 images\n",
    "IMG_HEIGHT = 224  # Changed from 256 to 224\n",
    "IMG_WIDTH = 224   # Changed from 256 to 224\n",
    "CHANNELS = 3  # RGB images\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "def conv_block(inputs, filters, kernel_size=(3, 3), padding='same', strides=1):\n",
    "    \"\"\"\n",
    "    Double convolution block with batch normalization\n",
    "    \"\"\"\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=strides, padding=padding)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters, kernel_size, padding=padding)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_segnet(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Build SegNet model\n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    # Block 1\n",
    "    conv1 = conv_block(inputs, 64)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(conv1)\n",
    "    \n",
    "    # Block 2\n",
    "    conv2 = conv_block(pool1, 128)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(conv2)\n",
    "    \n",
    "    # Block 3\n",
    "    conv3 = conv_block(pool2, 256)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(conv3)\n",
    "    \n",
    "    # Block 4\n",
    "    conv4 = conv_block(pool3, 512)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(conv4)\n",
    "    \n",
    "    # Bridge\n",
    "    conv5 = conv_block(pool4, 1024)\n",
    "    \n",
    "    # Decoder\n",
    "    # Block 4\n",
    "    up4 = layers.UpSampling2D(size=(2, 2))(conv5)\n",
    "    up4 = layers.concatenate([up4, conv4], axis=-1)\n",
    "    up_conv4 = conv_block(up4, 512)\n",
    "    \n",
    "    # Block 3\n",
    "    up3 = layers.UpSampling2D(size=(2, 2))(up_conv4)\n",
    "    up3 = layers.concatenate([up3, conv3], axis=-1)\n",
    "    up_conv3 = conv_block(up3, 256)\n",
    "    \n",
    "    # Block 2\n",
    "    up2 = layers.UpSampling2D(size=(2, 2))(up_conv3)\n",
    "    up2 = layers.concatenate([up2, conv2], axis=-1)\n",
    "    up_conv2 = conv_block(up2, 128)\n",
    "    \n",
    "    # Block 1\n",
    "    up1 = layers.UpSampling2D(size=(2, 2))(up_conv2)\n",
    "    up1 = layers.concatenate([up1, conv1], axis=-1)\n",
    "    up_conv1 = conv_block(up1, 64)\n",
    "    \n",
    "    # Output\n",
    "    outputs = layers.Conv2D(num_classes, (1, 1), activation='softmax')(up_conv1)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "model = build_segnet(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), \n",
    "                     num_classes=NUM_CLASSES)\n",
    "\n",
    "# Print model summary\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Number of classes (adjust if needed)\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# ‚úÖ Dice Coefficient (Mean across all classes)\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Weighted Categorical Crossentropy\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    class_weights = tf.constant([0.3776, 0.7605, 65.8554, 46.2381], dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "    class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))\n",
    "    weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)\n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# ‚úÖ Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Lov√°sz-Softmax Loss\n",
    "def lovasz_softmax_loss(y_true, y_pred, ignore_background=False):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    num_classes = tf.shape(y_true)[-1]\n",
    "    start_class = tf.constant(1 if ignore_background else 0)\n",
    "\n",
    "    def compute_class_loss(c):\n",
    "        y_true_class = y_true[..., c]\n",
    "        y_pred_class = y_pred[..., c]\n",
    "\n",
    "        y_true_flat = tf.reshape(y_true_class, [-1])\n",
    "        y_pred_flat = tf.reshape(y_pred_class, [-1])\n",
    "\n",
    "        errors = tf.abs(y_true_flat - y_pred_flat)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], sorted=True)\n",
    "        y_true_sorted = tf.gather(y_true_flat, perm)\n",
    "\n",
    "        gts = tf.reduce_sum(y_true_sorted)\n",
    "        intersection = gts - tf.cumsum(y_true_sorted)\n",
    "        union = gts + tf.cumsum(1. - y_true_sorted)\n",
    "        jaccard = 1. - intersection / union\n",
    "        grad = tf.concat([[jaccard[0]], jaccard[1:] - jaccard[:-1]], 0)\n",
    "\n",
    "        return tf.tensordot(errors_sorted, grad, axes=1)\n",
    "\n",
    "    # Loop through classes using tf.while_loop\n",
    "    losses = tf.TensorArray(dtype=tf.float32, size=num_classes)\n",
    "\n",
    "    def loop_cond(c, losses):\n",
    "        return tf.less(c, num_classes)\n",
    "\n",
    "    def loop_body(c, losses):\n",
    "        loss_c = compute_class_loss(c)\n",
    "        losses = losses.write(c, loss_c)\n",
    "        return c + 1, losses\n",
    "\n",
    "    _, losses = tf.while_loop(loop_cond, loop_body, [start_class, losses])\n",
    "    return tf.reduce_mean(losses.stack())\n",
    "\n",
    "# ‚úÖ Combined Loss\n",
    "def combined_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice_loss_val = 1 - (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss_val = tf.reduce_mean(dice_loss_val)\n",
    "    \n",
    "    lovasz_loss_val = lovasz_softmax_loss(y_true, tf.nn.softmax(y_pred), ignore_background=False)\n",
    "    return lovasz_loss_val + dice_loss_val\n",
    "\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_idx=0, name=None, **kwargs):  # <- default class_idx=0 to avoid missing arg\n",
    "        if name is None:\n",
    "            name = f\"DiceClass{class_idx}\"\n",
    "        super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        self.class_idx = class_idx\n",
    "        self.dice = self.add_weight(name=\"dice\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_class = y_true[..., self.class_idx]\n",
    "        y_pred_class = y_pred[..., self.class_idx]\n",
    "        intersection = tf.reduce_sum(y_true_class * y_pred_class, axis=[1, 2])\n",
    "        union = tf.reduce_sum(y_true_class, axis=[1, 2]) + tf.reduce_sum(y_pred_class, axis=[1, 2])\n",
    "        dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "        self.dice.assign(tf.reduce_mean(dice))\n",
    "\n",
    "    def result(self):\n",
    "        return self.dice\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"class_idx\": self.class_idx})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        if \"class_idx\" not in config:\n",
    "            # Try to extract class index from name like \"DiceClass2\"\n",
    "            name = config.get(\"name\", \"DiceClass0\")\n",
    "            if name.startswith(\"DiceClass\"):\n",
    "                config[\"class_idx\"] = int(name.replace(\"DiceClass\", \"\"))\n",
    "            else:\n",
    "                config[\"class_idx\"] = 0\n",
    "        return cls(**config)\n",
    "\n",
    "# ‚úÖ Helper to load Dice metrics by name\n",
    "def dice_metric_loader(name):\n",
    "    if name.startswith(\"DiceClass\"):\n",
    "        class_idx = int(name.replace(\"DiceClass\", \"\"))\n",
    "        return DiceCoefficient(class_idx=class_idx)\n",
    "    raise ValueError(f\"Unknown Dice metric name: {name}\")\n",
    "\n",
    "# ‚úÖ Register all custom objects for loading the model\n",
    "custom_objects = {\n",
    "    'combined_loss': combined_loss,\n",
    "    'lovasz_softmax_loss': lovasz_softmax_loss,\n",
    "    'MeanIoU': tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES),\n",
    "    'DiceCoefficient': DiceCoefficient,\n",
    "}\n",
    "\n",
    "# ‚úÖ Add DiceClass0‚Äì3 dynamically\n",
    "for i in range(NUM_CLASSES):\n",
    "    custom_objects[f'DiceClass{i}'] = dice_metric_loader(f'DiceClass{i}')\n",
    "\n",
    "# ‚úÖ Load the model\n",
    "model_segnet = load_model('C:\\\\Users\\\\User\\\\best_unet_model_onlineDA_128_lovaszloss_segnet.keras', custom_objects=custom_objects)\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, Concatenate, BatchNormalization, Activation\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "import gc\n",
    "\n",
    "# Constants\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "class ResizeLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"Custom layer to resize images.\"\"\"\n",
    "    def __init__(self, target_size, **kwargs):\n",
    "        super(ResizeLayer, self).__init__(**kwargs)\n",
    "        self.target_size = target_size\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.image.resize(inputs, self.target_size, method='bilinear')\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(ResizeLayer, self).get_config()\n",
    "        config.update({\"target_size\": self.target_size})\n",
    "        return config\n",
    "\n",
    "def conv_block(x, filters, kernel_size=3, padding='same', activation='relu'):\n",
    "    \"\"\"Helper function for creating a conv block with BN and activation.\"\"\"\n",
    "    x = Conv2D(filters, kernel_size, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    # Add a second conv to increase parameters\n",
    "    x = Conv2D(filters, kernel_size, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "def build_full_inceptionresnetv2_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), num_classes=NUM_CLASSES):\n",
    "    \"\"\"\n",
    "    Build a full UNet model with InceptionResNetV2 backbone with 60-70M parameters\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Input shape of the image\n",
    "        num_classes: Number of output classes\n",
    "        \n",
    "    Returns:\n",
    "        Keras Model instance with UNet architecture\n",
    "    \"\"\"\n",
    "    # Input layer (no fixed batch size)\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Create a full InceptionResNetV2 model to use as backbone\n",
    "    base_model = InceptionResNetV2(\n",
    "        input_tensor=inputs,\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling=None\n",
    "    )\n",
    "    \n",
    "    # Make all layers trainable as requested\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Extract features from all encoder levels\n",
    "    # Standard blocks in InceptionResNetV2\n",
    "    encoder1 = base_model.get_layer('activation').output  # 111x111x64\n",
    "    encoder2 = base_model.get_layer('activation_3').output  # 55x55x192\n",
    "    encoder3 = base_model.get_layer('block35_10_ac').output  # 27x27x320\n",
    "    encoder4 = base_model.get_layer('block17_20_ac').output  # 13x13x1088\n",
    "    encoder5 = base_model.get_layer('conv_7b_ac').output  # 6x6x2080\n",
    "    \n",
    "    # Use the bottleneck as is - don't reduce its channels\n",
    "    bottleneck = encoder5  # 6x6x2080\n",
    "    \n",
    "    # First, reduce the bottleneck dimensions to control parameter count\n",
    "    bottleneck = Conv2D(512, 1, padding='same')(bottleneck)\n",
    "    bottleneck = BatchNormalization()(bottleneck)\n",
    "    bottleneck = Activation('relu')(bottleneck)\n",
    "    \n",
    "    # Level 5 to 4: 6x6 -> 13x13\n",
    "    up4 = UpSampling2D(size=(2, 2))(bottleneck)\n",
    "    up4 = ResizeLayer(target_size=(encoder4.shape[1], encoder4.shape[2]))(up4)\n",
    "    up4 = conv_block(up4, 512, kernel_size=3)  # Reduced filters\n",
    "    \n",
    "    # Reduce skip connection channels before concatenation\n",
    "    skip4 = Conv2D(256, 1, padding='same')(encoder4)\n",
    "    skip4 = BatchNormalization()(skip4)\n",
    "    skip4 = Activation('relu')(skip4)\n",
    "    \n",
    "    # Concatenate with skip connection\n",
    "    merge4 = Concatenate()([up4, skip4])\n",
    "    merge4 = conv_block(merge4, 384)  # Reduced filters\n",
    "    \n",
    "    # Level 4 to 3: 13x13 -> 27x27\n",
    "    up3 = UpSampling2D(size=(2, 2))(merge4)\n",
    "    up3 = ResizeLayer(target_size=(encoder3.shape[1], encoder3.shape[2]))(up3)\n",
    "    up3 = conv_block(up3, 384, kernel_size=3)  # Reduced filters\n",
    "    \n",
    "    # Reduce skip connection channels\n",
    "    skip3 = Conv2D(128, 1, padding='same')(encoder3)\n",
    "    skip3 = BatchNormalization()(skip3)\n",
    "    skip3 = Activation('relu')(skip3)\n",
    "    \n",
    "    # Concatenate with skip connection\n",
    "    merge3 = Concatenate()([up3, skip3])\n",
    "    merge3 = conv_block(merge3, 192)  # Reduced filters\n",
    "    \n",
    "    # Level 3 to 2: 27x27 -> 55x55\n",
    "    up2 = UpSampling2D(size=(2, 2))(merge3)\n",
    "    up2 = ResizeLayer(target_size=(encoder2.shape[1], encoder2.shape[2]))(up2)\n",
    "    up2 = conv_block(up2, 192, kernel_size=3)  # Reduced filters\n",
    "    \n",
    "    # Reduce skip connection channels\n",
    "    skip2 = Conv2D(96, 1, padding='same')(encoder2)\n",
    "    skip2 = BatchNormalization()(skip2)\n",
    "    skip2 = Activation('relu')(skip2)\n",
    "    \n",
    "    # Concatenate with skip connection\n",
    "    merge2 = Concatenate()([up2, skip2])\n",
    "    merge2 = conv_block(merge2, 96)  # Reduced filters\n",
    "    \n",
    "    # Level 2 to 1: 55x55 -> 111x111\n",
    "    up1 = UpSampling2D(size=(2, 2))(merge2)\n",
    "    up1 = ResizeLayer(target_size=(encoder1.shape[1], encoder1.shape[2]))(up1)\n",
    "    up1 = conv_block(up1, 96, kernel_size=3)  # Reduced filters\n",
    "    \n",
    "    # Reduce skip connection channels\n",
    "    skip1 = Conv2D(48, 1, padding='same')(encoder1)\n",
    "    skip1 = BatchNormalization()(skip1)\n",
    "    skip1 = Activation('relu')(skip1)\n",
    "    \n",
    "    # Concatenate with skip connection\n",
    "    merge1 = Concatenate()([up1, skip1])\n",
    "    merge1 = conv_block(merge1, 48)  # Reduced filters\n",
    "    \n",
    "    # Final upsampling to original resolution: 111x111 -> 224x224\n",
    "    up_final = UpSampling2D(size=(2, 2))(merge1)\n",
    "    up_final = conv_block(up_final, 32)  # Reduced filters\n",
    "    \n",
    "    # Ensure final size matches input\n",
    "    if up_final.shape[1] != input_shape[0] or up_final.shape[2] != input_shape[1]:\n",
    "        up_final = ResizeLayer(target_size=(input_shape[0], input_shape[1]))(up_final)\n",
    "    \n",
    "    # Add a final segmentation head\n",
    "    outputs = Conv2D(num_classes, 1, activation='softmax', dtype='float32')(up_final)\n",
    "    \n",
    "    # Create and return the model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "print(\"Creating full InceptionResNetV2-UNet model...\")\n",
    "model = build_full_inceptionresnetv2_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), num_classes=NUM_CLASSES)\n",
    "print(\"Model created successfully!\")\n",
    "\n",
    "# Clear memory\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "class ResizeLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"Custom layer to resize images.\"\"\"\n",
    "    def __init__(self, target_size, **kwargs):\n",
    "        super(ResizeLayer, self).__init__(**kwargs)\n",
    "        self.target_size = target_size\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.image.resize(inputs, self.target_size, method='bilinear')\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(ResizeLayer, self).get_config()\n",
    "        config.update({\"target_size\": self.target_size})\n",
    "        return config\n",
    "\n",
    "# Number of classes (adjust if needed)\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# ‚úÖ Dice Coefficient (Mean across all classes)\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Weighted Categorical Crossentropy\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    class_weights = tf.constant([0.3776, 0.7605, 65.8554, 46.2381], dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "    class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))\n",
    "    weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)\n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# ‚úÖ Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Lov√°sz-Softmax Loss\n",
    "def lovasz_softmax_loss(y_true, y_pred, ignore_background=False):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    num_classes = tf.shape(y_true)[-1]\n",
    "    start_class = tf.constant(1 if ignore_background else 0)\n",
    "\n",
    "    def compute_class_loss(c):\n",
    "        y_true_class = y_true[..., c]\n",
    "        y_pred_class = y_pred[..., c]\n",
    "\n",
    "        y_true_flat = tf.reshape(y_true_class, [-1])\n",
    "        y_pred_flat = tf.reshape(y_pred_class, [-1])\n",
    "\n",
    "        errors = tf.abs(y_true_flat - y_pred_flat)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], sorted=True)\n",
    "        y_true_sorted = tf.gather(y_true_flat, perm)\n",
    "\n",
    "        gts = tf.reduce_sum(y_true_sorted)\n",
    "        intersection = gts - tf.cumsum(y_true_sorted)\n",
    "        union = gts + tf.cumsum(1. - y_true_sorted)\n",
    "        jaccard = 1. - intersection / union\n",
    "        grad = tf.concat([[jaccard[0]], jaccard[1:] - jaccard[:-1]], 0)\n",
    "\n",
    "        return tf.tensordot(errors_sorted, grad, axes=1)\n",
    "\n",
    "    # Loop through classes using tf.while_loop\n",
    "    losses = tf.TensorArray(dtype=tf.float32, size=num_classes)\n",
    "\n",
    "    def loop_cond(c, losses):\n",
    "        return tf.less(c, num_classes)\n",
    "\n",
    "    def loop_body(c, losses):\n",
    "        loss_c = compute_class_loss(c)\n",
    "        losses = losses.write(c, loss_c)\n",
    "        return c + 1, losses\n",
    "\n",
    "    _, losses = tf.while_loop(loop_cond, loop_body, [start_class, losses])\n",
    "    return tf.reduce_mean(losses.stack())\n",
    "\n",
    "# ‚úÖ Combined Loss\n",
    "def combined_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice_loss_val = 1 - (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss_val = tf.reduce_mean(dice_loss_val)\n",
    "    \n",
    "    lovasz_loss_val = lovasz_softmax_loss(y_true, tf.nn.softmax(y_pred), ignore_background=False)\n",
    "    return lovasz_loss_val + dice_loss_val\n",
    "\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_idx=0, name=None, **kwargs):  # <- default class_idx=0 to avoid missing arg\n",
    "        if name is None:\n",
    "            name = f\"DiceClass{class_idx}\"\n",
    "        super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        self.class_idx = class_idx\n",
    "        self.dice = self.add_weight(name=\"dice\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_class = y_true[..., self.class_idx]\n",
    "        y_pred_class = y_pred[..., self.class_idx]\n",
    "        intersection = tf.reduce_sum(y_true_class * y_pred_class, axis=[1, 2])\n",
    "        union = tf.reduce_sum(y_true_class, axis=[1, 2]) + tf.reduce_sum(y_pred_class, axis=[1, 2])\n",
    "        dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "        self.dice.assign(tf.reduce_mean(dice))\n",
    "\n",
    "    def result(self):\n",
    "        return self.dice\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"class_idx\": self.class_idx})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        if \"class_idx\" not in config:\n",
    "            # Try to extract class index from name like \"DiceClass2\"\n",
    "            name = config.get(\"name\", \"DiceClass0\")\n",
    "            if name.startswith(\"DiceClass\"):\n",
    "                config[\"class_idx\"] = int(name.replace(\"DiceClass\", \"\"))\n",
    "            else:\n",
    "                config[\"class_idx\"] = 0\n",
    "        return cls(**config)\n",
    "\n",
    "# ‚úÖ Helper to load Dice metrics by name\n",
    "def dice_metric_loader(name):\n",
    "    if name.startswith(\"DiceClass\"):\n",
    "        class_idx = int(name.replace(\"DiceClass\", \"\"))\n",
    "        return DiceCoefficient(class_idx=class_idx)\n",
    "    raise ValueError(f\"Unknown Dice metric name: {name}\")\n",
    "\n",
    "# ‚úÖ Register all custom objects for loading the model\n",
    "custom_objects = {\n",
    "    'ResizeLayer': ResizeLayer,\n",
    "    'combined_loss': combined_loss,\n",
    "    'lovasz_softmax_loss': lovasz_softmax_loss,\n",
    "    'MeanIoU': tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES),\n",
    "    'DiceCoefficient': DiceCoefficient,\n",
    "}\n",
    "\n",
    "# ‚úÖ Add DiceClass0‚Äì3 dynamically\n",
    "for i in range(NUM_CLASSES):\n",
    "    custom_objects[f'DiceClass{i}'] = dice_metric_loader(f'DiceClass{i}')\n",
    "\n",
    "# ‚úÖ Load the model\n",
    "model_inceptionresnetv2 = load_model('lovaszloss_unet++_inceptionresnetv2.keras', custom_objects=custom_objects)\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Add\n",
    "from tensorflow.keras.layers import Dense, Dropout, Layer, Reshape, Permute, Multiply, Concatenate\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, LayerNormalization, UpSampling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "\n",
    "class ResizeToMatchLayer(Layer):\n",
    "    \"\"\"Layer to resize input to match target tensor's spatial dimensions.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ResizeToMatchLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x, target = inputs\n",
    "        # Get spatial dimensions of target tensor\n",
    "        target_shape = tf.shape(target)\n",
    "        target_height, target_width = target_shape[1], target_shape[2]\n",
    "        \n",
    "        # Resize x to match target's spatial dimensions\n",
    "        return tf.image.resize(x, [target_height, target_width], method='bilinear')\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[1][1], input_shape[1][2], input_shape[0][3])\n",
    "\n",
    "def conv_block(x, filters, kernel_size=3, strides=1, padding='same', use_bn=True, activation='relu'):\n",
    "    \"\"\"Standard convolution block with BatchNorm and activation.\"\"\"\n",
    "    x = Conv2D(filters, kernel_size, strides=strides, padding=padding)(x)\n",
    "    \n",
    "    if use_bn:\n",
    "        x = BatchNormalization()(x)\n",
    "    \n",
    "    if activation:\n",
    "        x = Activation(activation)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def attention_gate(x, g, inter_channels):\n",
    "    \"\"\"\n",
    "    Attention Gate as described in Attention U-Net paper.\n",
    "    Args:\n",
    "        x: Feature map from skip connection (from encoder)\n",
    "        g: Gating signal from previous decoder layer\n",
    "        inter_channels: Number of channels in intermediate representations\n",
    "    \"\"\"\n",
    "    # Resize gating signal to match feature map's spatial dimensions if needed\n",
    "    g = ResizeToMatchLayer()([g, x])\n",
    "    \n",
    "    # Intermediate representation for input feature map\n",
    "    theta_x = Conv2D(inter_channels, 1, use_bias=False, padding='same')(x)\n",
    "    \n",
    "    # Intermediate representation for gating signal\n",
    "    phi_g = Conv2D(inter_channels, 1, use_bias=False, padding='same')(g)\n",
    "    \n",
    "    # Element-wise sum and ReLU\n",
    "    f = Activation('relu')(Add()([theta_x, phi_g]))\n",
    "    \n",
    "    # 1x1 convolution followed by sigmoid to get attention coefficients\n",
    "    psi_f = Conv2D(1, 1, use_bias=False, padding='same')(f)\n",
    "    att_map = Activation('sigmoid')(psi_f)\n",
    "    \n",
    "    # Apply attention\n",
    "    return Multiply()([x, att_map])\n",
    "\n",
    "def decoder_block(x, skip_connection, filters, use_attention=True):\n",
    "    \"\"\"Decoder block for Attention U-Net.\"\"\"\n",
    "    # Upsampling\n",
    "    x = UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "    \n",
    "    # Ensure dimensions match for concatenation\n",
    "    x = ResizeToMatchLayer()([x, skip_connection])\n",
    "    \n",
    "    # Apply attention mechanism if specified\n",
    "    if use_attention:\n",
    "        # Generate attention-gated skip connection\n",
    "        skip_connection = attention_gate(skip_connection, x, filters // 2)\n",
    "    \n",
    "    # Concatenate with skip connection\n",
    "    x = Concatenate()([x, skip_connection])\n",
    "    \n",
    "    # Apply two convolution blocks\n",
    "    x = conv_block(x, filters, 3, padding='same')\n",
    "    x = conv_block(x, filters, 3, padding='same')\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_efficientnet_attention_unet(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Build an Attention U-Net model with EfficientNetB4 backbone for semantic segmentation.\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Input shape of the image (height, width, channels)\n",
    "        num_classes: Number of segmentation classes\n",
    "        \n",
    "    Returns:\n",
    "        A Keras Model instance\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "        \n",
    "    # Load EfficientNetB4 with pre-trained weights as encoder backbone\n",
    "    # All layers are trainable for fine-tuning\n",
    "    base_model = EfficientNetB4(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_tensor=inputs\n",
    "    )\n",
    "    \n",
    "    # Reduce filter count to control parameter count since we're not freezing any layers\n",
    "    initial_filters = 32\n",
    "    \n",
    "    # Get skip connections from appropriate layers\n",
    "    skip1 = base_model.get_layer('block1b_add').output        # 1/2 scale (112x112)\n",
    "    skip2 = base_model.get_layer('block2d_add').output        # 1/4 scale (56x56)\n",
    "    skip3 = base_model.get_layer('block3d_add').output        # 1/8 scale (28x28)\n",
    "    skip4 = base_model.get_layer('block5e_add').output        # 1/16 scale (14x14)\n",
    "    \n",
    "    # Bridge (bottleneck)\n",
    "    bridge = base_model.get_layer('top_activation').output    # 1/32 scale (7x7)\n",
    "    \n",
    "    \n",
    "    # Reduce channels for each skip connection to control parameter count\n",
    "    skip1_conv = conv_block(skip1, initial_filters)\n",
    "    skip2_conv = conv_block(skip2, initial_filters * 2)\n",
    "    skip3_conv = conv_block(skip3, initial_filters * 4)\n",
    "    skip4_conv = conv_block(skip4, initial_filters * 8)\n",
    "    \n",
    "    # Reduce channels in bridge\n",
    "    bridge_conv = conv_block(bridge, initial_filters * 16)\n",
    "    \n",
    "    # Decoder pathway with attention gates\n",
    "    d1 = decoder_block(bridge_conv, skip4_conv, initial_filters * 8, use_attention=True)  # 1/16\n",
    "    d2 = decoder_block(d1, skip3_conv, initial_filters * 4, use_attention=True)           # 1/8\n",
    "    d3 = decoder_block(d2, skip2_conv, initial_filters * 2, use_attention=True)           # 1/4\n",
    "    d4 = decoder_block(d3, skip1_conv, initial_filters, use_attention=True)               # 1/2\n",
    "    \n",
    "    # Final upsampling to original image size\n",
    "    final = UpSampling2D(size=(2, 2), interpolation='bilinear')(d4)\n",
    "    \n",
    "    # Final convolution to generate segmentation map\n",
    "    outputs = Conv2D(num_classes, 1, padding='same', activation='softmax')(final)\n",
    "    \n",
    "    # Create and return the model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "# model = build_efficientnet_attention_unet(input_shape=(224, 224, 3), num_classes=4)\n",
    "\n",
    "# Print model summary\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1,2,3]) + tf.reduce_sum(y_pred, axis=[1,2,3])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Weighted Categorical Crossentropy\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    class_weights = tf.constant([0.3776, 0.7605, 65.8554, 46.2381], dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "    class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))\n",
    "    weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)\n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# ‚úÖ Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Custom Dice Coefficient Metric for Each Class\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_idx, name=None, **kwargs):  \n",
    "        if name is None:\n",
    "            name = f\"DiceClass{class_idx}\"  \n",
    "        super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        self.class_idx = class_idx\n",
    "        self.dice = self.add_weight(name=\"dice\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_class = y_true[..., self.class_idx]\n",
    "        y_pred_class = y_pred[..., self.class_idx]\n",
    "        intersection = tf.reduce_sum(y_true_class * y_pred_class, axis=[1, 2])\n",
    "        union = tf.reduce_sum(y_true_class, axis=[1, 2]) + tf.reduce_sum(y_pred_class, axis=[1, 2])\n",
    "        dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "        self.dice.assign(tf.reduce_mean(dice))\n",
    "\n",
    "    def result(self):\n",
    "        return self.dice\n",
    "\n",
    "# ‚úÖ Function to Get Class-wise Metrics\n",
    "def class_wise_metrics(num_classes=4):\n",
    "    return [DiceCoefficient(i) for i in range(num_classes)] + [tf.keras.metrics.MeanIoU(num_classes=num_classes)]\n",
    "\n",
    "model_efficientnetb4 = build_efficientnet_attention_unet(input_shape=(224, 224, 3), num_classes=4)\n",
    "model_efficientnetb4.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(4)  # Number of classes\n",
    ")\n",
    "model_efficientnetb4.load_weights(\"efficientnet_attention_unet_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "# Constants for 224x224 images\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "def convolution_block(inputs, filters, kernel_size=3, dilation_rate=1, padding='same', use_bias=False):\n",
    "    \"\"\"\n",
    "    Standard convolution block with batch normalization and ReLU activation\n",
    "    \"\"\"\n",
    "    x = layers.Conv2D(\n",
    "        filters, \n",
    "        kernel_size, \n",
    "        padding=padding,\n",
    "        dilation_rate=dilation_rate,\n",
    "        use_bias=use_bias\n",
    "    )(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def ASPP(inputs):\n",
    "    \"\"\"\n",
    "    Atrous Spatial Pyramid Pooling module for DeepLabV3+\n",
    "    \"\"\"\n",
    "    # ASPP with different dilation rates\n",
    "    b0 = convolution_block(inputs, 256, kernel_size=1, dilation_rate=1)\n",
    "    b1 = convolution_block(inputs, 256, kernel_size=3, dilation_rate=6)\n",
    "    b2 = convolution_block(inputs, 256, kernel_size=3, dilation_rate=12)\n",
    "    b3 = convolution_block(inputs, 256, kernel_size=3, dilation_rate=18)\n",
    "    \n",
    "    # Global context - simplified approach\n",
    "    b4 = layers.GlobalAveragePooling2D()(inputs)\n",
    "    b4 = layers.Reshape((1, 1, inputs.shape[-1]))(b4)\n",
    "    b4 = convolution_block(b4, 256, kernel_size=1)\n",
    "    # Use fixed upsampling instead of dynamic\n",
    "    b4 = layers.UpSampling2D(size=(inputs.shape[1], inputs.shape[2]))(b4)\n",
    "    \n",
    "    # Concatenate all branches\n",
    "    x = layers.Concatenate()([b0, b1, b2, b3, b4])\n",
    "    \n",
    "    # Final 1x1 convolution\n",
    "    output = convolution_block(x, 256, kernel_size=1)\n",
    "    return output\n",
    "\n",
    "def build_deeplabv3_plus_xception(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    DeepLabV3+ model with Xception backbone\n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Xception as backbone (with output stride of 16)\n",
    "    base_model = Xception(\n",
    "        input_tensor=inputs,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Don't freeze any layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Extract features from Xception\n",
    "    # The entry flow ends with 'block4_sepconv2_bn' which is a good low-level feature point\n",
    "    low_level_features = base_model.get_layer('block4_sepconv2_bn').output\n",
    "    # The final features from the exit flow\n",
    "    high_level_features = base_model.output\n",
    "    \n",
    "    # Process low-level features\n",
    "    low_level_features = convolution_block(low_level_features, 48, kernel_size=1)\n",
    "    \n",
    "    # Process high-level features with ASPP\n",
    "    x = ASPP(high_level_features)\n",
    "    \n",
    "    # Calculate upsampling factor for high-level features to match low-level features\n",
    "    hl_shape = high_level_features.shape\n",
    "    ll_shape = low_level_features.shape\n",
    "    h_factor = ll_shape[1] // hl_shape[1]\n",
    "    w_factor = ll_shape[2] // hl_shape[2]\n",
    "    \n",
    "    # Upsample high-level features to match low-level features\n",
    "    x = layers.UpSampling2D(size=(h_factor, w_factor), interpolation='bilinear')(x)\n",
    "    \n",
    "    # Concatenate features\n",
    "    x = layers.Concatenate()([x, low_level_features])\n",
    "    \n",
    "    # Apply convolution blocks\n",
    "    x = convolution_block(x, 256, kernel_size=3)\n",
    "    x = convolution_block(x, 256, kernel_size=3)\n",
    "    \n",
    "    # Calculate upsampling factor needed to reach 224x224\n",
    "    current_shape = x.shape\n",
    "    h_factor = IMG_HEIGHT // current_shape[1]\n",
    "    w_factor = IMG_WIDTH // current_shape[2]\n",
    "    \n",
    "    # Final upsampling to original size (224x224)\n",
    "    x = layers.UpSampling2D(size=(h_factor, w_factor), interpolation='bilinear')(x)\n",
    "    \n",
    "    # Ensure exact dimensions with a reshape if needed\n",
    "    x = layers.Reshape((IMG_HEIGHT, IMG_WIDTH, int(current_shape[3])))(x)\n",
    "    \n",
    "    # Final convolution for output (224, 224, 4)\n",
    "    outputs = layers.Conv2D(num_classes, kernel_size=1, padding='same', activation='softmax')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "model = build_deeplabv3_plus_xception(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), \n",
    "                                     num_classes=NUM_CLASSES)\n",
    "\n",
    "# Print model summary\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Number of classes (adjust if needed)\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# ‚úÖ Dice Coefficient (Mean across all classes)\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Weighted Categorical Crossentropy\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    class_weights = tf.constant([0.3776, 0.7605, 65.8554, 46.2381], dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "    class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))\n",
    "    weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)\n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# ‚úÖ Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Lov√°sz-Softmax Loss\n",
    "def lovasz_softmax_loss(y_true, y_pred, ignore_background=False):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    num_classes = tf.shape(y_true)[-1]\n",
    "    start_class = tf.constant(1 if ignore_background else 0)\n",
    "\n",
    "    def compute_class_loss(c):\n",
    "        y_true_class = y_true[..., c]\n",
    "        y_pred_class = y_pred[..., c]\n",
    "\n",
    "        y_true_flat = tf.reshape(y_true_class, [-1])\n",
    "        y_pred_flat = tf.reshape(y_pred_class, [-1])\n",
    "\n",
    "        errors = tf.abs(y_true_flat - y_pred_flat)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], sorted=True)\n",
    "        y_true_sorted = tf.gather(y_true_flat, perm)\n",
    "\n",
    "        gts = tf.reduce_sum(y_true_sorted)\n",
    "        intersection = gts - tf.cumsum(y_true_sorted)\n",
    "        union = gts + tf.cumsum(1. - y_true_sorted)\n",
    "        jaccard = 1. - intersection / union\n",
    "        grad = tf.concat([[jaccard[0]], jaccard[1:] - jaccard[:-1]], 0)\n",
    "\n",
    "        return tf.tensordot(errors_sorted, grad, axes=1)\n",
    "\n",
    "    # Loop through classes using tf.while_loop\n",
    "    losses = tf.TensorArray(dtype=tf.float32, size=num_classes)\n",
    "\n",
    "    def loop_cond(c, losses):\n",
    "        return tf.less(c, num_classes)\n",
    "\n",
    "    def loop_body(c, losses):\n",
    "        loss_c = compute_class_loss(c)\n",
    "        losses = losses.write(c, loss_c)\n",
    "        return c + 1, losses\n",
    "\n",
    "    _, losses = tf.while_loop(loop_cond, loop_body, [start_class, losses])\n",
    "    return tf.reduce_mean(losses.stack())\n",
    "\n",
    "# ‚úÖ Combined Loss\n",
    "def combined_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice_loss_val = 1 - (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss_val = tf.reduce_mean(dice_loss_val)\n",
    "    \n",
    "    lovasz_loss_val = lovasz_softmax_loss(y_true, tf.nn.softmax(y_pred), ignore_background=False)\n",
    "    return lovasz_loss_val + dice_loss_val\n",
    "\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_idx=0, name=None, **kwargs):  # <- default class_idx=0 to avoid missing arg\n",
    "        if name is None:\n",
    "            name = f\"DiceClass{class_idx}\"\n",
    "        super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        self.class_idx = class_idx\n",
    "        self.dice = self.add_weight(name=\"dice\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_class = y_true[..., self.class_idx]\n",
    "        y_pred_class = y_pred[..., self.class_idx]\n",
    "        intersection = tf.reduce_sum(y_true_class * y_pred_class, axis=[1, 2])\n",
    "        union = tf.reduce_sum(y_true_class, axis=[1, 2]) + tf.reduce_sum(y_pred_class, axis=[1, 2])\n",
    "        dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "        self.dice.assign(tf.reduce_mean(dice))\n",
    "\n",
    "    def result(self):\n",
    "        return self.dice\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"class_idx\": self.class_idx})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        if \"class_idx\" not in config:\n",
    "            # Try to extract class index from name like \"DiceClass2\"\n",
    "            name = config.get(\"name\", \"DiceClass0\")\n",
    "            if name.startswith(\"DiceClass\"):\n",
    "                config[\"class_idx\"] = int(name.replace(\"DiceClass\", \"\"))\n",
    "            else:\n",
    "                config[\"class_idx\"] = 0\n",
    "        return cls(**config)\n",
    "\n",
    "# ‚úÖ Helper to load Dice metrics by name\n",
    "def dice_metric_loader(name):\n",
    "    if name.startswith(\"DiceClass\"):\n",
    "        class_idx = int(name.replace(\"DiceClass\", \"\"))\n",
    "        return DiceCoefficient(class_idx=class_idx)\n",
    "    raise ValueError(f\"Unknown Dice metric name: {name}\")\n",
    "\n",
    "\n",
    "\n",
    "custom_objects = {\n",
    "    'combined_loss': combined_loss,\n",
    "    'lovasz_softmax_loss': lovasz_softmax_loss,\n",
    "    'MeanIoU': tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES),\n",
    "    'DiceCoefficient': DiceCoefficient,\n",
    "}\n",
    "\n",
    "# ‚úÖ Add DiceClass0‚Äì3 dynamically\n",
    "for i in range(NUM_CLASSES):\n",
    "    custom_objects[f'DiceClass{i}'] = dice_metric_loader(f'DiceClass{i}')\n",
    "\n",
    "# ‚úÖ Load the model\n",
    "model_xception = load_model('lovaszloss_deeplabv3_xception.keras', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.spatial.distance as dist\n",
    "from scipy.ndimage import binary_erosion\n",
    "import psutil\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "# Set up logging for better control over debug and output verbosity\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Check system memory\n",
    "def check_memory():\n",
    "    \"\"\"Check available system memory\"\"\"\n",
    "    memory = psutil.virtual_memory()\n",
    "    logger.info(f\"Total RAM: {memory.total / (1024**3):.2f} GB\")\n",
    "    logger.info(f\"Available RAM: {memory.available / (1024**3):.2f} GB\")\n",
    "    logger.info(f\"Used RAM: {memory.used / (1024**3):.2f} GB\")\n",
    "    logger.info(f\"Memory percentage used: {memory.percent:.1f}%\")\n",
    "    return memory\n",
    "\n",
    "def compute_surface_distances_optimized(pred, true, max_points=1000):\n",
    "    \"\"\"\n",
    "    Memory-optimized surface distance calculation with systematic point sampling.\n",
    "    \"\"\"\n",
    "    pred = tf.cast(pred, tf.bool).numpy()\n",
    "    true = tf.cast(true, tf.bool).numpy()\n",
    "    \n",
    "    # Extract boundary points\n",
    "    pred_boundary = get_boundary_points(pred)\n",
    "    true_boundary = get_boundary_points(true)\n",
    "    \n",
    "    logger.info(f\"Pred boundary points: {len(pred_boundary)}, True boundary points: {len(true_boundary)}\")\n",
    "    \n",
    "    # Handle edge cases\n",
    "    if len(pred_boundary) == 0 or len(true_boundary) == 0:\n",
    "        if len(pred_boundary) == 0 and len(true_boundary) == 0:\n",
    "            return np.array([[0]]), np.array([[0]])\n",
    "        else:\n",
    "            return np.array([[np.inf]]), np.array([[np.inf]])\n",
    "    \n",
    "    # Sample points if too many (to avoid memory issues)\n",
    "    if len(pred_boundary) > max_points:\n",
    "        step = len(pred_boundary) // max_points\n",
    "        pred_boundary = pred_boundary[::step][:max_points]\n",
    "        logger.info(f\"Systematically sampled pred boundary to {len(pred_boundary)} points\")\n",
    "    \n",
    "    if len(true_boundary) > max_points:\n",
    "        step = len(true_boundary) // max_points\n",
    "        true_boundary = true_boundary[::step][:max_points]\n",
    "        logger.info(f\"Systematically sampled true boundary to {len(true_boundary)} points\")\n",
    "    \n",
    "    # Estimate memory needed\n",
    "    estimated_memory_gb = (len(pred_boundary) * len(true_boundary) * 8) / (1024**3)\n",
    "    logger.info(f\"Estimated memory needed: {estimated_memory_gb:.2f} GB\")\n",
    "    \n",
    "    # Use chunked computation if still too large\n",
    "    if estimated_memory_gb > 2.0:  # If > 2GB, use chunked approach\n",
    "        return compute_distances_chunked(pred_boundary, true_boundary)\n",
    "    else:\n",
    "        # Compute distances normally\n",
    "        dist_pred_to_true = dist.cdist(pred_boundary, true_boundary, 'euclidean')\n",
    "        dist_true_to_pred = dist.cdist(true_boundary, pred_boundary, 'euclidean')\n",
    "        return dist_pred_to_true, dist_true_to_pred\n",
    "\n",
    "def compute_distances_chunked(pred_boundary, true_boundary, chunk_size=500):\n",
    "    \"\"\"\n",
    "    Compute distances in chunks to avoid memory issues.\n",
    "    \"\"\"\n",
    "    logger.info(\"Using chunked computation...\")\n",
    "    \n",
    "    # Initialize arrays to store minimum distances\n",
    "    min_pred_to_true = np.full(len(pred_boundary), np.inf)\n",
    "    min_true_to_pred = np.full(len(true_boundary), np.inf)\n",
    "    \n",
    "    # Process pred_boundary in chunks\n",
    "    for i in range(0, len(pred_boundary), chunk_size):\n",
    "        end_i = min(i + chunk_size, len(pred_boundary))\n",
    "        chunk_pred = pred_boundary[i:end_i]\n",
    "        \n",
    "        # Compute distances for this chunk\n",
    "        chunk_dist = dist.cdist(chunk_pred, true_boundary, 'euclidean')\n",
    "        \n",
    "        # Update minimum distances\n",
    "        min_pred_to_true[i:end_i] = np.min(chunk_dist, axis=1)\n",
    "        \n",
    "        # Clean up\n",
    "        del chunk_dist\n",
    "        gc.collect()\n",
    "    \n",
    "    # Process true_boundary in chunks\n",
    "    for j in range(0, len(true_boundary), chunk_size):\n",
    "        end_j = min(j + chunk_size, len(true_boundary))\n",
    "        chunk_true = true_boundary[j:end_j]\n",
    "        \n",
    "        # Compute distances for this chunk\n",
    "        chunk_dist = dist.cdist(chunk_true, pred_boundary, 'euclidean')\n",
    "        \n",
    "        # Update minimum distances\n",
    "        min_true_to_pred[j:end_j] = np.min(chunk_dist, axis=1)\n",
    "        \n",
    "        # Clean up\n",
    "        del chunk_dist\n",
    "        gc.collect()\n",
    "    \n",
    "    # Return as 2D arrays for compatibility\n",
    "    return min_pred_to_true.reshape(-1, 1), min_true_to_pred.reshape(-1, 1)\n",
    "\n",
    "def get_boundary_points(mask):\n",
    "    \"\"\"Extract boundary points with optional thinning.\"\"\"\n",
    "    if not np.any(mask):\n",
    "        return np.array([]).reshape(0, mask.ndim)\n",
    "    \n",
    "    # Get boundary using binary erosion\n",
    "    eroded = binary_erosion(mask)\n",
    "    boundary = mask & ~eroded\n",
    "    boundary_points = np.argwhere(boundary)\n",
    "    \n",
    "    return boundary_points\n",
    "\n",
    "def hausdorff_distance_optimized(dist_pred_to_true, dist_true_to_pred):\n",
    "    \"\"\"Optimized Hausdorff distance calculation.\"\"\"\n",
    "    if dist_pred_to_true.size == 0 or dist_true_to_pred.size == 0:\n",
    "        return np.inf\n",
    "    \n",
    "    # Handle chunked output (1D arrays)\n",
    "    max_dist_pred_to_true = np.max(np.min(dist_pred_to_true, axis=1))\n",
    "    max_dist_true_to_pred = np.max(np.min(dist_true_to_pred, axis=1))\n",
    "    \n",
    "    return max(max_dist_pred_to_true, max_dist_true_to_pred)\n",
    "\n",
    "def average_symmetric_surface_distance_optimized(dist_pred_to_true, dist_true_to_pred):\n",
    "    \"\"\"Optimized ASD calculation.\"\"\"\n",
    "    if dist_pred_to_true.size == 0 or dist_true_to_pred.size == 0:\n",
    "        return np.inf\n",
    "    \n",
    "    # Handle chunked output (1D arrays)\n",
    "    avg_dist_pred_to_true = np.mean(np.min(dist_pred_to_true, axis=1))\n",
    "    avg_dist_true_to_pred = np.mean(np.min(dist_true_to_pred, axis=1))\n",
    "    \n",
    "    return (avg_dist_pred_to_true + avg_dist_true_to_pred) / 2\n",
    "\n",
    "def calculate_mean_hd_and_asd_optimized(model, x_test, y_test, max_boundary_points=1000):\n",
    "    \"\"\"\n",
    "    Memory-optimized calculation of mean HD and ASD.\n",
    "    \"\"\"\n",
    "    logger.info(\"Checking system memory:\")\n",
    "    check_memory()\n",
    "    logger.info(\"Checking system memory:\")\n",
    "    \n",
    "    all_hd = []\n",
    "    all_asd = []\n",
    "    \n",
    "    for i in range(len(x_test)):\n",
    "        logger.info(f\"Processing sample {i+1}/{len(x_test)}\")\n",
    "        try:\n",
    "            y_pred = model.predict(np.expand_dims(x_test[i], axis=0), verbose=0)\n",
    "            y_true = y_test[i]\n",
    "            \n",
    "            # Convert to binary\n",
    "            if y_pred.max() <= 1.0 and y_pred.min() >= 0.0:\n",
    "                y_pred_binary = (y_pred[0] > 0.5).astype(bool)\n",
    "            else:\n",
    "                y_pred_binary = y_pred[0].astype(bool)\n",
    "            \n",
    "            y_true_binary = y_true.astype(bool)\n",
    "            \n",
    "            logger.info(f\"Mask shapes - Pred: {y_pred_binary.shape}, True: {y_true_binary.shape}\")\n",
    "            \n",
    "            # Compute surface distances\n",
    "            dist_pred_to_true, dist_true_to_pred = compute_surface_distances_optimized(\n",
    "                y_pred_binary, y_true_binary, max_boundary_points\n",
    "            )\n",
    "            \n",
    "            # Compute metrics\n",
    "            hd = hausdorff_distance_optimized(dist_pred_to_true, dist_true_to_pred)\n",
    "            asd = average_symmetric_surface_distance_optimized(dist_pred_to_true, dist_true_to_pred)\n",
    "            \n",
    "            if not np.isinf(hd) and not np.isinf(asd):\n",
    "                all_hd.append(hd)\n",
    "                all_asd.append(asd)\n",
    "                logger.info(f\"HD: {hd:.4f}, ASD: {asd:.4f}\")\n",
    "            else:\n",
    "                logger.info(f\"Skipping sample {i} due to empty mask(s)\")\n",
    "            \n",
    "            # Clean up memory\n",
    "            del dist_pred_to_true, dist_true_to_pred\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing sample {i}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        logger.info(\"Checking system memory:\")\n",
    "    \n",
    "    if len(all_hd) == 0:\n",
    "        logger.warning(\"No valid samples to compute metrics\")\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    mean_hd = np.mean(all_hd)\n",
    "    mean_asd = np.mean(all_asd)\n",
    "    \n",
    "    return mean_hd, mean_asd\n",
    "\n",
    "# Check your current memory usage\n",
    "logger.info(\"=== SYSTEM MEMORY CHECK ===\")\n",
    "memory_info = check_memory()\n",
    "logger.info(\"End of system memory check.\")  # Add a message to avoid TypeError\n",
    "\n",
    "# Run the optimized calculation\n",
    "logger.info(\"=== RUNNING OPTIMIZED SURFACE DISTANCE CALCULATION ===\")\n",
    "try:\n",
    "    # Use fewer boundary points to reduce memory usage\n",
    "    mean_hd, mean_asd = calculate_mean_hd_and_asd_optimized(\n",
    "        model_segnet, X_test, y_test, max_boundary_points=500\n",
    "    )\n",
    "    logger.info(f\"\\nFinal Results:\")\n",
    "    logger.info(f\"Mean Hausdorff Distance: {mean_hd:.4f}\")\n",
    "    logger.info(f\"Mean Average Symmetric Surface Distance: {mean_asd:.4f}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"=== RUNNING OPTIMIZED SURFACE DISTANCE CALCULATION ===\")\n",
    "try:\n",
    "    # Use fewer boundary points to reduce memory usage\n",
    "    mean_hd, mean_asd = calculate_mean_hd_and_asd_optimized(\n",
    "        model_xception, X_test, y_test, max_boundary_points=500\n",
    "    )\n",
    "    logger.info(f\"\\nFinal Results:\")\n",
    "    logger.info(f\"Mean Hausdorff Distance: {mean_hd:.4f}\")\n",
    "    logger.info(f\"Mean Average Symmetric Surface Distance: {mean_asd:.4f}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"=== RUNNING OPTIMIZED SURFACE DISTANCE CALCULATION ===\")\n",
    "try:\n",
    "    # Use fewer boundary points to reduce memory usage\n",
    "    mean_hd, mean_asd = calculate_mean_hd_and_asd_optimized(\n",
    "        model_efficientnetb4, X_test, y_test, max_boundary_points=500\n",
    "    )\n",
    "    logger.info(f\"\\nFinal Results:\")\n",
    "    logger.info(f\"Mean Hausdorff Distance: {mean_hd:.4f}\")\n",
    "    logger.info(f\"Mean Average Symmetric Surface Distance: {mean_asd:.4f}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"=== RUNNING OPTIMIZED SURFACE DISTANCE CALCULATION ===\")\n",
    "try:\n",
    "    # Use fewer boundary points to reduce memory usage\n",
    "    mean_hd, mean_asd = calculate_mean_hd_and_asd_optimized(\n",
    "        model_inceptionresnetv2, X_test, y_test, max_boundary_points=500\n",
    "    )\n",
    "    logger.info(f\"\\nFinal Results:\")\n",
    "    logger.info(f\"Mean Hausdorff Distance: {mean_hd:.4f}\")\n",
    "    logger.info(f\"Mean Average Symmetric Surface Distance: {mean_asd:.4f}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"=== RUNNING OPTIMIZED SURFACE DISTANCE CALCULATION ===\")\n",
    "try:\n",
    "    # Use fewer boundary points to reduce memory usage\n",
    "    mean_hd, mean_asd = calculate_mean_hd_and_asd_optimized(\n",
    "        student_model, X_test, y_test, max_boundary_points=500\n",
    "    )\n",
    "    logger.info(f\"\\nFinal Results:\")\n",
    "    logger.info(f\"Mean Hausdorff Distance: {mean_hd:.4f}\")\n",
    "    logger.info(f\"Mean Average Symmetric Surface Distance: {mean_asd:.4f}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Knowledge Distillation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data Augmentation configuration for the training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "# Fit the augmentation parameters on the training data\n",
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Activation, UpSampling2D, Concatenate, Add\n",
    "\n",
    "def res_conv_block(inputs, filters, kernel_size=(3, 3), padding=\"same\", use_batch_norm=True):\n",
    "    \"\"\"\n",
    "    Residual convolutional block with skip connections\n",
    "    \"\"\"\n",
    "    # Store input for residual connection\n",
    "    shortcut = inputs\n",
    "    \n",
    "    # First convolution\n",
    "    x = Conv2D(filters, kernel_size, padding=padding)(inputs)\n",
    "    if use_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    # Second convolution\n",
    "    x = Conv2D(filters, kernel_size, padding=padding)(x)\n",
    "    if use_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    \n",
    "    # If input channels don't match output channels, use 1x1 conv to match dimensions\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, (1, 1), padding=padding)(shortcut)\n",
    "        if use_batch_norm:\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    # Add residual connection\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def UNetPlusPlus(input_shape=(224, 224, 3), num_classes=4, filters=[24, 48, 96, 192], use_batch_norm=True):\n",
    "    \"\"\"\n",
    "    Enhanced UNet++ with residual connections\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Input image dimensions (height, width, channels)\n",
    "        num_classes: Number of output classes for segmentation\n",
    "        filters: List of filter dimensions for each level\n",
    "        use_batch_norm: Whether to use batch normalization\n",
    "    \"\"\"\n",
    "    # Input\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder (Downsampling path)\n",
    "    conv0_0 = res_conv_block(inputs, filters[0], use_batch_norm=use_batch_norm)\n",
    "    pool0 = MaxPooling2D(pool_size=(2, 2))(conv0_0)\n",
    "    \n",
    "    conv1_0 = res_conv_block(pool0, filters[1], use_batch_norm=use_batch_norm)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1_0)\n",
    "    \n",
    "    conv2_0 = res_conv_block(pool1, filters[2], use_batch_norm=use_batch_norm)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2_0)\n",
    "    \n",
    "    conv3_0 = res_conv_block(pool2, filters[3], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    # Decoder (Upsampling path with nested dense skip connections)\n",
    "    # Level 1 skip connections\n",
    "    up1_0 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv3_0)\n",
    "    concat2_1 = Concatenate()([up1_0, conv2_0])\n",
    "    conv2_1 = res_conv_block(concat2_1, filters[2], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    up0_1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv2_0)\n",
    "    concat1_1 = Concatenate()([up0_1, conv1_0])\n",
    "    conv1_1 = res_conv_block(concat1_1, filters[1], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    up0_2 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv1_0)\n",
    "    concat0_1 = Concatenate()([up0_2, conv0_0])\n",
    "    conv0_1 = res_conv_block(concat0_1, filters[0], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    # Level 2 skip connections\n",
    "    up1_1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv2_1)\n",
    "    concat1_2 = Concatenate()([up1_1, conv1_0, conv1_1])\n",
    "    conv1_2 = res_conv_block(concat1_2, filters[1], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    up0_3 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv1_1)\n",
    "    concat0_2 = Concatenate()([up0_3, conv0_0, conv0_1])\n",
    "    conv0_2 = res_conv_block(concat0_2, filters[0], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    # Level 3 skip connections\n",
    "    up0_4 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv1_2)\n",
    "    concat0_3 = Concatenate()([up0_4, conv0_0, conv0_1, conv0_2])\n",
    "    conv0_3 = res_conv_block(concat0_3, filters[0], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    # Output segmentation map (single output)\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(conv0_3)\n",
    "    \n",
    "    # Create model with single output\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    "\n",
    "student_model = UNetPlusPlus(input_shape=(224, 224, 3), num_classes=4)\n",
    "student_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',  # You can also use 'val_loss' if you log it manually\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',  # Or 'val_loss'\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='best_student_unetplusplus.keras',\n",
    "        monitor='val_loss',  # Or 'val_loss'\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "def create_train_generator(X, y, batch_size=16):\n",
    "    data_gen_args = dict(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    \n",
    "    seed = 42\n",
    "    image_generator = image_datagen.flow(X, batch_size=batch_size, seed=seed)\n",
    "    mask_generator = mask_datagen.flow(y, batch_size=batch_size, seed=seed)\n",
    "    \n",
    "    while True:\n",
    "        X_batch = next(image_generator)\n",
    "        y_batch = next(mask_generator)\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "train_generator = create_train_generator(X_train, y_train, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Hyperparameter Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# === Hyperparameter Space ===\n",
    "batch_sizes = [8, 16]\n",
    "temperatures = [1, 3, 9]\n",
    "alphas = [0.5]\n",
    "learning_rates = [1e-4, 1e-3]\n",
    "optimizers_dict = {\n",
    "    \"adam\": tf.keras.optimizers.Adam,\n",
    "    \"sgd\": tf.keras.optimizers.SGD,\n",
    "    \"rmsprop\": tf.keras.optimizers.RMSprop\n",
    "    \n",
    "}\n",
    "\n",
    "# === Result Logging ===\n",
    "results = []\n",
    "\n",
    "# === Dummy Callback for Logging Metrics ===\n",
    "class LoggingCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch + 1}: {logs}\")\n",
    "\n",
    "# === Training Loop ===\n",
    "trial_num = 1\n",
    "for batch_size, temp, alpha, lr, (opt_name, opt_class) in product(\n",
    "    batch_sizes, temperatures, alphas, learning_rates, optimizers_dict.items()\n",
    "):\n",
    "    print(f\"\\n=== Trial {trial_num} ===\")\n",
    "    print(f\"Batch Size: {batch_size}, Temp: {temp}, Alpha: {alpha}, LR: {lr}, Optimizer: {opt_name}\")\n",
    "\n",
    "    # === Prepare Optimizer ===\n",
    "    optimizer = opt_class(learning_rate=lr)\n",
    "\n",
    "    # === Instantiate Student Model from Scratch ===\n",
    "    student = UNetPlusPlus(input_shape=(224, 224, 3), num_classes=4)\n",
    "\n",
    "    # === KD Trainer Setup ===\n",
    "    kd_model = KDTrainer(\n",
    "        student=student,\n",
    "        teacher=teacher_model,\n",
    "        alpha=alpha,\n",
    "        temperature=temp\n",
    "    )\n",
    "\n",
    "    kd_model.compile(\n",
    "        optimizer=optimizer,\n",
    "        metrics=class_wise_metrics(num_classes=4)\n",
    "    )\n",
    "\n",
    "    # === Generator and Training ===\n",
    "    train_generator = create_train_generator(X_train, y_train, batch_size=batch_size)\n",
    "    steps_per_epoch = len(X_train) // batch_size\n",
    "\n",
    "    history = kd_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=5,\n",
    "        verbose=0,\n",
    "        callbacks=[LoggingCallback()]\n",
    "    )\n",
    "\n",
    "    # === Evaluate & Log ===\n",
    "    val_metrics = kd_model.evaluate(X_val, y_val, verbose=0)\n",
    "    metric_names = kd_model.metrics_names\n",
    "    metric_dict = dict(zip(metric_names, val_metrics))\n",
    "\n",
    "    results.append({\n",
    "        \"Trial\": trial_num,\n",
    "        \"Dice Coefficient\": metric_dict.get(\"dice_coef\", np.nan),\n",
    "        \"Batch Size\": batch_size,\n",
    "        \"Temperature\": temp,\n",
    "        \"Alpha\": alpha,\n",
    "        \"Learning Rate\": lr,\n",
    "        \"Optimizer\": opt_name\n",
    "    })\n",
    "\n",
    "    trial_num += 1\n",
    "\n",
    "# === Print Summary Table ===\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== Trial Summary ===\")\n",
    "print(results_df[[\"Trial\", \"Dice Coefficient\", \"Batch Size\", \"Temperature\", \"Optimizer\", \"Learning Rate\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "models = [\n",
    "    model_xception,\n",
    "    model_segnet,\n",
    "    model_inceptionresnetv2,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "class WeightedSoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, weights=None, apply_softmax=True):\n",
    "        super(WeightedSoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        if weights is None:\n",
    "            weights = [1.0 / len(models)] * len(models)\n",
    "        else:\n",
    "            total = sum(weights)\n",
    "            weights = [w / total for w in weights]\n",
    "\n",
    "        self.model_weights = tf.constant(weights, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        weighted_sum = 0\n",
    "        for i, model in enumerate(self.models):\n",
    "            output = model(x, training=training)\n",
    "\n",
    "            is_softmaxed = (\n",
    "                hasattr(model, \"name\") and \"efficientnet\" in model.name.lower()\n",
    "            )\n",
    "\n",
    "            if self.apply_softmax and not is_softmaxed:\n",
    "                probs = tf.nn.softmax(output, axis=-1)\n",
    "            else:\n",
    "                probs = output\n",
    "\n",
    "            weighted_sum += self.model_weights[i] * probs\n",
    "\n",
    "        avg_prob = weighted_sum  # shape: [B, H, W, C]\n",
    "\n",
    "        # üîÅ Convert to one-hot for metric compatibility\n",
    "        one_hot_pred = tf.one_hot(tf.argmax(avg_prob, axis=-1), depth=avg_prob.shape[-1])\n",
    "        return one_hot_pred  # [B, H, W, C]\n",
    "\n",
    "final_weights = [0.255, 0.2427, 0.2515, 0.2508]\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "teacher_model = ensemble_model \n",
    "\n",
    "def distillation_loss(y_true, y_student_logits, y_teacher_probs, alpha=0.5, temperature=3.0):\n",
    "    # Softened predictions for KL\n",
    "    student_soft = tf.nn.softmax(y_student_logits / temperature)\n",
    "    teacher_soft = tf.nn.softmax(y_teacher_probs / temperature)\n",
    "\n",
    "    # Soft loss: KL divergence\n",
    "    kl_loss = tf.keras.losses.KLDivergence()(teacher_soft, student_soft)\n",
    "\n",
    "    # Hard loss: Use your custom combined loss (Dice + Lovasz)\n",
    "    ce_loss = combined_loss(y_true, y_student_logits) + tf.keras.losses.CategoricalCrossentropy()(y_true, y_student_logits)\n",
    "\n",
    "    # Combine them\n",
    "    return alpha * ce_loss + (1 - alpha) * (temperature ** 2) * kl_loss\n",
    "\n",
    "# === KD Wrapper Model ===\n",
    "class KDTrainer(tf.keras.Model):\n",
    "    def __init__(self, student, teacher, alpha=0.5, temperature=3.0):\n",
    "        super(KDTrainer, self).__init__()\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def compile(self, optimizer, metrics):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.metrics_list = metrics\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y_true = data\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_logits = self.student(x, training=True)               # [B, H, W, C]\n",
    "            teacher_probs = self.teacher(x, training=False)               # Soft probs\n",
    "\n",
    "            loss = distillation_loss(\n",
    "                y_true, student_logits, teacher_probs,\n",
    "                alpha=self.alpha, temperature=self.temperature\n",
    "            )\n",
    "\n",
    "        grads = tape.gradient(loss, self.student.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.student.trainable_variables))\n",
    "\n",
    "        for metric in self.metrics_list:\n",
    "            metric.update_state(y_true, student_logits)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics_list} | {\"loss\": loss}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y_true = data\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = self.student(x, training=False)\n",
    "        loss = combined_loss(y_true, y_pred)\n",
    "\n",
    "        for metric in self.metrics_list:\n",
    "            metric.update_state(y_true, y_pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics_list} | {\"loss\": loss}\n",
    "\n",
    "# === Instantiate KDTrainer ===\n",
    "kd_model = KDTrainer(\n",
    "    student=student_model,\n",
    "    teacher=teacher_model,\n",
    "    alpha=0.5,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "# === Compile ===\n",
    "kd_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "checkpoint_path = f\"best_student_unetplusplus_{timestamp}\"\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=6,\n",
    "        min_lr=1e-7\n",
    "    ), \n",
    "    ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    save_format='tf'  # ‚úÖ use TF SavedModel format\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_train_generator(X, y, batch_size=16):\n",
    "    data_gen_args = dict(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    seed = 42\n",
    "    image_generator = image_datagen.flow(X, batch_size=batch_size, seed=seed)\n",
    "    mask_generator = mask_datagen.flow(y, batch_size=batch_size, seed=seed)\n",
    "\n",
    "    while True:\n",
    "        X_batch = next(image_generator)\n",
    "        y_batch = next(mask_generator)\n",
    "        yield X_batch.astype('float32'), y_batch.astype('float32')\n",
    "\n",
    "batch_size = 8\n",
    "train_generator = create_train_generator(X_train, y_train, batch_size=batch_size)\n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "\n",
    "\n",
    "history = kd_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.save_weights(\"student_model_weights_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.load_weights(\"student_model_weights_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Number of classes (adjust if needed)\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# ‚úÖ Dice Coefficient (Mean across all classes)\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Weighted Categorical Crossentropy\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    class_weights = tf.constant([0.3776, 0.7605, 65.8554, 46.2381], dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "    class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))\n",
    "    weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)\n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# ‚úÖ Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Lov√°sz-Softmax Loss\n",
    "def lovasz_softmax_loss(y_true, y_pred, ignore_background=False):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    num_classes = tf.shape(y_true)[-1]\n",
    "    start_class = tf.constant(1 if ignore_background else 0)\n",
    "\n",
    "    def compute_class_loss(c):\n",
    "        y_true_class = y_true[..., c]\n",
    "        y_pred_class = y_pred[..., c]\n",
    "\n",
    "        y_true_flat = tf.reshape(y_true_class, [-1])\n",
    "        y_pred_flat = tf.reshape(y_pred_class, [-1])\n",
    "\n",
    "        errors = tf.abs(y_true_flat - y_pred_flat)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], sorted=True)\n",
    "        y_true_sorted = tf.gather(y_true_flat, perm)\n",
    "\n",
    "        gts = tf.reduce_sum(y_true_sorted)\n",
    "        intersection = gts - tf.cumsum(y_true_sorted)\n",
    "        union = gts + tf.cumsum(1. - y_true_sorted)\n",
    "        jaccard = 1. - intersection / union\n",
    "        grad = tf.concat([[jaccard[0]], jaccard[1:] - jaccard[:-1]], 0)\n",
    "\n",
    "        return tf.tensordot(errors_sorted, grad, axes=1)\n",
    "\n",
    "    # Loop through classes using tf.while_loop\n",
    "    losses = tf.TensorArray(dtype=tf.float32, size=num_classes)\n",
    "\n",
    "    def loop_cond(c, losses):\n",
    "        return tf.less(c, num_classes)\n",
    "\n",
    "    def loop_body(c, losses):\n",
    "        loss_c = compute_class_loss(c)\n",
    "        losses = losses.write(c, loss_c)\n",
    "        return c + 1, losses\n",
    "\n",
    "    _, losses = tf.while_loop(loop_cond, loop_body, [start_class, losses])\n",
    "    return tf.reduce_mean(losses.stack())\n",
    "\n",
    "# ‚úÖ Combined Loss\n",
    "def combined_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice_loss_val = 1 - (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss_val = tf.reduce_mean(dice_loss_val)\n",
    "    \n",
    "    lovasz_loss_val = lovasz_softmax_loss(y_true, tf.nn.softmax(y_pred), ignore_background=False)\n",
    "    return lovasz_loss_val + dice_loss_val\n",
    "\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_idx=0, name=None, **kwargs):  # <- default class_idx=0 to avoid missing arg\n",
    "        if name is None:\n",
    "            name = f\"DiceClass{class_idx}\"\n",
    "        super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        self.class_idx = class_idx\n",
    "        self.dice = self.add_weight(name=\"dice\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_class = y_true[..., self.class_idx]\n",
    "        y_pred_class = y_pred[..., self.class_idx]\n",
    "        intersection = tf.reduce_sum(y_true_class * y_pred_class, axis=[1, 2])\n",
    "        union = tf.reduce_sum(y_true_class, axis=[1, 2]) + tf.reduce_sum(y_pred_class, axis=[1, 2])\n",
    "        dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "        self.dice.assign(tf.reduce_mean(dice))\n",
    "\n",
    "    def result(self):\n",
    "        return self.dice\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"class_idx\": self.class_idx})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        if \"class_idx\" not in config:\n",
    "            # Try to extract class index from name like \"DiceClass2\"\n",
    "            name = config.get(\"name\", \"DiceClass0\")\n",
    "            if name.startswith(\"DiceClass\"):\n",
    "                config[\"class_idx\"] = int(name.replace(\"DiceClass\", \"\"))\n",
    "            else:\n",
    "                config[\"class_idx\"] = 0\n",
    "        return cls(**config)\n",
    "\n",
    "# ‚úÖ Helper to load Dice metrics by name\n",
    "def dice_metric_loader(name):\n",
    "    if name.startswith(\"DiceClass\"):\n",
    "        class_idx = int(name.replace(\"DiceClass\", \"\"))\n",
    "        return DiceCoefficient(class_idx=class_idx)\n",
    "    raise ValueError(f\"Unknown Dice metric name: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_wise_metrics(num_classes=4):\n",
    "    return [DiceCoefficient(i) for i in range(num_classes)] + [tf.keras.metrics.MeanIoU(num_classes=num_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_eval_loss(y_true, y_pred):\n",
    "    return [combined_loss(y_true, y_pred) + tf.keras.losses.CategoricalCrossentropy()(y_true, y_pred)]\n",
    "\n",
    "student_model.compile(\n",
    "    optimizer= tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
    "    loss=student_eval_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class ImageMaskGenerator(Sequence):\n",
    "    def __init__(self, image_paths, mask_paths, batch_size=4, num_classes=4, img_size=(224, 224), shuffle=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.image_paths))\n",
    "        self.CLASS_MAP = {\n",
    "            (255, 0, 0): 1,\n",
    "            (0, 255, 0): 2,\n",
    "            (0, 0, 255): 3,\n",
    "            (0, 0, 0): 0,\n",
    "        }\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_images = []\n",
    "        batch_masks = []\n",
    "\n",
    "        for i in batch_indices:\n",
    "            img = cv2.imread(self.image_paths[i])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, self.img_size)\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "\n",
    "            mask = cv2.imread(self.mask_paths[i])\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "            mask = cv2.resize(mask, self.img_size, interpolation=cv2.INTER_NEAREST)\n",
    "            mask = self.rgb_to_class(mask)\n",
    "            mask = tf.keras.utils.to_categorical(mask, num_classes=self.num_classes)\n",
    "\n",
    "            batch_images.append(img)\n",
    "            batch_masks.append(mask)\n",
    "\n",
    "        return np.array(batch_images), np.array(batch_masks)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def rgb_to_class(self, mask_array):\n",
    "        h, w, _ = mask_array.shape\n",
    "        class_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "        for rgb, class_idx in self.CLASS_MAP.items():\n",
    "            matches = np.all(mask_array == rgb, axis=-1)\n",
    "            class_mask[matches] = class_idx\n",
    "        return class_mask\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "def load_paths(image_dir, mask_dir):\n",
    "    images = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.png')])\n",
    "    masks = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith('.png')])\n",
    "    return images, masks\n",
    "\n",
    "train_imgs, train_masks = load_paths(train_image_dir, train_mask_dir)\n",
    "val_imgs, val_masks = load_paths(val_image_dir, val_mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageMaskGenerator(train_imgs, train_masks, batch_size=8)\n",
    "val_gen = ImageMaskGenerator(val_imgs, val_masks, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import gc\n",
    "import time\n",
    "\n",
    "# ‚úÖ Dice Coefficient Metric for Each Class\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_idx=0, name=None, **kwargs):\n",
    "        if name is None:\n",
    "            name = f\"DiceClass{class_idx}\"\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.class_idx = class_idx\n",
    "        self.dice = self.add_weight(name=\"dice\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_class = y_true[..., self.class_idx]\n",
    "        y_pred_class = y_pred[..., self.class_idx]\n",
    "        intersection = tf.reduce_sum(y_true_class * y_pred_class, axis=[1, 2])\n",
    "        union = tf.reduce_sum(y_true_class, axis=[1, 2]) + tf.reduce_sum(y_pred_class, axis=[1, 2])\n",
    "        dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "        self.dice.assign(tf.reduce_mean(dice))\n",
    "\n",
    "    def result(self):\n",
    "        return self.dice\n",
    "\n",
    "def class_wise_metrics(num_classes=4):\n",
    "    return [DiceCoefficient(i) for i in range(num_classes)] + [tf.keras.metrics.MeanIoU(num_classes=num_classes)]\n",
    "\n",
    "# ‚úÖ Your existing combined loss setup\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    return 1 - tf.reduce_mean((2. * intersection + smooth) / (union + smooth))\n",
    "\n",
    "def lovasz_softmax_loss(y_true, y_pred, ignore_background=False):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    num_classes = tf.shape(y_true)[-1]\n",
    "    start_class = 1 if ignore_background else 0\n",
    "\n",
    "    def compute_class_loss(c):\n",
    "        y_true_class = y_true[..., c]\n",
    "        y_pred_class = y_pred[..., c]\n",
    "        y_true_flat = tf.reshape(y_true_class, [-1])\n",
    "        y_pred_flat = tf.reshape(y_pred_class, [-1])\n",
    "        errors = tf.abs(y_true_flat - y_pred_flat)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], sorted=True)\n",
    "        y_true_sorted = tf.gather(y_true_flat, perm)\n",
    "        gts = tf.reduce_sum(y_true_sorted)\n",
    "        intersection = gts - tf.cumsum(y_true_sorted)\n",
    "        union = gts + tf.cumsum(1. - y_true_sorted)\n",
    "        jaccard = 1. - intersection / union\n",
    "        grad = tf.concat([[jaccard[0]], jaccard[1:] - jaccard[:-1]], 0)\n",
    "        return tf.tensordot(errors_sorted, grad, axes=1)\n",
    "\n",
    "    losses = tf.TensorArray(dtype=tf.float32, size=num_classes)\n",
    "    def loop_cond(c, _): return c < num_classes\n",
    "    def loop_body(c, losses): return c + 1, losses.write(c, compute_class_loss(c))\n",
    "    _, losses = tf.while_loop(loop_cond, loop_body, [start_class, losses])\n",
    "    return tf.reduce_mean(losses.stack())\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    lovasz = lovasz_softmax_loss(y_true, tf.nn.softmax(y_pred), ignore_background=False)\n",
    "    return dice + lovasz\n",
    "\n",
    "def student_eval_loss(y_true, y_pred):\n",
    "    return combined_loss(y_true, y_pred) + tf.keras.losses.CategoricalCrossentropy()(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_student_model(train_gen, val_gen, model_builder_fn, weights_path,\n",
    "                               batch_size=8, epochs=3, repeats=1):\n",
    "    epoch_times_all = []\n",
    "    power_samples_all = []\n",
    "\n",
    "    for r in range(repeats):\n",
    "        print(f\"\\nüîÅ Repeat {r+1}/{repeats}\")\n",
    "\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "        model = model_builder_fn()\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
    "            loss=student_eval_loss,\n",
    "            metrics=class_wise_metrics(num_classes=4)\n",
    "        )\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "        start = time.time()\n",
    "        power_proc = subprocess.Popen(\n",
    "            ['nvidia-smi', '--query-gpu=power.draw', '--format=csv,noheader,nounits', '-lms', '500'],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "            text=True\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=epochs,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        end = time.time()\n",
    "        total_time = end - start\n",
    "        avg_epoch_time = total_time / epochs\n",
    "        epoch_times_all.extend([avg_epoch_time] * epochs)\n",
    "\n",
    "        power_proc.terminate()\n",
    "        try:\n",
    "            power_output = power_proc.stdout.read().strip().split('\\n')\n",
    "            power_values = [float(line) for line in power_output if line.strip()]\n",
    "            avg_power = np.mean(power_values)\n",
    "            power_samples_all.extend([avg_power] * epochs)\n",
    "            print(f\"‚ö° Avg Power: {avg_power:.2f} W\")\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è Power log failed.\")\n",
    "            power_samples_all.extend([np.nan] * epochs)\n",
    "\n",
    "        del model\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "\n",
    "    return epoch_times_all, power_samples_all\n",
    "\n",
    "def build_student_model():\n",
    "    return UNetPlusPlus(input_shape=(224, 224, 3), num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "epoch_times, power_vals = run_training_student_model(\n",
    "    train_gen=train_gen,\n",
    "    val_gen=val_gen,\n",
    "    model_builder_fn=build_student_model,\n",
    "    weights_path=\"student_model_weights_final.h5\",\n",
    "    batch_size=8,\n",
    "    epochs=3,\n",
    "    repeats=1\n",
    ")\n",
    "\n",
    "mean_time = np.mean(epoch_times)\n",
    "mean_power = np.nanmean(power_vals)\n",
    "energy_wh = (mean_time * mean_power) / 3600\n",
    "\n",
    "print(\"\\nüìä Summary:\")\n",
    "print(f\"‚è±Ô∏è Avg time/epoch: {mean_time:.2f} s\")\n",
    "print(f\"‚ö° Avg GPU power: {mean_power:.2f} W\")\n",
    "print(f\"üîã Avg energy/epoch: {energy_wh:.4f} Wh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate GFLOPS per epoch (assuming 4 GFLOPs/sample)\n",
    "samples_per_epoch = len(X_train)\n",
    "estimated_flops_per_sample = 4e9  # 4 GFLOPs\n",
    "gflops = (2 * estimated_flops_per_sample * samples_per_epoch) / (mean_time * 1e9)\n",
    "print(f\"‚öôÔ∏è  Estimated GFLOPS: {gflops:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gflops(model, input_res=(224, 224, 3)):\n",
    "    from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "    import tensorflow as tf\n",
    "\n",
    "    # Create dummy input\n",
    "    input_shape = (1,) + input_res\n",
    "    inputs = tf.random.normal(input_shape)\n",
    "    \n",
    "    # Convert model to frozen graph\n",
    "    full_model = tf.function(lambda x: model(x))\n",
    "    full_model = full_model.get_concrete_function(tf.TensorSpec(input_shape, model.inputs[0].dtype))\n",
    "\n",
    "    frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "    graph_def = frozen_func.graph.as_graph_def()\n",
    "\n",
    "    # Calculate FLOPs using TF profiler\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "        flops = tf.compat.v1.profiler.profile(graph=graph,\n",
    "                                              run_meta=run_meta,\n",
    "                                              cmd='op',\n",
    "                                              options=opts)\n",
    "    gflops = flops.total_float_ops / 1e9\n",
    "    return gflops\n",
    "\n",
    "student_model = UNetPlusPlus(input_shape=(224, 224, 3), num_classes=4)\n",
    "gflops = calculate_gflops(student_model)\n",
    "print(f\"üìè Model GFLOPs: {gflops:.2f} GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Number of classes (adjust if needed)\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# ‚úÖ Dice Coefficient (Mean across all classes)\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Weighted Categorical Crossentropy\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    class_weights = tf.constant([0.3776, 0.7605, 65.8554, 46.2381], dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "    class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))\n",
    "    weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)\n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# ‚úÖ Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# ‚úÖ Lov√°sz-Softmax Loss\n",
    "def lovasz_softmax_loss(y_true, y_pred, ignore_background=False):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    num_classes = tf.shape(y_true)[-1]\n",
    "    start_class = tf.constant(1 if ignore_background else 0)\n",
    "\n",
    "    def compute_class_loss(c):\n",
    "        y_true_class = y_true[..., c]\n",
    "        y_pred_class = y_pred[..., c]\n",
    "\n",
    "        y_true_flat = tf.reshape(y_true_class, [-1])\n",
    "        y_pred_flat = tf.reshape(y_pred_class, [-1])\n",
    "\n",
    "        errors = tf.abs(y_true_flat - y_pred_flat)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], sorted=True)\n",
    "        y_true_sorted = tf.gather(y_true_flat, perm)\n",
    "\n",
    "        gts = tf.reduce_sum(y_true_sorted)\n",
    "        intersection = gts - tf.cumsum(y_true_sorted)\n",
    "        union = gts + tf.cumsum(1. - y_true_sorted)\n",
    "        jaccard = 1. - intersection / union\n",
    "        grad = tf.concat([[jaccard[0]], jaccard[1:] - jaccard[:-1]], 0)\n",
    "\n",
    "        return tf.tensordot(errors_sorted, grad, axes=1)\n",
    "\n",
    "    # Loop through classes using tf.while_loop\n",
    "    losses = tf.TensorArray(dtype=tf.float32, size=num_classes)\n",
    "\n",
    "    def loop_cond(c, losses):\n",
    "        return tf.less(c, num_classes)\n",
    "\n",
    "    def loop_body(c, losses):\n",
    "        loss_c = compute_class_loss(c)\n",
    "        losses = losses.write(c, loss_c)\n",
    "        return c + 1, losses\n",
    "\n",
    "    _, losses = tf.while_loop(loop_cond, loop_body, [start_class, losses])\n",
    "    return tf.reduce_mean(losses.stack())\n",
    "\n",
    "# ‚úÖ Combined Loss\n",
    "def combined_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice_loss_val = 1 - (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss_val = tf.reduce_mean(dice_loss_val)\n",
    "    \n",
    "    lovasz_loss_val = lovasz_softmax_loss(y_true, tf.nn.softmax(y_pred), ignore_background=False)\n",
    "    return lovasz_loss_val + dice_loss_val\n",
    "\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_idx=0, name=None, **kwargs):  # <- default class_idx=0 to avoid missing arg\n",
    "        if name is None:\n",
    "            name = f\"DiceClass{class_idx}\"\n",
    "        super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        self.class_idx = class_idx\n",
    "        self.dice = self.add_weight(name=\"dice\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_class = y_true[..., self.class_idx]\n",
    "        y_pred_class = y_pred[..., self.class_idx]\n",
    "        intersection = tf.reduce_sum(y_true_class * y_pred_class, axis=[1, 2])\n",
    "        union = tf.reduce_sum(y_true_class, axis=[1, 2]) + tf.reduce_sum(y_pred_class, axis=[1, 2])\n",
    "        dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "        self.dice.assign(tf.reduce_mean(dice))\n",
    "\n",
    "    def result(self):\n",
    "        return self.dice\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"class_idx\": self.class_idx})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        if \"class_idx\" not in config:\n",
    "            # Try to extract class index from name like \"DiceClass2\"\n",
    "            name = config.get(\"name\", \"DiceClass0\")\n",
    "            if name.startswith(\"DiceClass\"):\n",
    "                config[\"class_idx\"] = int(name.replace(\"DiceClass\", \"\"))\n",
    "            else:\n",
    "                config[\"class_idx\"] = 0\n",
    "        return cls(**config)\n",
    "\n",
    "# ‚úÖ Helper to load Dice metrics by name\n",
    "def dice_metric_loader(name):\n",
    "    if name.startswith(\"DiceClass\"):\n",
    "        class_idx = int(name.replace(\"DiceClass\", \"\"))\n",
    "        return DiceCoefficient(class_idx=class_idx)\n",
    "    raise ValueError(f\"Unknown Dice metric name: {name}\")\n",
    "\n",
    "# ‚úÖ Register all custom objects for loading the model\n",
    "custom_objects = {\n",
    "    'combined_loss': combined_loss,\n",
    "    'lovasz_softmax_loss': lovasz_softmax_loss,\n",
    "    'MeanIoU': tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES),\n",
    "    'DiceCoefficient': DiceCoefficient,\n",
    "}\n",
    "\n",
    "# ‚úÖ Add DiceClass0‚Äì3 dynamically\n",
    "for i in range(NUM_CLASSES):\n",
    "    custom_objects[f'DiceClass{i}'] = dice_metric_loader(f'DiceClass{i}')\n",
    "\n",
    "# ‚úÖ Load the model\n",
    "model_segnet = load_model('C:\\\\Users\\\\User\\\\best_unet_model_onlineDA_128_lovaszloss_segnet.keras', custom_objects=custom_objects)\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gflops(model, input_res=(224, 224, 3)):\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "    # Prepare input\n",
    "    inputs = tf.random.normal((1,) + input_res)\n",
    "\n",
    "    # Convert to ConcreteFunction\n",
    "    full_model = tf.function(lambda x: model(x))\n",
    "    full_model = full_model.get_concrete_function(tf.TensorSpec(inputs.shape, model.inputs[0].dtype))\n",
    "\n",
    "    # Freeze the model\n",
    "    frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "    graph_def = frozen_func.graph.as_graph_def()\n",
    "\n",
    "    # Calculate FLOPs using profiler\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "        flops = tf.compat.v1.profiler.profile(\n",
    "            graph=graph,\n",
    "            run_meta=run_meta,\n",
    "            cmd='op',\n",
    "            options=opts\n",
    "        )\n",
    "    \n",
    "    if flops is None:\n",
    "        raise ValueError(\"‚ùå Could not compute FLOPs. Check if the model contains unsupported ops.\")\n",
    "    \n",
    "    return flops.total_float_ops / 1e9  # Convert to GFLOPs\n",
    "\n",
    "gflops = calculate_gflops(model_segnet)\n",
    "print(f\"üìè Model GFLOPs: {gflops:.2f} GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, Concatenate, BatchNormalization, Activation\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "import gc\n",
    "\n",
    "# Constants\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "class ResizeLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"Custom layer to resize images.\"\"\"\n",
    "    def __init__(self, target_size, **kwargs):\n",
    "        super(ResizeLayer, self).__init__(**kwargs)\n",
    "        self.target_size = target_size\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.image.resize(inputs, self.target_size, method='bilinear')\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(ResizeLayer, self).get_config()\n",
    "        config.update({\"target_size\": self.target_size})\n",
    "        return config\n",
    "\n",
    "def conv_block(x, filters, kernel_size=3, padding='same', activation='relu'):\n",
    "    \"\"\"Helper function for creating a conv block with BN and activation.\"\"\"\n",
    "    x = Conv2D(filters, kernel_size, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    # Add a second conv to increase parameters\n",
    "    x = Conv2D(filters, kernel_size, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "def build_full_inceptionresnetv2_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), num_classes=NUM_CLASSES):\n",
    "    \"\"\"\n",
    "    Build a full UNet model with InceptionResNetV2 backbone with 60-70M parameters\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Input shape of the image\n",
    "        num_classes: Number of output classes\n",
    "        \n",
    "    Returns:\n",
    "        Keras Model instance with UNet architecture\n",
    "    \"\"\"\n",
    "    # Input layer (no fixed batch size)\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Create a full InceptionResNetV2 model to use as backbone\n",
    "    base_model = InceptionResNetV2(\n",
    "        input_tensor=inputs,\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling=None\n",
    "    )\n",
    "    \n",
    "    # Make all layers trainable as requested\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Extract features from all encoder levels\n",
    "    # Standard blocks in InceptionResNetV2\n",
    "    encoder1 = base_model.get_layer('activation').output  # 111x111x64\n",
    "    encoder2 = base_model.get_layer('activation_3').output  # 55x55x192\n",
    "    encoder3 = base_model.get_layer('block35_10_ac').output  # 27x27x320\n",
    "    encoder4 = base_model.get_layer('block17_20_ac').output  # 13x13x1088\n",
    "    encoder5 = base_model.get_layer('conv_7b_ac').output  # 6x6x2080\n",
    "    \n",
    "    # Use the bottleneck as is - don't reduce its channels\n",
    "    bottleneck = encoder5  # 6x6x2080\n",
    "    \n",
    "    # First, reduce the bottleneck dimensions to control parameter count\n",
    "    bottleneck = Conv2D(512, 1, padding='same')(bottleneck)\n",
    "    bottleneck = BatchNormalization()(bottleneck)\n",
    "    bottleneck = Activation('relu')(bottleneck)\n",
    "    \n",
    "    # Level 5 to 4: 6x6 -> 13x13\n",
    "    up4 = UpSampling2D(size=(2, 2))(bottleneck)\n",
    "    up4 = ResizeLayer(target_size=(encoder4.shape[1], encoder4.shape[2]))(up4)\n",
    "    up4 = conv_block(up4, 512, kernel_size=3)  # Reduced filters\n",
    "    \n",
    "    # Reduce skip connection channels before concatenation\n",
    "    skip4 = Conv2D(256, 1, padding='same')(encoder4)\n",
    "    skip4 = BatchNormalization()(skip4)\n",
    "    skip4 = Activation('relu')(skip4)\n",
    "    \n",
    "    # Concatenate with skip connection\n",
    "    merge4 = Concatenate()([up4, skip4])\n",
    "    merge4 = conv_block(merge4, 384)  # Reduced filters\n",
    "    \n",
    "    # Level 4 to 3: 13x13 -> 27x27\n",
    "    up3 = UpSampling2D(size=(2, 2))(merge4)\n",
    "    up3 = ResizeLayer(target_size=(encoder3.shape[1], encoder3.shape[2]))(up3)\n",
    "    up3 = conv_block(up3, 384, kernel_size=3)  # Reduced filters\n",
    "    \n",
    "    # Reduce skip connection channels\n",
    "    skip3 = Conv2D(128, 1, padding='same')(encoder3)\n",
    "    skip3 = BatchNormalization()(skip3)\n",
    "    skip3 = Activation('relu')(skip3)\n",
    "    \n",
    "    # Concatenate with skip connection\n",
    "    merge3 = Concatenate()([up3, skip3])\n",
    "    merge3 = conv_block(merge3, 192)  # Reduced filters\n",
    "    \n",
    "    # Level 3 to 2: 27x27 -> 55x55\n",
    "    up2 = UpSampling2D(size=(2, 2))(merge3)\n",
    "    up2 = ResizeLayer(target_size=(encoder2.shape[1], encoder2.shape[2]))(up2)\n",
    "    up2 = conv_block(up2, 192, kernel_size=3)  # Reduced filters\n",
    "    \n",
    "    # Reduce skip connection channels\n",
    "    skip2 = Conv2D(96, 1, padding='same')(encoder2)\n",
    "    skip2 = BatchNormalization()(skip2)\n",
    "    skip2 = Activation('relu')(skip2)\n",
    "    \n",
    "    # Concatenate with skip connection\n",
    "    merge2 = Concatenate()([up2, skip2])\n",
    "    merge2 = conv_block(merge2, 96)  # Reduced filters\n",
    "    \n",
    "    # Level 2 to 1: 55x55 -> 111x111\n",
    "    up1 = UpSampling2D(size=(2, 2))(merge2)\n",
    "    up1 = ResizeLayer(target_size=(encoder1.shape[1], encoder1.shape[2]))(up1)\n",
    "    up1 = conv_block(up1, 96, kernel_size=3)  # Reduced filters\n",
    "    \n",
    "    # Reduce skip connection channels\n",
    "    skip1 = Conv2D(48, 1, padding='same')(encoder1)\n",
    "    skip1 = BatchNormalization()(skip1)\n",
    "    skip1 = Activation('relu')(skip1)\n",
    "    \n",
    "    # Concatenate with skip connection\n",
    "    merge1 = Concatenate()([up1, skip1])\n",
    "    merge1 = conv_block(merge1, 48)  # Reduced filters\n",
    "    \n",
    "    # Final upsampling to original resolution: 111x111 -> 224x224\n",
    "    up_final = UpSampling2D(size=(2, 2))(merge1)\n",
    "    up_final = conv_block(up_final, 32)  # Reduced filters\n",
    "    \n",
    "    # Ensure final size matches input\n",
    "    if up_final.shape[1] != input_shape[0] or up_final.shape[2] != input_shape[1]:\n",
    "        up_final = ResizeLayer(target_size=(input_shape[0], input_shape[1]))(up_final)\n",
    "    \n",
    "    # Add a final segmentation head\n",
    "    outputs = Conv2D(num_classes, 1, activation='softmax', dtype='float32')(up_final)\n",
    "    \n",
    "    # Create and return the model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "print(\"Creating full InceptionResNetV2-UNet model...\")\n",
    "model = build_full_inceptionresnetv2_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), num_classes=NUM_CLASSES)\n",
    "print(\"Model created successfully!\")\n",
    "\n",
    "# Clear memory\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gflops(model, input_res=(224, 224, 3)):\n",
    "    from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "    import tensorflow as tf\n",
    "\n",
    "    # Create dummy input\n",
    "    input_shape = (1,) + input_res\n",
    "    inputs = tf.random.normal(input_shape)\n",
    "    \n",
    "    # Convert model to frozen graph\n",
    "    full_model = tf.function(lambda x: model(x))\n",
    "    full_model = full_model.get_concrete_function(tf.TensorSpec(input_shape, model.inputs[0].dtype))\n",
    "\n",
    "    frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "    graph_def = frozen_func.graph.as_graph_def()\n",
    "\n",
    "    # Calculate FLOPs using TF profiler\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "        flops = tf.compat.v1.profiler.profile(graph=graph,\n",
    "                                              run_meta=run_meta,\n",
    "                                              cmd='op',\n",
    "                                              options=opts)\n",
    "    gflops = flops.total_float_ops / 1e9\n",
    "    return gflops\n",
    "\n",
    "gflops = calculate_gflops(model)\n",
    "print(f\"üìè Model GFLOPs: {gflops:.2f} GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def measure_inference_speed(model, input_shape=(224, 224, 3), batch_size=1, num_runs=100):\n",
    "    dummy_input = np.random.rand(batch_size, *input_shape).astype(np.float32)\n",
    "\n",
    "    # Warm-up\n",
    "    for _ in range(10):\n",
    "        model.predict(dummy_input)\n",
    "\n",
    "    # Timed inference\n",
    "    start = time.time()\n",
    "    for _ in range(num_runs):\n",
    "        model.predict(dummy_input)\n",
    "    end = time.time()\n",
    "\n",
    "    total_time = end - start\n",
    "    avg_time_per_image = total_time / (num_runs * batch_size)\n",
    "    fps = 1.0 / avg_time_per_image\n",
    "    return avg_time_per_image * 1000, fps  # return in ms, FPS\n",
    "\n",
    "ms, fps = measure_inference_speed(model)\n",
    "print(f\"Inference Time: {ms:.2f} ms/image | FPS: {fps:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Add\n",
    "from tensorflow.keras.layers import Dense, Dropout, Layer, Reshape, Permute, Multiply, Concatenate\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, LayerNormalization, UpSampling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "\n",
    "class ResizeToMatchLayer(Layer):\n",
    "    \"\"\"Layer to resize input to match target tensor's spatial dimensions.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ResizeToMatchLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x, target = inputs\n",
    "        # Get spatial dimensions of target tensor\n",
    "        target_shape = tf.shape(target)\n",
    "        target_height, target_width = target_shape[1], target_shape[2]\n",
    "        \n",
    "        # Resize x to match target's spatial dimensions\n",
    "        return tf.image.resize(x, [target_height, target_width], method='bilinear')\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[1][1], input_shape[1][2], input_shape[0][3])\n",
    "\n",
    "def conv_block(x, filters, kernel_size=3, strides=1, padding='same', use_bn=True, activation='relu'):\n",
    "    \"\"\"Standard convolution block with BatchNorm and activation.\"\"\"\n",
    "    x = Conv2D(filters, kernel_size, strides=strides, padding=padding)(x)\n",
    "    \n",
    "    if use_bn:\n",
    "        x = BatchNormalization()(x)\n",
    "    \n",
    "    if activation:\n",
    "        x = Activation(activation)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def attention_gate(x, g, inter_channels):\n",
    "    \"\"\"\n",
    "    Attention Gate as described in Attention U-Net paper.\n",
    "    Args:\n",
    "        x: Feature map from skip connection (from encoder)\n",
    "        g: Gating signal from previous decoder layer\n",
    "        inter_channels: Number of channels in intermediate representations\n",
    "    \"\"\"\n",
    "    # Resize gating signal to match feature map's spatial dimensions if needed\n",
    "    g = ResizeToMatchLayer()([g, x])\n",
    "    \n",
    "    # Intermediate representation for input feature map\n",
    "    theta_x = Conv2D(inter_channels, 1, use_bias=False, padding='same')(x)\n",
    "    \n",
    "    # Intermediate representation for gating signal\n",
    "    phi_g = Conv2D(inter_channels, 1, use_bias=False, padding='same')(g)\n",
    "    \n",
    "    # Element-wise sum and ReLU\n",
    "    f = Activation('relu')(Add()([theta_x, phi_g]))\n",
    "    \n",
    "    # 1x1 convolution followed by sigmoid to get attention coefficients\n",
    "    psi_f = Conv2D(1, 1, use_bias=False, padding='same')(f)\n",
    "    att_map = Activation('sigmoid')(psi_f)\n",
    "    \n",
    "    # Apply attention\n",
    "    return Multiply()([x, att_map])\n",
    "\n",
    "def decoder_block(x, skip_connection, filters, use_attention=True):\n",
    "    \"\"\"Decoder block for Attention U-Net.\"\"\"\n",
    "    # Upsampling\n",
    "    x = UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "    \n",
    "    # Ensure dimensions match for concatenation\n",
    "    x = ResizeToMatchLayer()([x, skip_connection])\n",
    "    \n",
    "    # Apply attention mechanism if specified\n",
    "    if use_attention:\n",
    "        # Generate attention-gated skip connection\n",
    "        skip_connection = attention_gate(skip_connection, x, filters // 2)\n",
    "    \n",
    "    # Concatenate with skip connection\n",
    "    x = Concatenate()([x, skip_connection])\n",
    "    \n",
    "    # Apply two convolution blocks\n",
    "    x = conv_block(x, filters, 3, padding='same')\n",
    "    x = conv_block(x, filters, 3, padding='same')\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_efficientnet_attention_unet(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Build an Attention U-Net model with EfficientNetB4 backbone for semantic segmentation.\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Input shape of the image (height, width, channels)\n",
    "        num_classes: Number of segmentation classes\n",
    "        \n",
    "    Returns:\n",
    "        A Keras Model instance\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "        \n",
    "    # Load EfficientNetB4 with pre-trained weights as encoder backbone\n",
    "    # All layers are trainable for fine-tuning\n",
    "    base_model = EfficientNetB4(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_tensor=inputs\n",
    "    )\n",
    "    \n",
    "    # Reduce filter count to control parameter count since we're not freezing any layers\n",
    "    initial_filters = 32\n",
    "    \n",
    "    # Get skip connections from appropriate layers\n",
    "    skip1 = base_model.get_layer('block1b_add').output        # 1/2 scale (112x112)\n",
    "    skip2 = base_model.get_layer('block2d_add').output        # 1/4 scale (56x56)\n",
    "    skip3 = base_model.get_layer('block3d_add').output        # 1/8 scale (28x28)\n",
    "    skip4 = base_model.get_layer('block5e_add').output        # 1/16 scale (14x14)\n",
    "    \n",
    "    # Bridge (bottleneck)\n",
    "    bridge = base_model.get_layer('top_activation').output    # 1/32 scale (7x7)\n",
    "    \n",
    "    \n",
    "    # Reduce channels for each skip connection to control parameter count\n",
    "    skip1_conv = conv_block(skip1, initial_filters)\n",
    "    skip2_conv = conv_block(skip2, initial_filters * 2)\n",
    "    skip3_conv = conv_block(skip3, initial_filters * 4)\n",
    "    skip4_conv = conv_block(skip4, initial_filters * 8)\n",
    "    \n",
    "    # Reduce channels in bridge\n",
    "    bridge_conv = conv_block(bridge, initial_filters * 16)\n",
    "    \n",
    "    # Decoder pathway with attention gates\n",
    "    d1 = decoder_block(bridge_conv, skip4_conv, initial_filters * 8, use_attention=True)  # 1/16\n",
    "    d2 = decoder_block(d1, skip3_conv, initial_filters * 4, use_attention=True)           # 1/8\n",
    "    d3 = decoder_block(d2, skip2_conv, initial_filters * 2, use_attention=True)           # 1/4\n",
    "    d4 = decoder_block(d3, skip1_conv, initial_filters, use_attention=True)               # 1/2\n",
    "    \n",
    "    # Final upsampling to original image size\n",
    "    final = UpSampling2D(size=(2, 2), interpolation='bilinear')(d4)\n",
    "    \n",
    "    # Final convolution to generate segmentation map\n",
    "    outputs = Conv2D(num_classes, 1, padding='same', activation='softmax')(final)\n",
    "    \n",
    "    # Create and return the model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_efficientnet_attention_unet(input_shape=(224, 224, 3), num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gflops = calculate_gflops(model)\n",
    "print(f\"üìè Model GFLOPs: {gflops:.2f} GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "# Constants for 224x224 images\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "def convolution_block(inputs, filters, kernel_size=3, dilation_rate=1, padding='same', use_bias=False):\n",
    "    \"\"\"\n",
    "    Standard convolution block with batch normalization and ReLU activation\n",
    "    \"\"\"\n",
    "    x = layers.Conv2D(\n",
    "        filters, \n",
    "        kernel_size, \n",
    "        padding=padding,\n",
    "        dilation_rate=dilation_rate,\n",
    "        use_bias=use_bias\n",
    "    )(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def ASPP(inputs):\n",
    "    \"\"\"\n",
    "    Atrous Spatial Pyramid Pooling module for DeepLabV3+\n",
    "    \"\"\"\n",
    "    # ASPP with different dilation rates\n",
    "    b0 = convolution_block(inputs, 256, kernel_size=1, dilation_rate=1)\n",
    "    b1 = convolution_block(inputs, 256, kernel_size=3, dilation_rate=6)\n",
    "    b2 = convolution_block(inputs, 256, kernel_size=3, dilation_rate=12)\n",
    "    b3 = convolution_block(inputs, 256, kernel_size=3, dilation_rate=18)\n",
    "    \n",
    "    # Global context - simplified approach\n",
    "    b4 = layers.GlobalAveragePooling2D()(inputs)\n",
    "    b4 = layers.Reshape((1, 1, inputs.shape[-1]))(b4)\n",
    "    b4 = convolution_block(b4, 256, kernel_size=1)\n",
    "    # Use fixed upsampling instead of dynamic\n",
    "    b4 = layers.UpSampling2D(size=(inputs.shape[1], inputs.shape[2]))(b4)\n",
    "    \n",
    "    # Concatenate all branches\n",
    "    x = layers.Concatenate()([b0, b1, b2, b3, b4])\n",
    "    \n",
    "    # Final 1x1 convolution\n",
    "    output = convolution_block(x, 256, kernel_size=1)\n",
    "    return output\n",
    "\n",
    "def build_deeplabv3_plus_xception(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    DeepLabV3+ model with Xception backbone\n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Xception as backbone (with output stride of 16)\n",
    "    base_model = Xception(\n",
    "        input_tensor=inputs,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Don't freeze any layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Extract features from Xception\n",
    "    # The entry flow ends with 'block4_sepconv2_bn' which is a good low-level feature point\n",
    "    low_level_features = base_model.get_layer('block4_sepconv2_bn').output\n",
    "    # The final features from the exit flow\n",
    "    high_level_features = base_model.output\n",
    "    \n",
    "    # Process low-level features\n",
    "    low_level_features = convolution_block(low_level_features, 48, kernel_size=1)\n",
    "    \n",
    "    # Process high-level features with ASPP\n",
    "    x = ASPP(high_level_features)\n",
    "    \n",
    "    # Calculate upsampling factor for high-level features to match low-level features\n",
    "    hl_shape = high_level_features.shape\n",
    "    ll_shape = low_level_features.shape\n",
    "    h_factor = ll_shape[1] // hl_shape[1]\n",
    "    w_factor = ll_shape[2] // hl_shape[2]\n",
    "    \n",
    "    # Upsample high-level features to match low-level features\n",
    "    x = layers.UpSampling2D(size=(h_factor, w_factor), interpolation='bilinear')(x)\n",
    "    \n",
    "    # Concatenate features\n",
    "    x = layers.Concatenate()([x, low_level_features])\n",
    "    \n",
    "    # Apply convolution blocks\n",
    "    x = convolution_block(x, 256, kernel_size=3)\n",
    "    x = convolution_block(x, 256, kernel_size=3)\n",
    "    \n",
    "    # Calculate upsampling factor needed to reach 224x224\n",
    "    current_shape = x.shape\n",
    "    h_factor = IMG_HEIGHT // current_shape[1]\n",
    "    w_factor = IMG_WIDTH // current_shape[2]\n",
    "    \n",
    "    # Final upsampling to original size (224x224)\n",
    "    x = layers.UpSampling2D(size=(h_factor, w_factor), interpolation='bilinear')(x)\n",
    "    \n",
    "    # Ensure exact dimensions with a reshape if needed\n",
    "    x = layers.Reshape((IMG_HEIGHT, IMG_WIDTH, int(current_shape[3])))(x)\n",
    "    \n",
    "    # Final convolution for output (224, 224, 4)\n",
    "    outputs = layers.Conv2D(num_classes, kernel_size=1, padding='same', activation='softmax')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "model_xception = build_deeplabv3_plus_xception(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), \n",
    "                                     num_classes=NUM_CLASSES)\n",
    "\n",
    "gflops = calculate_gflops(model_xception)\n",
    "print(f\"üìè Model GFLOPs: {gflops:.2f} GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Define your data\n",
    "data = {\n",
    "    \"Model\": [\"Unet++(InceptionResNetV2)\", \"AttentionUnet(EfficientNetB4)\", \"Xception\", \"SegNet\", \"LightSeg\"],\n",
    "    \"Training Time (s)\": [190.62, 149.88, 102.30, 250.62, 164.84],\n",
    "    \"GFLOPs\": [34.78, 8.26, 17.15, 85.32, 18.89],\n",
    "    \"Energy (Wh)\": [5.56, 4.00, 3.28, 9.93, 5.51],\n",
    "    \"Params (M)\": [69.3, 29.7, 37.8, 31.4, 1.33],\n",
    "    \"Size (MB)\": [796, 114, 432, 359, 5.35]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# List of metrics to plot\n",
    "metrics = [\"Training Time (s)\", \"GFLOPs\", \"Energy (Wh)\", \"Params (M)\", \"Size (MB)\"]\n",
    "\n",
    "# Plot each metric\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x=\"Model\", y=metric, data=df, palette=\"coolwarm\")\n",
    "    plt.title(f\"Comparison of Models by {metric}\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.xticks(rotation=15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extracting data from the history object\n",
    "history_dict = history.history\n",
    "\n",
    "# Plotting the training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plotting loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_dict['loss'], label='Training Loss')\n",
    "plt.plot(history_dict['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# If accuracy is available, plot training and validation accuracy\n",
    "if 'accuracy' in history_dict:\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_dict['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history_dict['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Curves')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.evaluate(X_test, y_test, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.evaluate(X_test, y_test, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.spatial.distance as dist\n",
    "from scipy.ndimage import binary_erosion\n",
    "import psutil\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def check_memory():\n",
    "    \"\"\"Check available system memory\"\"\"\n",
    "    memory = psutil.virtual_memory()\n",
    "    logger.info(f\"Total RAM: {memory.total / (1024**3):.2f} GB\")\n",
    "    logger.info(f\"Available RAM: {memory.available / (1024**3):.2f} GB\")\n",
    "    logger.info(f\"Used RAM: {memory.used / (1024**3):.2f} GB\")\n",
    "    logger.info(f\"Memory percentage used: {memory.percent:.1f}%\")\n",
    "    return memory\n",
    "\n",
    "\n",
    "def get_boundary_points(mask):\n",
    "    \"\"\"Extract boundary points from a binary mask.\"\"\"\n",
    "    if not np.any(mask):\n",
    "        return np.empty((0, mask.ndim), dtype=int)\n",
    "    eroded = binary_erosion(mask)\n",
    "    boundary = mask & ~eroded\n",
    "    return np.argwhere(boundary)\n",
    "\n",
    "\n",
    "def compute_surface_distances_optimized(pred, true, max_points=1000):\n",
    "    \"\"\"\n",
    "    Memory-optimized surface distance calculation with systematic point sampling.\n",
    "    \"\"\"\n",
    "    pred = tf.cast(pred, tf.bool).numpy()\n",
    "    true = tf.cast(true, tf.bool).numpy()\n",
    "\n",
    "    pred_boundary = get_boundary_points(pred)\n",
    "    true_boundary = get_boundary_points(true)\n",
    "\n",
    "    if len(pred_boundary) == 0 or len(true_boundary) == 0:\n",
    "        if len(pred_boundary) == 0 and len(true_boundary) == 0:\n",
    "            return np.array([[0]]), np.array([[0]])\n",
    "        else:\n",
    "            return np.array([[np.inf]]), np.array([[np.inf]])\n",
    "\n",
    "    if len(pred_boundary) > max_points:\n",
    "        step = len(pred_boundary) // max_points\n",
    "        pred_boundary = pred_boundary[::step][:max_points]\n",
    "        logger.info(f\"Sampled pred boundary to {len(pred_boundary)}\")\n",
    "\n",
    "    if len(true_boundary) > max_points:\n",
    "        step = len(true_boundary) // max_points\n",
    "        true_boundary = true_boundary[::step][:max_points]\n",
    "        logger.info(f\"Sampled true boundary to {len(true_boundary)}\")\n",
    "\n",
    "    estimated_memory_gb = (len(pred_boundary) * len(true_boundary) * 8) / (1024**3)\n",
    "    logger.info(f\"Estimated memory needed: {estimated_memory_gb:.2f} GB\")\n",
    "\n",
    "    if estimated_memory_gb > 2.0:\n",
    "        return compute_distances_chunked(pred_boundary, true_boundary)\n",
    "    else:\n",
    "        dist_pred_to_true = dist.cdist(pred_boundary, true_boundary, 'euclidean')\n",
    "        dist_true_to_pred = dist.cdist(true_boundary, pred_boundary, 'euclidean')\n",
    "        return dist_pred_to_true, dist_true_to_pred\n",
    "\n",
    "\n",
    "def compute_distances_chunked(pred_boundary, true_boundary, chunk_size=500):\n",
    "    \"\"\"\n",
    "    Compute distances in chunks to avoid memory issues.\n",
    "    \"\"\"\n",
    "    logger.info(\"Using chunked distance computation...\")\n",
    "    min_pred_to_true = np.full(len(pred_boundary), np.inf)\n",
    "    min_true_to_pred = np.full(len(true_boundary), np.inf)\n",
    "\n",
    "    for i in range(0, len(pred_boundary), chunk_size):\n",
    "        chunk_pred = pred_boundary[i:i + chunk_size]\n",
    "        chunk_dist = dist.cdist(chunk_pred, true_boundary, 'euclidean')\n",
    "        min_pred_to_true[i:i + chunk_size] = np.min(chunk_dist, axis=1)\n",
    "        del chunk_dist\n",
    "        gc.collect()\n",
    "\n",
    "    for j in range(0, len(true_boundary), chunk_size):\n",
    "        chunk_true = true_boundary[j:j + chunk_size]\n",
    "        chunk_dist = dist.cdist(chunk_true, pred_boundary, 'euclidean')\n",
    "        min_true_to_pred[j:j + chunk_size] = np.min(chunk_dist, axis=1)\n",
    "        del chunk_dist\n",
    "        gc.collect()\n",
    "\n",
    "    return min_pred_to_true.reshape(-1, 1), min_true_to_pred.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def hausdorff_distance_95(dist_pred_to_true, dist_true_to_pred):\n",
    "    if dist_pred_to_true.size == 0 or dist_true_to_pred.size == 0:\n",
    "        return np.inf\n",
    "    pred_to_true_95 = np.percentile(np.min(dist_pred_to_true, axis=1), 95)\n",
    "    true_to_pred_95 = np.percentile(np.min(dist_true_to_pred, axis=1), 95)\n",
    "    return max(pred_to_true_95, true_to_pred_95)\n",
    "\n",
    "def average_symmetric_surface_distance_optimized(dist_pred_to_true, dist_true_to_pred):\n",
    "    if dist_pred_to_true.size == 0 or dist_true_to_pred.size == 0:\n",
    "        return np.inf\n",
    "    return (np.mean(np.min(dist_pred_to_true, axis=1)) + np.mean(np.min(dist_true_to_pred, axis=1))) / 2\n",
    "\n",
    "\n",
    "def calculate_hd_asd_combined_mask(model, x_test, y_test, batch_size=8, max_boundary_points=1000, foreground_class_indices=[1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Compute HD and ASD for combined foreground mask (e.g., brain/tumor/all relevant classes).\n",
    "    Matches style of FetSAM evaluation.\n",
    "    \"\"\"\n",
    "    logger.info(\"Running combined-mask HD/ASD computation...\")\n",
    "    check_memory()\n",
    "    \n",
    "    all_hd = []\n",
    "    all_asd = []\n",
    "\n",
    "    # Predict in batches\n",
    "    y_preds = model.predict(x_test, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    for i in range(len(y_preds)):\n",
    "        y_pred = y_preds[i]\n",
    "        y_true = y_test[i]\n",
    "\n",
    "        # Convert softmax outputs to class predictions\n",
    "        y_pred_labels = np.argmax(y_pred, axis=-1)  # shape: (H, W)\n",
    "        y_true_labels = np.argmax(y_true, axis=-1)  # shape: (H, W)\n",
    "\n",
    "        # Combine specified foreground classes into one binary mask\n",
    "        y_pred_binary = np.isin(y_pred_labels, foreground_class_indices).astype(bool)\n",
    "        y_true_binary = np.isin(y_true_labels, foreground_class_indices).astype(bool)\n",
    "\n",
    "        # Compute surface distances\n",
    "        dist_pred_to_true, dist_true_to_pred = compute_surface_distances_optimized(\n",
    "            y_pred_binary, y_true_binary, max_boundary_points\n",
    "        )\n",
    "\n",
    "        # Compute HD and ASD\n",
    "        hd = hausdorff_distance_optimized(dist_pred_to_true, dist_true_to_pred)\n",
    "        asd = average_symmetric_surface_distance_optimized(dist_pred_to_true, dist_true_to_pred)\n",
    "\n",
    "        if not np.isinf(hd) and not np.isinf(asd):\n",
    "            all_hd.append(hd)\n",
    "            all_asd.append(asd)\n",
    "            logger.info(f\"Sample {i}: HD = {hd:.4f}, ASD = {asd:.4f}\")\n",
    "        else:\n",
    "            logger.warning(f\"Skipping sample {i} due to empty masks\")\n",
    "\n",
    "        del dist_pred_to_true, dist_true_to_pred\n",
    "        gc.collect()\n",
    "\n",
    "    if not all_hd:\n",
    "        logger.error(\"No valid samples for HD/ASD calculation\")\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    mean_hd = np.mean(all_hd)\n",
    "    mean_asd = np.mean(all_asd)\n",
    "\n",
    "    return mean_hd, mean_asd\n",
    "\n",
    "# For a combined mask of classes 1, 2, 3 (e.g. whole fetal head):\n",
    "mean_hd, mean_asd = calculate_hd_asd_combined_mask(student_model, X_test, y_test, batch_size=8)\n",
    "\n",
    "print(f\"Combined HD: {mean_hd:.4f}\")\n",
    "print(f\"Combined ASD: {mean_asd:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.spatial.distance as dist\n",
    "from scipy.ndimage import binary_erosion\n",
    "import psutil\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "# Setup logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def check_memory():\n",
    "    \"\"\"Check and log system memory.\"\"\"\n",
    "    memory = psutil.virtual_memory()\n",
    "    logger.info(f\"Total RAM: {memory.total / (1024**3):.2f} GB\")\n",
    "    logger.info(f\"Available RAM: {memory.available / (1024**3):.2f} GB\")\n",
    "    logger.info(f\"Used RAM: {memory.used / (1024**3):.2f} GB\")\n",
    "    logger.info(f\"Memory usage: {memory.percent:.1f}%\")\n",
    "    return memory\n",
    "\n",
    "\n",
    "def get_boundary_points(mask):\n",
    "    \"\"\"Extract boundary points from a binary mask.\"\"\"\n",
    "    if not np.any(mask):\n",
    "        return np.empty((0, mask.ndim), dtype=int)\n",
    "    eroded = binary_erosion(mask)\n",
    "    boundary = mask & ~eroded\n",
    "    return np.argwhere(boundary)\n",
    "\n",
    "\n",
    "def compute_distances_chunked(pred_boundary, true_boundary, chunk_size=500):\n",
    "    \"\"\"Compute surface distances in memory-safe chunks.\"\"\"\n",
    "    min_pred_to_true = np.full(len(pred_boundary), np.inf)\n",
    "    min_true_to_pred = np.full(len(true_boundary), np.inf)\n",
    "\n",
    "    for i in range(0, len(pred_boundary), chunk_size):\n",
    "        chunk_pred = pred_boundary[i:i + chunk_size]\n",
    "        dists = dist.cdist(chunk_pred, true_boundary, 'euclidean')\n",
    "        min_pred_to_true[i:i + chunk_size] = np.min(dists, axis=1)\n",
    "        del dists\n",
    "        gc.collect()\n",
    "\n",
    "    for j in range(0, len(true_boundary), chunk_size):\n",
    "        chunk_true = true_boundary[j:j + chunk_size]\n",
    "        dists = dist.cdist(chunk_true, pred_boundary, 'euclidean')\n",
    "        min_true_to_pred[j:j + chunk_size] = np.min(dists, axis=1)\n",
    "        del dists\n",
    "        gc.collect()\n",
    "\n",
    "    return min_pred_to_true.reshape(-1, 1), min_true_to_pred.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def compute_surface_distances_optimized(pred, true, max_points=1000):\n",
    "    \"\"\"Efficient surface distance computation using boundary sampling.\"\"\"\n",
    "    pred = tf.cast(pred, tf.bool).numpy()\n",
    "    true = tf.cast(true, tf.bool).numpy()\n",
    "\n",
    "    pred_boundary = get_boundary_points(pred)\n",
    "    true_boundary = get_boundary_points(true)\n",
    "\n",
    "    if len(pred_boundary) == 0 or len(true_boundary) == 0:\n",
    "        if len(pred_boundary) == 0 and len(true_boundary) == 0:\n",
    "            return np.array([[0]]), np.array([[0]])\n",
    "        return np.array([[np.inf]]), np.array([[np.inf]])\n",
    "\n",
    "    if len(pred_boundary) > max_points:\n",
    "        step = len(pred_boundary) // max_points\n",
    "        pred_boundary = pred_boundary[::step][:max_points]\n",
    "\n",
    "    if len(true_boundary) > max_points:\n",
    "        step = len(true_boundary) // max_points\n",
    "        true_boundary = true_boundary[::step][:max_points]\n",
    "\n",
    "    est_mem_gb = (len(pred_boundary) * len(true_boundary) * 8) / (1024**3)\n",
    "    if est_mem_gb > 2.0:\n",
    "        return compute_distances_chunked(pred_boundary, true_boundary)\n",
    "\n",
    "    dptt = dist.cdist(pred_boundary, true_boundary, 'euclidean')\n",
    "    dttp = dist.cdist(true_boundary, pred_boundary, 'euclidean')\n",
    "    return dptt, dttp\n",
    "\n",
    "\n",
    "def hausdorff_distance_95(dist_pred_to_true, dist_true_to_pred):\n",
    "    \"\"\"Compute the 95th percentile Hausdorff Distance.\"\"\"\n",
    "    if dist_pred_to_true.size == 0 or dist_true_to_pred.size == 0:\n",
    "        return np.inf\n",
    "    pred_to_true_95 = np.percentile(np.min(dist_pred_to_true, axis=1), 95)\n",
    "    true_to_pred_95 = np.percentile(np.min(dist_true_to_pred, axis=1), 95)\n",
    "    return max(pred_to_true_95, true_to_pred_95)\n",
    "\n",
    "\n",
    "def average_symmetric_surface_distance(dist_pred_to_true, dist_true_to_pred):\n",
    "    \"\"\"Compute ASD (Average Symmetric Surface Distance).\"\"\"\n",
    "    if dist_pred_to_true.size == 0 or dist_true_to_pred.size == 0:\n",
    "        return np.inf\n",
    "    return (np.mean(np.min(dist_pred_to_true, axis=1)) + np.mean(np.min(dist_true_to_pred, axis=1))) / 2\n",
    "\n",
    "\n",
    "def calculate_hd95_asd_combined_mask(model, x_test, y_test, batch_size=8, max_boundary_points=1000, foreground_class_indices=[1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Compute HD95 and ASD over combined foreground (e.g., brain, CSP, LV).\n",
    "    Reviewer-compliant: accurate, interpretable, consistent with medical benchmarks.\n",
    "    \"\"\"\n",
    "    logger.info(\"üîç Starting combined-mask HD95 + ASD evaluation\")\n",
    "    check_memory()\n",
    "\n",
    "    all_hd95 = []\n",
    "    all_asd = []\n",
    "\n",
    "    y_preds = model.predict(x_test, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    for i in range(len(y_preds)):\n",
    "        y_pred = y_preds[i]\n",
    "        y_true = y_test[i]\n",
    "\n",
    "        # Convert softmax outputs to class labels\n",
    "        y_pred_labels = np.argmax(y_pred, axis=-1)\n",
    "        y_true_labels = np.argmax(y_true, axis=-1)\n",
    "\n",
    "        # Create combined foreground binary masks\n",
    "        y_pred_binary = np.isin(y_pred_labels, foreground_class_indices)\n",
    "        y_true_binary = np.isin(y_true_labels, foreground_class_indices)\n",
    "\n",
    "        # Compute distances\n",
    "        dist_pred_to_true, dist_true_to_pred = compute_surface_distances_optimized(\n",
    "            y_pred_binary, y_true_binary, max_boundary_points\n",
    "        )\n",
    "\n",
    "        hd95 = hausdorff_distance_95(dist_pred_to_true, dist_true_to_pred)\n",
    "        asd = average_symmetric_surface_distance(dist_pred_to_true, dist_true_to_pred)\n",
    "\n",
    "        if not np.isinf(hd95) and not np.isinf(asd):\n",
    "            all_hd95.append(hd95)\n",
    "            all_asd.append(asd)\n",
    "            logger.info(f\"Sample {i:03d} | HD95 = {hd95:.2f} | ASD = {asd:.2f}\")\n",
    "        else:\n",
    "            logger.warning(f\"‚ö†Ô∏è Sample {i} skipped due to empty mask\")\n",
    "\n",
    "        del dist_pred_to_true, dist_true_to_pred\n",
    "        gc.collect()\n",
    "\n",
    "    if len(all_hd95) == 0:\n",
    "        logger.error(\"‚ùå No valid samples for HD95/ASD computation.\")\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    # Summary stats\n",
    "    mean_hd95 = np.mean(all_hd95)\n",
    "    median_hd95 = np.median(all_hd95)\n",
    "    mean_asd = np.mean(all_asd)\n",
    "\n",
    "    logger.info(\"\\nüìä Final Evaluation Results:\")\n",
    "    logger.info(f\"Mean HD95: {mean_hd95:.4f}\")\n",
    "    logger.info(f\"Median HD95: {median_hd95:.4f}\")\n",
    "    logger.info(f\"Mean ASD: {mean_asd:.4f}\")\n",
    "\n",
    "    return mean_hd95, mean_asd\n",
    "\n",
    "mean_hd95, mean_asd = calculate_hd95_asd_combined_mask(\n",
    "    model=student_model,\n",
    "    x_test=X_test,\n",
    "    y_test=y_test,\n",
    "    batch_size=8,\n",
    "    foreground_class_indices=[1, 2, 3]  # Brain + CSP + LV\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Combined HD95: {mean_hd95:.4f}\")\n",
    "print(f\"‚úÖ Combined ASD:  {mean_asd:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.spatial.distance as dist\n",
    "from scipy.ndimage import binary_erosion\n",
    "import psutil\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "# Setup logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def check_memory():\n",
    "    \"\"\"Check and log system memory.\"\"\"\n",
    "    memory = psutil.virtual_memory()\n",
    "    logger.info(f\"Total RAM: {memory.total / (1024**3):.2f} GB\")\n",
    "    logger.info(f\"Available RAM: {memory.available / (1024**3):.2f} GB\")\n",
    "    logger.info(f\"Used RAM: {memory.used / (1024**3):.2f} GB\")\n",
    "    logger.info(f\"Memory usage: {memory.percent:.1f}%\")\n",
    "    return memory\n",
    "\n",
    "\n",
    "def get_boundary_points(mask):\n",
    "    \"\"\"Extract boundary points from a binary mask.\"\"\"\n",
    "    if not np.any(mask):\n",
    "        return np.empty((0, mask.ndim), dtype=int)\n",
    "    eroded = binary_erosion(mask)\n",
    "    boundary = mask & ~eroded\n",
    "    return np.argwhere(boundary)\n",
    "\n",
    "\n",
    "def compute_distances_chunked(pred_boundary, true_boundary, chunk_size=500):\n",
    "    \"\"\"Compute surface distances in memory-safe chunks.\"\"\"\n",
    "    min_pred_to_true = np.full(len(pred_boundary), np.inf)\n",
    "    min_true_to_pred = np.full(len(true_boundary), np.inf)\n",
    "\n",
    "    for i in range(0, len(pred_boundary), chunk_size):\n",
    "        chunk_pred = pred_boundary[i:i + chunk_size]\n",
    "        dists = dist.cdist(chunk_pred, true_boundary, 'euclidean')\n",
    "        min_pred_to_true[i:i + chunk_size] = np.min(dists, axis=1)\n",
    "        del dists\n",
    "        gc.collect()\n",
    "\n",
    "    for j in range(0, len(true_boundary), chunk_size):\n",
    "        chunk_true = true_boundary[j:j + chunk_size]\n",
    "        dists = dist.cdist(chunk_true, pred_boundary, 'euclidean')\n",
    "        min_true_to_pred[j:j + chunk_size] = np.min(dists, axis=1)\n",
    "        del dists\n",
    "        gc.collect()\n",
    "\n",
    "    return min_pred_to_true.reshape(-1, 1), min_true_to_pred.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def compute_surface_distances_optimized(pred, true, max_points=1000):\n",
    "    \"\"\"Efficient surface distance computation using boundary sampling.\"\"\"\n",
    "    pred = tf.cast(pred, tf.bool).numpy()\n",
    "    true = tf.cast(true, tf.bool).numpy()\n",
    "\n",
    "    pred_boundary = get_boundary_points(pred)\n",
    "    true_boundary = get_boundary_points(true)\n",
    "\n",
    "    if len(pred_boundary) == 0 or len(true_boundary) == 0:\n",
    "        if len(pred_boundary) == 0 and len(true_boundary) == 0:\n",
    "            return np.array([[0]]), np.array([[0]])\n",
    "        return np.array([[np.inf]]), np.array([[np.inf]])\n",
    "\n",
    "    if len(pred_boundary) > max_points:\n",
    "        step = len(pred_boundary) // max_points\n",
    "        pred_boundary = pred_boundary[::step][:max_points]\n",
    "\n",
    "    if len(true_boundary) > max_points:\n",
    "        step = len(true_boundary) // max_points\n",
    "        true_boundary = true_boundary[::step][:max_points]\n",
    "\n",
    "    est_mem_gb = (len(pred_boundary) * len(true_boundary) * 8) / (1024**3)\n",
    "    if est_mem_gb > 2.0:\n",
    "        return compute_distances_chunked(pred_boundary, true_boundary)\n",
    "\n",
    "    dptt = dist.cdist(pred_boundary, true_boundary, 'euclidean')\n",
    "    dttp = dist.cdist(true_boundary, pred_boundary, 'euclidean')\n",
    "    return dptt, dttp\n",
    "\n",
    "\n",
    "def hausdorff_distance_95(dist_pred_to_true, dist_true_to_pred):\n",
    "    \"\"\"Compute the 95th percentile Hausdorff Distance.\"\"\"\n",
    "    if dist_pred_to_true.size == 0 or dist_true_to_pred.size == 0:\n",
    "        return np.inf\n",
    "    pred_to_true_95 = np.percentile(np.min(dist_pred_to_true, axis=1), 95)\n",
    "    true_to_pred_95 = np.percentile(np.min(dist_true_to_pred, axis=1), 95)\n",
    "    return max(pred_to_true_95, true_to_pred_95)\n",
    "\n",
    "\n",
    "def average_symmetric_surface_distance(dist_pred_to_true, dist_true_to_pred):\n",
    "    \"\"\"Compute ASD (Average Symmetric Surface Distance).\"\"\"\n",
    "    if dist_pred_to_true.size == 0 or dist_true_to_pred.size == 0:\n",
    "        return np.inf\n",
    "    return (np.mean(np.min(dist_pred_to_true, axis=1)) + np.mean(np.min(dist_true_to_pred, axis=1))) / 2\n",
    "\n",
    "\n",
    "def calculate_hd95_asd_combined_mask(model, x_test, y_test, batch_size=8, max_boundary_points=1000, foreground_class_indices=[1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Compute HD95 and ASD over combined foreground (e.g., brain, CSP, LV).\n",
    "    Reviewer-compliant: accurate, interpretable, consistent with medical benchmarks.\n",
    "    \"\"\"\n",
    "    logger.info(\"üîç Starting combined-mask HD95 + ASD evaluation\")\n",
    "    check_memory()\n",
    "\n",
    "    all_hd95 = []\n",
    "    all_asd = []\n",
    "\n",
    "    y_preds = model.predict(x_test, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    for i in range(len(y_preds)):\n",
    "        y_pred = y_preds[i]\n",
    "        y_true = y_test[i]\n",
    "\n",
    "        # Convert softmax outputs to class labels\n",
    "        y_pred_labels = np.argmax(y_pred, axis=-1)\n",
    "        y_true_labels = np.argmax(y_true, axis=-1)\n",
    "\n",
    "        # Create combined foreground binary masks\n",
    "        y_pred_binary = np.isin(y_pred_labels, foreground_class_indices)\n",
    "        y_true_binary = np.isin(y_true_labels, foreground_class_indices)\n",
    "\n",
    "        # Compute distances\n",
    "        dist_pred_to_true, dist_true_to_pred = compute_surface_distances_optimized(\n",
    "            y_pred_binary, y_true_binary, max_boundary_points\n",
    "        )\n",
    "\n",
    "        hd95 = hausdorff_distance_95(dist_pred_to_true, dist_true_to_pred)\n",
    "        asd = average_symmetric_surface_distance(dist_pred_to_true, dist_true_to_pred)\n",
    "\n",
    "        if not np.isinf(hd95) and not np.isinf(asd):\n",
    "            all_hd95.append(hd95)\n",
    "            all_asd.append(asd)\n",
    "            logger.info(f\"Sample {i:03d} | HD95 = {hd95:.2f} | ASD = {asd:.2f}\")\n",
    "        else:\n",
    "            logger.warning(f\"‚ö†Ô∏è Sample {i} skipped due to empty mask\")\n",
    "\n",
    "        del dist_pred_to_true, dist_true_to_pred\n",
    "        gc.collect()\n",
    "\n",
    "    if len(all_hd95) == 0:\n",
    "        logger.error(\"‚ùå No valid samples for HD95/ASD computation.\")\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    # Summary stats\n",
    "    mean_hd95 = np.mean(all_hd95)\n",
    "    median_hd95 = np.median(all_hd95)\n",
    "    mean_asd = np.mean(all_asd)\n",
    "\n",
    "    logger.info(\"\\nüìä Final Evaluation Results:\")\n",
    "    logger.info(f\"Mean HD95: {mean_hd95:.4f}\")\n",
    "    logger.info(f\"Median HD95: {median_hd95:.4f}\")\n",
    "    logger.info(f\"Mean ASD: {mean_asd:.4f}\")\n",
    "\n",
    "    return mean_hd95, mean_asd\n",
    "\n",
    "mean_hd95, mean_asd = calculate_hd95_asd_combined_mask(\n",
    "    model=model_xception,\n",
    "    x_test=X_test,\n",
    "    y_test=y_test,\n",
    "    batch_size=16,\n",
    "    foreground_class_indices=[1, 2, 3]  # Brain + CSP + LV\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Combined HD95: {mean_hd95:.4f}\")\n",
    "print(f\"‚úÖ Combined ASD:  {mean_asd:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.spatial.distance as dist\n",
    "from scipy.ndimage import binary_erosion\n",
    "import psutil\n",
    "import gc\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def check_memory():\n",
    "    memory = psutil.virtual_memory()\n",
    "    logger.info(f\"Total RAM: {memory.total / (1024**3):.2f} GB\")\n",
    "    logger.info(f\"Available RAM: {memory.available / (1024**3):.2f} GB\")\n",
    "    logger.info(f\"Used RAM: {memory.used / (1024**3):.2f} GB\")\n",
    "    logger.info(f\"Memory usage: {memory.percent:.1f}%\")\n",
    "    return memory\n",
    "\n",
    "def get_boundary_points(mask):\n",
    "    if not np.any(mask):\n",
    "        return np.empty((0, mask.ndim), dtype=int)\n",
    "    eroded = binary_erosion(mask)\n",
    "    boundary = mask & ~eroded\n",
    "    return np.argwhere(boundary)\n",
    "\n",
    "def compute_distances_chunked(pred_boundary, true_boundary, chunk_size=500):\n",
    "    min_pred_to_true = np.full(len(pred_boundary), np.inf)\n",
    "    min_true_to_pred = np.full(len(true_boundary), np.inf)\n",
    "\n",
    "    for i in range(0, len(pred_boundary), chunk_size):\n",
    "        chunk_pred = pred_boundary[i:i + chunk_size]\n",
    "        dists = dist.cdist(chunk_pred, true_boundary, 'euclidean')\n",
    "        min_pred_to_true[i:i + chunk_size] = np.min(dists, axis=1)\n",
    "        del dists\n",
    "        gc.collect()\n",
    "\n",
    "    for j in range(0, len(true_boundary), chunk_size):\n",
    "        chunk_true = true_boundary[j:j + chunk_size]\n",
    "        dists = dist.cdist(chunk_true, pred_boundary, 'euclidean')\n",
    "        min_true_to_pred[j:j + chunk_size] = np.min(dists, axis=1)\n",
    "        del dists\n",
    "        gc.collect()\n",
    "\n",
    "    return min_pred_to_true.reshape(-1, 1), min_true_to_pred.reshape(-1, 1)\n",
    "\n",
    "def compute_surface_distances_optimized(pred, true, max_points=1000):\n",
    "    pred = tf.cast(pred, tf.bool).numpy()\n",
    "    true = tf.cast(true, tf.bool).numpy()\n",
    "\n",
    "    pred_boundary = get_boundary_points(pred)\n",
    "    true_boundary = get_boundary_points(true)\n",
    "\n",
    "    if len(pred_boundary) == 0 or len(true_boundary) == 0:\n",
    "        if len(pred_boundary) == 0 and len(true_boundary) == 0:\n",
    "            return np.array([[0]]), np.array([[0]])\n",
    "        return np.array([[np.inf]]), np.array([[np.inf]])\n",
    "\n",
    "    if len(pred_boundary) > max_points:\n",
    "        step = len(pred_boundary) // max_points\n",
    "        pred_boundary = pred_boundary[::step][:max_points]\n",
    "\n",
    "    if len(true_boundary) > max_points:\n",
    "        step = len(true_boundary) // max_points\n",
    "        true_boundary = true_boundary[::step][:max_points]\n",
    "\n",
    "    est_mem_gb = (len(pred_boundary) * len(true_boundary) * 8) / (1024**3)\n",
    "    if est_mem_gb > 2.0:\n",
    "        return compute_distances_chunked(pred_boundary, true_boundary)\n",
    "\n",
    "    dptt = dist.cdist(pred_boundary, true_boundary, 'euclidean')\n",
    "    dttp = dist.cdist(true_boundary, pred_boundary, 'euclidean')\n",
    "    return dptt, dttp\n",
    "\n",
    "def hausdorff_distance_95(dist_pred_to_true, dist_true_to_pred):\n",
    "    if dist_pred_to_true.size == 0 or dist_true_to_pred.size == 0:\n",
    "        return np.inf\n",
    "    pred_to_true_95 = np.percentile(np.min(dist_pred_to_true, axis=1), 95)\n",
    "    true_to_pred_95 = np.percentile(np.min(dist_true_to_pred, axis=1), 95)\n",
    "    return max(pred_to_true_95, true_to_pred_95)\n",
    "\n",
    "def average_symmetric_surface_distance(dist_pred_to_true, dist_true_to_pred):\n",
    "    if dist_pred_to_true.size == 0 or dist_true_to_pred.size == 0:\n",
    "        return np.inf\n",
    "    return (np.mean(np.min(dist_pred_to_true, axis=1)) + np.mean(np.min(dist_true_to_pred, axis=1))) / 2\n",
    "\n",
    "\n",
    "# ‚úÖ Storage for visualization\n",
    "worst_hd95_results = []\n",
    "\n",
    "def calculate_hd95_asd_combined_mask(model, x_test, y_test, batch_size=8, max_boundary_points=1000, foreground_class_indices=[1, 2, 3]):\n",
    "    logger.info(\"üîç Starting combined-mask HD95 + ASD evaluation\")\n",
    "    check_memory()\n",
    "\n",
    "    all_hd95 = []\n",
    "    all_asd = []\n",
    "\n",
    "    y_preds = model.predict(x_test, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    for i in range(len(y_preds)):\n",
    "        y_pred = y_preds[i]\n",
    "        y_true = y_test[i]\n",
    "\n",
    "        y_pred_labels = np.argmax(y_pred, axis=-1)\n",
    "        y_true_labels = np.argmax(y_true, axis=-1)\n",
    "\n",
    "        y_pred_binary = np.isin(y_pred_labels, foreground_class_indices)\n",
    "        y_true_binary = np.isin(y_true_labels, foreground_class_indices)\n",
    "\n",
    "        dist_pred_to_true, dist_true_to_pred = compute_surface_distances_optimized(\n",
    "            y_pred_binary, y_true_binary, max_boundary_points\n",
    "        )\n",
    "\n",
    "        hd95 = hausdorff_distance_95(dist_pred_to_true, dist_true_to_pred)\n",
    "        asd = average_symmetric_surface_distance(dist_pred_to_true, dist_true_to_pred)\n",
    "\n",
    "        if not np.isinf(hd95) and not np.isinf(asd):\n",
    "            all_hd95.append(hd95)\n",
    "            all_asd.append(asd)\n",
    "            worst_hd95_results.append((i, hd95, y_pred_labels, y_true_labels))  # Save for plotting\n",
    "            logger.info(f\"Sample {i:03d} | HD95 = {hd95:.2f} | ASD = {asd:.2f}\")\n",
    "        else:\n",
    "            logger.warning(f\"‚ö†Ô∏è Sample {i} skipped due to empty mask\")\n",
    "\n",
    "        del dist_pred_to_true, dist_true_to_pred\n",
    "        gc.collect()\n",
    "\n",
    "    if len(all_hd95) == 0:\n",
    "        logger.error(\"‚ùå No valid samples for HD95/ASD computation.\")\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    mean_hd95 = np.mean(all_hd95)\n",
    "    median_hd95 = np.median(all_hd95)\n",
    "    mean_asd = np.mean(all_asd)\n",
    "\n",
    "    logger.info(\"\\nüìä Final Evaluation Results:\")\n",
    "    logger.info(f\"Mean HD95: {mean_hd95:.4f}\")\n",
    "    logger.info(f\"Median HD95: {median_hd95:.4f}\")\n",
    "    logger.info(f\"Mean ASD: {mean_asd:.4f}\")\n",
    "\n",
    "    return mean_hd95, mean_asd\n",
    "\n",
    "\n",
    "# ‚úÖ New: Visualization function\n",
    "def visualize_worst_predictions(X_test, worst_results, top_n=5, class_colors=None):\n",
    "    if class_colors is None:\n",
    "        # Default class color map: background, brain, CSP, LV\n",
    "        class_colors = {\n",
    "            0: [0, 0, 0],\n",
    "            1: [255, 0, 0],\n",
    "            2: [0, 255, 0],\n",
    "            3: [0, 0, 255],\n",
    "        }\n",
    "\n",
    "    worst_results = sorted(worst_results, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    for idx, (i, hd95, y_pred_label, y_true_label) in enumerate(worst_results):\n",
    "        img = X_test[i]\n",
    "\n",
    "        def color_mask(label_mask):\n",
    "            color_mask = np.zeros((label_mask.shape[0], label_mask.shape[1], 3), dtype=np.uint8)\n",
    "            for class_idx, color in class_colors.items():\n",
    "                color_mask[label_mask == class_idx] = color\n",
    "            return color_mask\n",
    "\n",
    "        pred_rgb = color_mask(y_pred_label)\n",
    "        true_rgb = color_mask(y_true_label)\n",
    "        error_map = (y_pred_label != y_true_label).astype(np.uint8)\n",
    "\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "        axs[0].imshow(img)\n",
    "        axs[0].set_title(f\"Input Image [{i}]\")\n",
    "        axs[1].imshow(true_rgb)\n",
    "        axs[1].set_title(\"Ground Truth\")\n",
    "        axs[2].imshow(pred_rgb)\n",
    "        axs[2].set_title(\"Prediction\")\n",
    "        axs[3].imshow(error_map, cmap='hot')\n",
    "        axs[3].set_title(f\"Error Map (HD95={hd95:.2f})\")\n",
    "\n",
    "        for ax in axs:\n",
    "            ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Run evaluation and store worst cases\n",
    "mean_hd95, mean_asd = calculate_hd95_asd_combined_mask(\n",
    "    model=student_model,\n",
    "    x_test=X_test,\n",
    "    y_test=y_test,\n",
    "    batch_size=8,\n",
    "    foreground_class_indices=[1, 2, 3]\n",
    ")\n",
    "\n",
    "# Visualize top 5 worst predictions\n",
    "visualize_worst_predictions(X_test, worst_hd95_results, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ‚úÖ RGB to Class Index Conversion (for the test masks)\n",
    "RGB_TO_CLASS = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0     # Background\n",
    "}\n",
    "\n",
    "# ‚úÖ Function to convert RGB masks to class index masks\n",
    "def rgb_to_class_mask(rgb_mask):\n",
    "    # Create a mask initialized with zeros (for background class)\n",
    "    class_mask = np.zeros(rgb_mask.shape[:2], dtype=int)\n",
    "\n",
    "    # Loop through the RGB_TO_CLASS dictionary\n",
    "    for rgb, class_idx in RGB_TO_CLASS.items():\n",
    "        # Identify the pixels with the current RGB value and assign them the class index\n",
    "        match_mask = np.all(rgb_mask == np.array(rgb), axis=-1)\n",
    "        class_mask[match_mask] = class_idx\n",
    "\n",
    "    return class_mask\n",
    "\n",
    "# ‚úÖ Function to calculate Dice Similarity Coefficient (DSC)\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# ‚úÖ Function to calculate IoU (Intersection over Union)\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-15)\n",
    "\n",
    "# ‚úÖ Function to calculate Hausdorff Distance\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')  # Return inf if no points for either true or pred class\n",
    "\n",
    "    forward_hausdorff = directed_hausdorff(true_points, pred_points)[0]\n",
    "    reverse_hausdorff = directed_hausdorff(pred_points, true_points)[0]\n",
    "    return max(forward_hausdorff, reverse_hausdorff)\n",
    "\n",
    "# ‚úÖ Function to calculate Average Surface Distance (ASD)\n",
    "def average_surface_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')  # Return inf if no points for either true or pred class\n",
    "\n",
    "    distances = []\n",
    "    for true_point in true_points:\n",
    "        distances.append(np.min(np.linalg.norm(pred_points - true_point, axis=1)))\n",
    "    return np.mean(distances)\n",
    "\n",
    "# ‚úÖ Function to evaluate the model on the test set class-wise\n",
    "def evaluate_classwise_metrics(model, X_test, y_test, num_classes=4, batch_size=8):\n",
    "    # Predict in batches\n",
    "    y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)  # Convert to class index prediction\n",
    "\n",
    "    # Convert y_test to class index format (since it's one-hot encoded)\n",
    "    y_test_class = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    # Initialize lists to store class-wise metrics\n",
    "    class_metrics ={i: {'dice': [], 'iou': [], 'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'hausdorff': [], 'asd': []} for i in range(num_classes)}\n",
    "\n",
    "    # Calculate metrics for each test sample\n",
    "    for i in range(len(X_test)):\n",
    "        true_mask = y_test_class[i]  # one-hot -> class index\n",
    "        pred_mask = y_pred[i]\n",
    "\n",
    "        # For each class (0: Background, 1: Brain, 2: CSP, 3: LV)\n",
    "        for class_idx in range(num_classes):\n",
    "            true_class_mask = (true_mask == class_idx).astype(int)\n",
    "            pred_class_mask = (pred_mask == class_idx).astype(int)\n",
    "\n",
    "            # Dice Coefficient\n",
    "            class_metrics[class_idx]['dice'].append(dice_coefficient(true_class_mask, pred_class_mask))\n",
    "            # IoU\n",
    "            class_metrics[class_idx]['iou'].append(iou(true_class_mask, pred_class_mask))\n",
    "            # Precision\n",
    "            class_metrics[class_idx]['precision'].append(precision_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # Recall\n",
    "            class_metrics[class_idx]['recall'].append(recall_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # F1 Score\n",
    "            class_metrics[class_idx]['f1'].append(f1_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # Accuracy\n",
    "            class_metrics[class_idx]['accuracy'].append(accuracy_score(true_class_mask.flatten(), pred_class_mask.flatten()))\n",
    "            # Hausdorff Distance\n",
    "            # class_metrics[class_idx]['hausdorff'].append(hausdorff_distance(true_class_mask, pred_class_mask))\n",
    "            # # Average Surface Distance\n",
    "            # class_metrics[class_idx]['asd'].append(average_surface_distance(true_class_mask, pred_class_mask))\n",
    "\n",
    "    # Print class-wise metrics in percentage\n",
    "    print(f\"{'Class':<10}{'Dice Coefficient (%)':<20}{'IoU (%)':<20}{'Precision (%)':<20}{'Recall (%)':<20}{'F1 Score (%)':<20}{'Accuracy (%)':<20}{'Hausdorff Distance':<20}{'Avg Surface Distance':<20}\")\n",
    "    print('-' * 180)\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        print(f\"Class {class_idx}:\")\n",
    "        print(f\"  Dice Coefficient: {np.mean(class_metrics[class_idx]['dice']) * 100:.2f}%\")\n",
    "        print(f\"  IoU: {np.mean(class_metrics[class_idx]['iou']) * 100:.2f}%\")\n",
    "        print(f\"  Precision: {np.mean(class_metrics[class_idx]['precision']) * 100:.2f}%\")\n",
    "        print(f\"  Recall: {np.mean(class_metrics[class_idx]['recall']) * 100:.2f}%\")\n",
    "        print(f\"  F1 Score: {np.mean(class_metrics[class_idx]['f1']) * 100:.2f}%\")\n",
    "        print(f\"  Accuracy: {np.mean(class_metrics[class_idx]['accuracy']) * 100:.2f}%\")\n",
    "        # print(f\"  Hausdorff Distance: {np.mean(class_metrics[class_idx]['hausdorff']):.4f}\")\n",
    "        # print(f\"  Average Surface Distance: {np.mean(class_metrics[class_idx]['asd']):.4f}\")\n",
    "        print(\"-\" * 180)\n",
    "\n",
    "    # Evaluate on test set to print overall test accuracy and loss\n",
    "    test_loss, *test_metrics = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    for metric, value in zip(model.metrics_names[1:], test_metrics):\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# ‚úÖ Call the evaluation function on the test set class-wise\n",
    "evaluate_classwise_metrics(student_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ‚úÖ RGB to Class Index Conversion (for the test masks)\n",
    "RGB_TO_CLASS = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0     # Background\n",
    "}\n",
    "\n",
    "# ‚úÖ Function to convert RGB masks to class index masks\n",
    "def rgb_to_class_mask(rgb_mask):\n",
    "    # Create a mask initialized with zeros (for background class)\n",
    "    class_mask = np.zeros(rgb_mask.shape[:2], dtype=int)\n",
    "\n",
    "    # Loop through the RGB_TO_CLASS dictionary\n",
    "    for rgb, class_idx in RGB_TO_CLASS.items():\n",
    "        # Identify the pixels with the current RGB value and assign them the class index\n",
    "        match_mask = np.all(rgb_mask == np.array(rgb), axis=-1)\n",
    "        class_mask[match_mask] = class_idx\n",
    "\n",
    "    return class_mask\n",
    "\n",
    "# ‚úÖ Function to calculate Dice Similarity Coefficient (DSC)\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# ‚úÖ Function to calculate IoU (Intersection over Union)\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-15)\n",
    "\n",
    "def hausdorff_distance_debug(y_true, y_pred, threshold=0.5):\n",
    "    # Apply threshold to convert predicted probabilities (if any) to binary\n",
    "    y_true = (y_true > threshold).astype(np.uint8)\n",
    "    y_pred = (y_pred > threshold).astype(np.uint8)\n",
    "\n",
    "    # Debug: print shapes and unique values\n",
    "    print(f\"[HD] y_true shape: {y_true.shape}, unique: {np.unique(y_true)}\")\n",
    "    print(f\"[HD] y_pred shape: {y_pred.shape}, unique: {np.unique(y_pred)}\")\n",
    "\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        print(\"[HD] ‚ùå Empty mask detected ‚Äî returning inf\")\n",
    "        return float('inf')\n",
    "\n",
    "    forward_hausdorff = directed_hausdorff(true_points, pred_points)[0]\n",
    "    reverse_hausdorff = directed_hausdorff(pred_points, true_points)[0]\n",
    "    return max(forward_hausdorff, reverse_hausdorff)\n",
    "\n",
    "\n",
    "def average_surface_distance_debug(y_true, y_pred, threshold=0.5):\n",
    "    # Apply threshold\n",
    "    y_true = (y_true > threshold).astype(np.uint8)\n",
    "    y_pred = (y_pred > threshold).astype(np.uint8)\n",
    "\n",
    "    # Debug: print shapes and unique values\n",
    "    print(f\"[ASD] y_true shape: {y_true.shape}, unique: {np.unique(y_true)}\")\n",
    "    print(f\"[ASD] y_pred shape: {y_pred.shape}, unique: {np.unique(y_pred)}\")\n",
    "\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        print(\"[ASD] ‚ùå Empty mask detected ‚Äî returning inf\")\n",
    "        return float('inf')\n",
    "\n",
    "    distances = [np.min(np.linalg.norm(pred_points - tp, axis=1)) for tp in true_points]\n",
    "    return np.mean(distances)\n",
    "\n",
    "# ‚úÖ Function to evaluate the model on the test set class-wise\n",
    "def evaluate_classwise_metrics(model, X_test, y_test, num_classes=4, batch_size=8):\n",
    "    # Predict in batches\n",
    "    y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)  # Convert to class index prediction\n",
    "\n",
    "    # Convert y_test to class index format (since it's one-hot encoded)\n",
    "    y_test_class = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    # Initialize lists to store class-wise metrics\n",
    "    class_metrics ={i: {'dice': [], 'iou': [], 'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'hausdorff': [], 'asd': []} for i in range(num_classes)}\n",
    "\n",
    "    # Calculate metrics for each test sample\n",
    "    for i in range(len(X_test)):\n",
    "        true_mask = y_test_class[i]  # one-hot -> class index\n",
    "        pred_mask = y_pred[i]\n",
    "\n",
    "        # For each class (0: Background, 1: Brain, 2: CSP, 3: LV)\n",
    "        for class_idx in range(num_classes):\n",
    "            true_class_mask = (true_mask == class_idx).astype(int)\n",
    "            pred_class_mask = (pred_mask == class_idx).astype(int)\n",
    "\n",
    "            # Dice Coefficient\n",
    "            # class_metrics[class_idx]['dice'].append(dice_coefficient(true_class_mask, pred_class_mask))\n",
    "            # IoU\n",
    "            # class_metrics[class_idx]['iou'].append(iou(true_class_mask, pred_class_mask))\n",
    "            # Precision\n",
    "            # class_metrics[class_idx]['precision'].append(precision_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # Recall\n",
    "            # class_metrics[class_idx]['recall'].append(recall_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # F1 Score\n",
    "            # class_metrics[class_idx]['f1'].append(f1_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # Accuracy\n",
    "            # class_metrics[class_idx]['accuracy'].append(accuracy_score(true_class_mask.flatten(), pred_class_mask.flatten()))\n",
    "            # Hausdorff Distance\n",
    "            class_metrics[class_idx]['hausdorff'].append(hausdorff_distance_debug(true_class_mask, pred_class_mask))\n",
    "            # # Average Surface Distance\n",
    "            class_metrics[class_idx]['asd'].append(average_surface_distance_debug(true_class_mask, pred_class_mask))\n",
    "\n",
    "    # Print class-wise metrics in percentage\n",
    "    print(f\"{'Class':<10}{'Dice Coefficient (%)':<20}{'IoU (%)':<20}{'Precision (%)':<20}{'Recall (%)':<20}{'F1 Score (%)':<20}{'Accuracy (%)':<20}{'Hausdorff Distance':<20}{'Avg Surface Distance':<20}\")\n",
    "    print('-' * 180)\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        print(f\"Class {class_idx}:\")\n",
    "        # print(f\"  Dice Coefficient: {np.mean(class_metrics[class_idx]['dice']) * 100:.2f}%\")\n",
    "        # print(f\"  IoU: {np.mean(class_metrics[class_idx]['iou']) * 100:.2f}%\")\n",
    "        # print(f\"  Precision: {np.mean(class_metrics[class_idx]['precision']) * 100:.2f}%\")\n",
    "        # print(f\"  Recall: {np.mean(class_metrics[class_idx]['recall']) * 100:.2f}%\")\n",
    "        # print(f\"  F1 Score: {np.mean(class_metrics[class_idx]['f1']) * 100:.2f}%\")\n",
    "        # print(f\"  Accuracy: {np.mean(class_metrics[class_idx]['accuracy']) * 100:.2f}%\")\n",
    "        print(f\"  Hausdorff Distance: {np.mean(class_metrics[class_idx]['hausdorff']):.4f}\")\n",
    "        print(f\"  Average Surface Distance: {np.mean(class_metrics[class_idx]['asd']):.4f}\")\n",
    "        print(\"-\" * 180)\n",
    "\n",
    "    for metric, value in zip(model.metrics_names[1:], test_metrics):\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# ‚úÖ Call the evaluation function on the test set class-wise\n",
    "evaluate_classwise_metrics(student_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"true shape: {y_true.shape}, pred shape: {y_pred.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- METRICS ---\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-15)\n",
    "\n",
    "def hausdorff_distance_debug(y_true, y_pred):\n",
    "    y_true = (y_true > 0.5).astype(np.uint8)\n",
    "    y_pred = (y_pred > 0.5).astype(np.uint8)\n",
    "    print(f\"[HD] y_true shape: {y_true.shape}, unique: {np.unique(y_true)}\")\n",
    "    print(f\"[HD] y_pred shape: {y_pred.shape}, unique: {np.unique(y_pred)}\")\n",
    "\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')\n",
    "    return max(\n",
    "        directed_hausdorff(true_points, pred_points)[0],\n",
    "        directed_hausdorff(pred_points, true_points)[0]\n",
    "    )\n",
    "\n",
    "def average_surface_distance_debug(y_true, y_pred):\n",
    "    y_true = (y_true > 0.5).astype(np.uint8)\n",
    "    y_pred = (y_pred > 0.5).astype(np.uint8)\n",
    "    print(f\"[ASD] y_true shape: {y_true.shape}, unique: {np.unique(y_true)}\")\n",
    "    print(f\"[ASD] y_pred shape: {y_pred.shape}, unique: {np.unique(y_pred)}\")\n",
    "\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')\n",
    "    return np.mean([np.min(np.linalg.norm(pred_points - p, axis=1)) for p in true_points])\n",
    "\n",
    "# --- EVALUATION ---\n",
    "\n",
    "def evaluate_with_debug(model, X_test, y_test, num_classes=4, batch_size=8, threshold=0.3):\n",
    "    y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "    y_pred_class = np.argmax(y_pred, axis=-1)\n",
    "    y_true_class = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    metrics = {i: {'dice': [], 'iou': [], 'hd': [], 'asd': []} for i in range(num_classes)}\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        for class_idx in range(num_classes):\n",
    "            true_mask = (y_true_class[i] == class_idx).astype(np.uint8)\n",
    "            pred_mask = (y_pred[i, :, :, class_idx] > threshold).astype(np.uint8)\n",
    "\n",
    "            dice = dice_coefficient(true_mask, pred_mask)\n",
    "            iou_score = iou(true_mask, pred_mask)\n",
    "\n",
    "            if np.any(true_mask) and np.any(pred_mask):\n",
    "                hd = hausdorff_distance_debug(true_mask, pred_mask)\n",
    "                asd = average_surface_distance_debug(true_mask, pred_mask)\n",
    "            else:\n",
    "                hd = np.nan\n",
    "                asd = np.nan\n",
    "\n",
    "            metrics[class_idx]['dice'].append(dice)\n",
    "            metrics[class_idx]['iou'].append(iou_score)\n",
    "            metrics[class_idx]['hd'].append(hd)\n",
    "            metrics[class_idx]['asd'].append(asd)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# --- SUMMARY ---\n",
    "\n",
    "def summarize_metrics(metrics):\n",
    "    import pandas as pd\n",
    "    rows = []\n",
    "    for class_idx, m in metrics.items():\n",
    "        row = {\n",
    "            'Class': class_idx,\n",
    "            'Dice (%)': np.nanmean(m['dice']) * 100,\n",
    "            'IoU (%)': np.nanmean(m['iou']) * 100,\n",
    "            'Hausdorff': np.nanmean(m['hd']),\n",
    "            'ASD': np.nanmean(m['asd']),\n",
    "        }\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# --- USAGE EXAMPLE ---\n",
    "metrics = evaluate_with_debug(student_model, X_test, y_test)\n",
    "summary_df = summarize_metrics(metrics)\n",
    "# print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Raw data - Updated to match your actual column names with arrows\n",
    "data = {\n",
    "    \"Model\": [\"Unet++(InceptionResNetV2)\", \"AttentionUnet(EfficientNetB4)\", \"Deeplabv3+(Xception)\", \"CNN(SegNet)\", \"LightSeg\"],\n",
    "    \"Training Time (s) ‚Üì\": [190.62, 149.88, 102.30, 250.62, 164.84],\n",
    "    \"GFLOPs ‚Üë\": [34.78, 8.26, 17.15, 85.32, 18.89],\n",
    "    \"Energy (Wh) ‚Üì\": [5.56, 4.00, 3.28, 9.93, 5.51],\n",
    "    \"Params (M) ‚Üì\": [69.3, 29.7, 37.8, 31.4, 1.33],\n",
    "    \"Size (MB) ‚Üì\": [796, 114, 432, 359, 5.35]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Normalize metrics - Updated to match your actual column names\n",
    "metrics = [\"Training Time (s) ‚Üì\", \"GFLOPs ‚Üë\", \"Energy (Wh) ‚Üì\", \"Params (M) ‚Üì\", \"Size (MB) ‚Üì\"]\n",
    "scaler = MinMaxScaler()\n",
    "df_norm = df.copy()\n",
    "df_norm[metrics] = scaler.fit_transform(df[metrics])\n",
    "\n",
    "# Melt normalized and original data\n",
    "df_norm_melted = df_norm.melt(id_vars=\"Model\", value_vars=metrics, var_name=\"Metric\", value_name=\"Normalized Value\")\n",
    "df_orig_melted = df.melt(id_vars=\"Model\", value_vars=metrics, var_name=\"Metric\", value_name=\"Original Value\")\n",
    "\n",
    "# Merge for annotations\n",
    "df_plot = pd.merge(df_norm_melted, df_orig_melted, on=[\"Model\", \"Metric\"])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "ax = sns.barplot(x=\"Metric\", y=\"Normalized Value\", hue=\"Model\", data=df_plot, palette=\"coolwarm\", edgecolor=\"black\")\n",
    "\n",
    "# Correct way to annotate original values\n",
    "# Get the order of models as they appear in the legend\n",
    "model_order = df_plot['Model'].unique()\n",
    "\n",
    "# Annotate bars with original values\n",
    "for i, metric in enumerate(metrics):\n",
    "    metric_data = df_plot[df_plot['Metric'] == metric]\n",
    "    for j, model in enumerate(model_order):\n",
    "        model_data = metric_data[metric_data['Model'] == model]\n",
    "        if not model_data.empty:\n",
    "            original_value = model_data['Original Value'].iloc[0]\n",
    "            # Calculate bar position: metric position + offset for each model\n",
    "            x_pos = i + (j - len(model_order)/2 + 0.5) * (0.8 / len(model_order))\n",
    "            y_pos = model_data['Normalized Value'].iloc[0]\n",
    "            \n",
    "            # Format the annotation based on the metric\n",
    "            if 'Size' in metric:\n",
    "                text = f'{original_value:.1f}'\n",
    "            elif 'Params' in metric:\n",
    "                text = f'{original_value:.1f}'\n",
    "            else:\n",
    "                text = f'{original_value:.2f}'\n",
    "            \n",
    "            ax.annotate(text, \n",
    "                       (x_pos, y_pos),\n",
    "                       ha='center', va='bottom', fontsize=9, fontweight='bold',\n",
    "                       xytext=(0, 3), textcoords='offset points')\n",
    "\n",
    "# Formatting\n",
    "plt.title(\"Normalized Comparison of Model Efficiency Metrics\", fontsize=16, fontweight='bold')\n",
    "plt.ylabel(\"Normalized Value (0‚Äì1)\", fontsize=12, fontweight='bold')\n",
    "plt.xlabel(\"Metric\", fontsize=12, fontweight='bold')\n",
    "plt.xticks(fontsize=12, fontweight='bold')\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "plt.legend(title=\"Model\", bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=12, title_fontsize=11)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Alternative simpler approach using seaborn's built-in annotation\n",
    "plt.figure(figsize=(16, 8))\n",
    "ax = sns.barplot(x=\"Metric\", y=\"Normalized Value\", hue=\"Model\", data=df_plot, palette=\"coolwarm\", edgecolor=\"black\")\n",
    "\n",
    "# Simpler annotation approach\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, labels=[f'{v:.2f}' for v in container.datavalues], \n",
    "                fontsize=10, fontweight='bold', padding=3)\n",
    "\n",
    "plt.title(\"Normalized Comparison of Model Efficiency Metrics (Alternative)\", fontsize=16, fontweight='bold')\n",
    "plt.ylabel(\"Normalized Value (0‚Äì1)\", fontsize=12, fontweight='bold')\n",
    "plt.xlabel(\"Metric\", fontsize=12, fontweight='bold')\n",
    "plt.xticks(fontsize=11, fontweight='bold')\n",
    "plt.yticks(fontsize=11, fontweight='bold')\n",
    "plt.legend(title=\"Model\", bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=10, title_fontsize=11)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data from the chart\n",
    "models = ['InceptionResNetV2', 'Xception', 'EfficientNetB4', 'SegNet', 'Soft Voting', \n",
    "          'Majority Voting', 'Weighted Soft Voting', 'Proposed Lightseg']\n",
    "mean_iou = [83.34, 83.25, 89.08, 83.32, 84.21, 85.26, 85.26, 80.39]\n",
    "mean_dice = [92.07, 91.62, 91.56, 91.34, 91.82, 93.07, 93.09, 92.49]\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Set the width of bars\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(models))\n",
    "\n",
    "# Create vertical bars\n",
    "bars1 = ax.bar(x - bar_width/2, mean_iou, bar_width, label='Mean IoU', \n",
    "               color='#FFB6C1', alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "bars2 = ax.bar(x + bar_width/2, mean_dice, bar_width, label='Mean Dice Coefficient', \n",
    "               color='#DDA0DD', alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (iou, dice) in enumerate(zip(mean_iou, mean_dice)):\n",
    "    ax.text(i - bar_width/2, iou + 0.2, f'{iou:.2f}', \n",
    "            ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "    ax.text(i + bar_width/2, dice + 0.2, f'{dice:.2f}', \n",
    "            ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models, fontsize=11, rotation=45, ha='right')\n",
    "ax.set_ylabel('Score', fontsize=13, fontweight='bold')\n",
    "ax.set_ylim(75, 96)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(loc='upper left', fontsize=11)\n",
    "\n",
    "# Add grid for better readability\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Set title\n",
    "ax.set_title('Model Performance Comparison\\n(Mean IoU vs Mean Dice Coefficient)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>External Validation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "models = [\n",
    "    model_xception,\n",
    "    model_segnet,\n",
    "    model_inceptionresnetv2,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "class WeightedSoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, weights=None, apply_softmax=True):\n",
    "        super(WeightedSoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        if weights is None:\n",
    "            weights = [1.0 / len(models)] * len(models)\n",
    "        else:\n",
    "            total = sum(weights)\n",
    "            weights = [w / total for w in weights]\n",
    "\n",
    "        self.model_weights = tf.constant(weights, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        weighted_sum = 0\n",
    "        for i, model in enumerate(self.models):\n",
    "            output = model(x, training=training)\n",
    "\n",
    "            is_softmaxed = (\n",
    "                hasattr(model, \"name\") and \"efficientnet\" in model.name.lower()\n",
    "            )\n",
    "\n",
    "            if self.apply_softmax and not is_softmaxed:\n",
    "                probs = tf.nn.softmax(output, axis=-1)\n",
    "            else:\n",
    "                probs = output\n",
    "\n",
    "            weighted_sum += self.model_weights[i] * probs\n",
    "\n",
    "        avg_prob = weighted_sum  # shape: [B, H, W, C]\n",
    "\n",
    "        # üîÅ Convert to one-hot for metric compatibility\n",
    "        one_hot_pred = tf.one_hot(tf.argmax(avg_prob, axis=-1), depth=avg_prob.shape[-1])\n",
    "        return one_hot_pred  # [B, H, W, C]\n",
    "\n",
    "final_weights = [0.255, 0.2427, 0.2515, 0.2508]\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "teacher_model = ensemble_model \n",
    "\n",
    "def distillation_loss(y_true, y_student_logits, y_teacher_probs, alpha=0.5, temperature=3.0):\n",
    "    # Softened predictions for KL\n",
    "    student_soft = tf.nn.softmax(y_student_logits / temperature)\n",
    "    teacher_soft = tf.nn.softmax(y_teacher_probs / temperature)\n",
    "\n",
    "    # Soft loss: KL divergence\n",
    "    kl_loss = tf.keras.losses.KLDivergence()(teacher_soft, student_soft)\n",
    "\n",
    "    # Hard loss: Use your custom combined loss (Dice + Lovasz)\n",
    "    ce_loss = combined_loss(y_true, y_student_logits) + tf.keras.losses.CategoricalCrossentropy()(y_true, y_student_logits)\n",
    "\n",
    "    # Combine them\n",
    "    return alpha * ce_loss + (1 - alpha) * (temperature ** 2) * kl_loss\n",
    "\n",
    "# === KD Wrapper Model ===\n",
    "class KDTrainer(tf.keras.Model):\n",
    "    def __init__(self, student, teacher, alpha=0.5, temperature=3.0):\n",
    "        super(KDTrainer, self).__init__()\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def compile(self, optimizer, metrics):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.metrics_list = metrics\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y_true = data\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_logits = self.student(x, training=True)               # [B, H, W, C]\n",
    "            teacher_probs = self.teacher(x, training=False)               # Soft probs\n",
    "\n",
    "            loss = distillation_loss(\n",
    "                y_true, student_logits, teacher_probs,\n",
    "                alpha=self.alpha, temperature=self.temperature\n",
    "            )\n",
    "\n",
    "        grads = tape.gradient(loss, self.student.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.student.trainable_variables))\n",
    "\n",
    "        for metric in self.metrics_list:\n",
    "            metric.update_state(y_true, student_logits)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics_list} | {\"loss\": loss}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y_true = data\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = self.student(x, training=False)\n",
    "        loss = combined_loss(y_true, y_pred)\n",
    "\n",
    "        for metric in self.metrics_list:\n",
    "            metric.update_state(y_true, y_pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics_list} | {\"loss\": loss}\n",
    "\n",
    "# === Instantiate KDTrainer ===\n",
    "kd_model = KDTrainer(\n",
    "    student=student_model,\n",
    "    teacher=teacher_model,\n",
    "    alpha=0.5,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "# === Compile ===\n",
    "kd_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Brightness</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception.evaluate(X_test_bright, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_segnet.evaluate(X_test_bright, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inceptionresnetv2.evaluate(X_test_bright, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_efficientnetb4.evaluate(X_test_bright, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model.evaluate(X_test_bright, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_model.evaluate(X_test_bright, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dark</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception.evaluate(X_test_dark, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_segnet.evaluate(X_test_dark, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inceptionresnetv2.evaluate(X_test_dark, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_efficientnetb4.evaluate(X_test_dark, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model.evaluate(X_test_dark, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_model.evaluate(X_test_dark, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Blur 20%</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception.evaluate(X_test_blur_20, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_segnet.evaluate(X_test_blur_20, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inceptionresnetv2.evaluate(X_test_blur_20, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_efficientnetb4.evaluate(X_test_blur_20, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model.evaluate(X_test_blur_20, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_model.evaluate(X_test_blur_20, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Blur 40%</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception.evaluate(X_test_blur_40, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_segnet.evaluate(X_test_blur_40, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inceptionresnetv2.evaluate(X_test_blur_40, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_efficientnetb4.evaluate(X_test_blur_40, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model.evaluate(X_test_blur_40, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_model.evaluate(X_test_blur_40, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6804412,
     "sourceId": 10941215,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
