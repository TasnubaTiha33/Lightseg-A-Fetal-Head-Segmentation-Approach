{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "\n",
    "CLASS_MAP = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0     # Background\n",
    "}\n",
    "\n",
    "def mask_to_class(mask):\n",
    "    mask = np.array(mask)\n",
    "    h, w, _ = mask.shape\n",
    "    class_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    for rgb, class_idx in CLASS_MAP.items():\n",
    "        match = np.all(mask == rgb, axis=-1)\n",
    "        class_mask[match] = class_idx\n",
    "    return class_mask\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "class Pix2PixDataset(Dataset):\n",
    "    def __init__(self, mask_dir, image_dir, transform_img=None, transform_mask=None):\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_dir = image_dir\n",
    "        self.transform_img = transform_img or transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5]*3, [0.5]*3)  # For 3-channel images\n",
    "        ])\n",
    "        self.transform_mask = transform_mask or transforms.Compose([\n",
    "            transforms.Resize((224, 224), interpolation=Image.NEAREST)\n",
    "        ])\n",
    "\n",
    "        self.mask_paths = sorted(os.listdir(mask_dir))\n",
    "        self.image_paths = sorted(os.listdir(image_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mask_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_paths[idx])\n",
    "        image_path = os.path.join(self.image_dir, self.image_paths[idx])\n",
    "\n",
    "        mask = Image.open(mask_path).convert(\"RGB\")  # Keep RGB to apply CLASS_MAP\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # Resize both before applying conversion\n",
    "        if self.transform_mask:\n",
    "            mask = self.transform_mask(mask)\n",
    "        if self.transform_img:\n",
    "            image = self.transform_img(image)\n",
    "\n",
    "        # Now convert mask to class indices\n",
    "        mask = np.array(mask)\n",
    "        class_mask = mask_to_class(mask)  # (H, W)\n",
    "        class_mask = torch.from_numpy(class_mask).unsqueeze(0).float()  # Shape: [1, H, W], type float for Generator\n",
    "\n",
    "        return class_mask.float(), image  # convert to float so conv works\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = Pix2PixDataset(\n",
    "    image_dir=r\"D:\\Updated\\train\\images\",\n",
    "    mask_dir=r\"D:\\Updated\\train\\masks\"\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class UNetBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, down=True, use_dropout=False):\n",
    "        super(UNetBlock, self).__init__()\n",
    "        layers = []\n",
    "        if down:\n",
    "            layers += [\n",
    "                nn.Conv2d(in_ch, out_ch, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            ]\n",
    "        else:\n",
    "            layers += [\n",
    "                nn.ConvTranspose2d(in_ch, out_ch, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "        if use_dropout:\n",
    "            layers += [nn.Dropout(0.5)]\n",
    "        self.block = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class Pix2PixGenerator(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=3, features=64):\n",
    "        super().__init__()\n",
    "        # Encoder (downsampling)\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features, 4, 2, 1), \n",
    "            nn.LeakyReLU(0.2)\n",
    "        )  # 224 -> 112\n",
    "        self.down2 = UNetBlock(features, features*2)      # 112 -> 56\n",
    "        self.down3 = UNetBlock(features*2, features*4)    # 56 -> 28\n",
    "        self.down4 = UNetBlock(features*4, features*8)    # 28 -> 14\n",
    "        self.down5 = UNetBlock(features*8, features*8)    # 14 -> 7\n",
    "        self.down6 = UNetBlock(features*8, features*8)    # 7 -> 3\n",
    "        \n",
    "        # Bottleneck - use stride=1 to avoid going to 0 size\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features*8, features*8, 4, 1, 1),  # 3 -> 2 (with padding)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder (upsampling)\n",
    "        self.up1 = UNetBlock(features*8, features*8, down=False, use_dropout=True)    # 2 -> 4\n",
    "        self.up2 = UNetBlock(features*8*2, features*8, down=False, use_dropout=True)  # 4 -> 8\n",
    "        self.up3 = UNetBlock(features*8*2, features*8, down=False, use_dropout=True)  # 8 -> 16\n",
    "        self.up4 = UNetBlock(features*8*2, features*4, down=False)                    # 16 -> 32\n",
    "        self.up5 = UNetBlock(features*4*2, features*2, down=False)                    # 32 -> 64\n",
    "        self.up6 = UNetBlock(features*2*2, features, down=False)                      # 64 -> 128\n",
    "        \n",
    "        # Final upsampling to get back to 224x224\n",
    "        self.final_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features*2, out_channels, 4, 2, 1),  # 128 -> 256\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # Add adaptive pooling to ensure exact output size\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((224, 224))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        d1 = self.down1(x)      # [B, 64, 112, 112]\n",
    "        d2 = self.down2(d1)     # [B, 128, 56, 56]\n",
    "        d3 = self.down3(d2)     # [B, 256, 28, 28]\n",
    "        d4 = self.down4(d3)     # [B, 512, 14, 14]\n",
    "        d5 = self.down5(d4)     # [B, 512, 7, 7]\n",
    "        d6 = self.down6(d5)     # [B, 512, 3, 3]\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(d6)  # [B, 512, 2, 2]\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        up1 = self.up1(bottleneck)                          # [B, 512, 4, 4]\n",
    "        # Resize d6 to match up1 size for concatenation\n",
    "        d6_resized = nn.functional.interpolate(d6, size=up1.shape[2:], mode='bilinear', align_corners=False)\n",
    "        up2 = self.up2(torch.cat([up1, d6_resized], 1))     # [B, 512, 8, 8]\n",
    "        \n",
    "        # Resize d5 to match up2 size\n",
    "        d5_resized = nn.functional.interpolate(d5, size=up2.shape[2:], mode='bilinear', align_corners=False)\n",
    "        up3 = self.up3(torch.cat([up2, d5_resized], 1))     # [B, 512, 16, 16]\n",
    "        \n",
    "        # Resize d4 to match up3 size\n",
    "        d4_resized = nn.functional.interpolate(d4, size=up3.shape[2:], mode='bilinear', align_corners=False)\n",
    "        up4 = self.up4(torch.cat([up3, d4_resized], 1))     # [B, 256, 32, 32]\n",
    "        \n",
    "        # Resize d3 to match up4 size\n",
    "        d3_resized = nn.functional.interpolate(d3, size=up4.shape[2:], mode='bilinear', align_corners=False)\n",
    "        up5 = self.up5(torch.cat([up4, d3_resized], 1))     # [B, 128, 64, 64]\n",
    "        \n",
    "        # Resize d2 to match up5 size\n",
    "        d2_resized = nn.functional.interpolate(d2, size=up5.shape[2:], mode='bilinear', align_corners=False)\n",
    "        up6 = self.up6(torch.cat([up5, d2_resized], 1))     # [B, 64, 128, 128]\n",
    "        \n",
    "        # Resize d1 to match up6 size\n",
    "        d1_resized = nn.functional.interpolate(d1, size=up6.shape[2:], mode='bilinear', align_corners=False)\n",
    "        final = self.final_up(torch.cat([up6, d1_resized], 1))  # [B, 3, 256, 256]\n",
    "        \n",
    "        # Resize to exactly 224x224 if needed\n",
    "        if final.shape[2] != 224 or final.shape[3] != 224:\n",
    "            final = nn.functional.interpolate(final, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        return final\n",
    "\n",
    "class Pix2PixDiscriminator(nn.Module):\n",
    "    def __init__(self, in_channels=4, features=64):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features, 4, 2, 1),    # 224 -> 112\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(features, features*2, 4, 2, 1),      # 112 -> 56\n",
    "            nn.BatchNorm2d(features*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(features*2, features*4, 4, 2, 1),    # 56 -> 28\n",
    "            nn.BatchNorm2d(features*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(features*4, features*8, 4, 2, 1),    # 28 -> 14\n",
    "            nn.BatchNorm2d(features*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Use stride=1 and padding=0 to get a more predictable output size\n",
    "            nn.Conv2d(features*8, 1, 4, 1, 0),             # 14 -> 11\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        # Concatenate mask and image along channel dim\n",
    "        return self.model(torch.cat([x, y], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from lovasz_losses import lovasz_softmax  # pip install git+https://github.com/bermanmaxim/LovaszSoftmax\n",
    "\n",
    "# Dice Loss (for multi-class)\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        targets = F.one_hot(targets, num_classes=probs.shape[1]).permute(0, 3, 1, 2).float()\n",
    "        dims = (0, 2, 3)\n",
    "        intersection = torch.sum(probs * targets, dims)\n",
    "        union = torch.sum(probs + targets, dims)\n",
    "        dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "ce_loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# 1) Build your models\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "class UNetBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, down=True, use_dropout=False):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        if down:\n",
    "            layers += [\n",
    "                nn.Conv2d(in_ch, out_ch, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "            ]\n",
    "        else:\n",
    "            layers += [\n",
    "                nn.ConvTranspose2d(in_ch, out_ch, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "        if use_dropout:\n",
    "            layers += [nn.Dropout(0.5)]\n",
    "        self.block = nn.Sequential(*layers)\n",
    "    def forward(self, x): return self.block(x)\n",
    "\n",
    "class Pix2PixGenerator(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=3, features=64):\n",
    "        super().__init__()\n",
    "        # downsample\n",
    "        self.down1 = nn.Sequential(nn.Conv2d(in_channels, features, 4, 2, 1), nn.LeakyReLU(0.2))\n",
    "        self.down2 = UNetBlock(features,     features*2)\n",
    "        self.down3 = UNetBlock(features*2,   features*4)\n",
    "        self.down4 = UNetBlock(features*4,   features*8)\n",
    "        self.down5 = UNetBlock(features*8,   features*8)\n",
    "        self.down6 = UNetBlock(features*8,   features*8)\n",
    "        # bottleneck (keep >0 spatial size)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features*8, features*8, 4, 1, 1),  # e.g. 7â†’6â†’5 etc\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # upsample\n",
    "        self.up1 = UNetBlock(features*8,     features*8, down=False, use_dropout=True)\n",
    "        self.up2 = UNetBlock(features*8*2,   features*8, down=False, use_dropout=True)\n",
    "        self.up3 = UNetBlock(features*8*2,   features*8, down=False, use_dropout=True)\n",
    "        self.up4 = UNetBlock(features*8*2,   features*4, down=False)\n",
    "        self.up5 = UNetBlock(features*4*2,   features*2, down=False)\n",
    "        self.up6 = UNetBlock(features*2*2,   features,   down=False)\n",
    "        # final â†’ may overshoot 224, so weâ€™ll adaptively pool\n",
    "        self.final_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features*2, out_channels, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)    # 224â†’112\n",
    "        d2 = self.down2(d1)   # 112â†’56\n",
    "        d3 = self.down3(d2)   # 56â†’28\n",
    "        d4 = self.down4(d3)   # 28â†’14\n",
    "        d5 = self.down5(d4)   # 14â†’7\n",
    "        d6 = self.down6(d5)   # 7â†’3\n",
    "        bt = self.bottleneck(d6)        # 3â†’2\n",
    "        u1 = self.up1(bt)                # 2â†’4\n",
    "        u2 = self.up2(torch.cat([u1, nn.functional.interpolate(d6, u1.shape[2:])], 1))  # 4â†’8\n",
    "        u3 = self.up3(torch.cat([u2, nn.functional.interpolate(d5, u2.shape[2:])], 1))  # 8â†’16\n",
    "        u4 = self.up4(torch.cat([u3, nn.functional.interpolate(d4, u3.shape[2:])], 1))  # 16â†’32\n",
    "        u5 = self.up5(torch.cat([u4, nn.functional.interpolate(d3, u4.shape[2:])], 1))  # 32â†’64\n",
    "        u6 = self.up6(torch.cat([u5, nn.functional.interpolate(d2, u5.shape[2:])], 1))  # 64â†’128\n",
    "        final = self.final_up(torch.cat([u6, nn.functional.interpolate(d1, u6.shape[2:])], 1))  # 128â†’256\n",
    "        # bring back to exactly 224\n",
    "        return nn.functional.interpolate(final, size=(224,224), mode='bilinear', align_corners=False)\n",
    "\n",
    "class Pix2PixDiscriminator(nn.Module):\n",
    "    def __init__(self, in_channels=4, features=64):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features,   4,2,1), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(features,   features*2,  4,2,1), nn.BatchNorm2d(features*2), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(features*2, features*4,  4,2,1), nn.BatchNorm2d(features*4), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(features*4, features*8,  4,2,1), nn.BatchNorm2d(features*8), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(features*8, 1,           4,1,0), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, mask, img):\n",
    "        # mask: [B,1,224,224], img:[B,3,224,224] â†’ concatâ†’[B,4,224,224]\n",
    "        return self.model(torch.cat([mask, img], dim=1))\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# 2) Training loop\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "def train_pix2pix(\n",
    "    gen, disc, loader, device,\n",
    "    num_epochs=100,\n",
    "    lr_G=1e-4,      # Slower generator\n",
    "    lr_D=4e-4,      # Faster discriminator  \n",
    "    Î»_adv=1.0,      # Adversarial loss weight\n",
    "    Î»_dice=50,      # Dice loss weight (reduced from your implicit high weight)\n",
    "    Î»_lovasz=50,    # LovÃ¡sz loss weight\n",
    "    Î»_ce=10,        # Cross-entropy weight\n",
    "    save_dir=r\"D:\\Updated\\pix2pix\"\n",
    "):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Different learning rates to prevent discriminator dominance\n",
    "    opt_G = optim.Adam(gen.parameters(), lr=lr_G, betas=(0.5, 0.999))\n",
    "    opt_D = optim.Adam(disc.parameters(), lr=lr_D, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Loss functions\n",
    "    bce_loss = nn.BCEWithLogitsLoss()  # More stable\n",
    "    dice_loss_fn = DiceLoss()\n",
    "    ce_loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    gen.to(device)\n",
    "    disc.to(device)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        gen.train()\n",
    "        disc.train()\n",
    "        \n",
    "        for i, (mask, real_img) in enumerate(loader):\n",
    "            mask = mask.to(device)      # [B,1,224,224]\n",
    "            real_img = real_img.to(device)  # [B,3,224,224]\n",
    "            B = mask.size(0)\n",
    "            \n",
    "            # --- Train Discriminator (every step) ---\n",
    "            opt_D.zero_grad()\n",
    "            \n",
    "            # Add slight noise to prevent overfitting\n",
    "            noise_std = 0.05\n",
    "            real_noisy = real_img + noise_std * torch.randn_like(real_img)\n",
    "            \n",
    "            fake_img = gen(mask)\n",
    "            fake_noisy = fake_img.detach() + noise_std * torch.randn_like(fake_img)\n",
    "            \n",
    "            # Real and fake predictions\n",
    "            pred_real = disc(mask, real_noisy)\n",
    "            pred_fake = disc(mask, fake_noisy)\n",
    "            \n",
    "            # Binary labels\n",
    "            valid = torch.ones_like(pred_real)\n",
    "            fake_labels = torch.zeros_like(pred_fake)\n",
    "            \n",
    "            # Discriminator loss with label smoothing\n",
    "            loss_D_real = bce_loss(pred_real, valid * 0.9)  # Label smoothing\n",
    "            loss_D_fake = bce_loss(pred_fake, fake_labels)\n",
    "            loss_D = 0.5 * (loss_D_real + loss_D_fake)\n",
    "            \n",
    "            loss_D.backward()\n",
    "            opt_D.step()\n",
    "            \n",
    "            # --- Train Generator (every 2 steps to balance training) ---\n",
    "            if i % 2 == 0:\n",
    "                opt_G.zero_grad()\n",
    "                \n",
    "                fake_img = gen(mask)\n",
    "                \n",
    "                # 1. Adversarial loss\n",
    "                pred_fake = disc(mask, fake_img)\n",
    "                loss_G_adv = Î»_adv * bce_loss(pred_fake, torch.ones_like(pred_fake))\n",
    "                \n",
    "                # 2. Segmentation losses (your key insight!)\n",
    "                # Convert real_img to class targets\n",
    "                targets = real_img.argmax(dim=1) if real_img.shape[1] > 1 else real_img.squeeze(1).long()\n",
    "                \n",
    "                dice_loss = Î»_dice * dice_loss_fn(fake_img, targets)\n",
    "                lovasz_loss = Î»_lovasz * lovasz_softmax(fake_img, targets)\n",
    "                ce_loss = Î»_ce * ce_loss_fn(fake_img, targets)\n",
    "                \n",
    "                # Combined generator loss\n",
    "                loss_G = loss_G_adv + dice_loss + lovasz_loss + ce_loss\n",
    "                \n",
    "                loss_G.backward()\n",
    "                opt_G.step()\n",
    "            \n",
    "            # Logging with discriminator accuracy\n",
    "            if i % 50 == 0:\n",
    "                with torch.no_grad():\n",
    "                    d_real_acc = (torch.sigmoid(pred_real) > 0.5).float().mean()\n",
    "                    d_fake_acc = (torch.sigmoid(pred_fake) < 0.5).float().mean()\n",
    "                    d_overall_acc = (d_real_acc + d_fake_acc) / 2\n",
    "                \n",
    "                print(f\"[E{epoch}/{num_epochs} B{i}/{len(loader)}] \"\n",
    "                      f\"D: {loss_D.item():.3f} (Acc: {d_overall_acc:.2f}) | \"\n",
    "                      f\"G: {loss_G.item():.3f} \"\n",
    "                      f\"(Adv: {loss_G_adv.item():.2f}, Dice: {dice_loss.item():.2f})\")\n",
    "        \n",
    "        # Save samples every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            gen.eval()\n",
    "            with torch.no_grad():\n",
    "                m, r = next(iter(loader))\n",
    "                m, r = m.to(device), r.to(device)\n",
    "                sample = gen(m)\n",
    "                \n",
    "                for idx in range(min(3, B)):\n",
    "                    save_image(sample[idx], \n",
    "                              os.path.join(save_dir, f\"ep{epoch}_gen{idx}.png\"),\n",
    "                              normalize=True)\n",
    "                    save_image(m[idx],\n",
    "                              os.path.join(save_dir, f\"ep{epoch}_mask{idx}.png\"))\n",
    "                    save_image(r[idx],\n",
    "                              os.path.join(save_dir, f\"ep{epoch}_real{idx}.png\"),\n",
    "                              normalize=True)\n",
    "    \n",
    "    print(\"âœ… Training complete.\")\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# 3) Kick it off\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gen  = Pix2PixGenerator(in_channels=1, out_channels=3)\n",
    "disc = Pix2PixDiscriminator(in_channels=1+3)\n",
    "\n",
    "train_pix2pix(gen, disc, train_loader, device,\n",
    "              num_epochs=200,\n",
    "              lr=2e-4,\n",
    "              Î»_l1=100,\n",
    "              save_dir=r\"D:\\Updated\\pix2pix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# 1) Build your models\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "class UNetBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, down=True, use_dropout=False):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        if down:\n",
    "            layers += [\n",
    "                nn.Conv2d(in_ch, out_ch, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "            ]\n",
    "        else:\n",
    "            layers += [\n",
    "                nn.ConvTranspose2d(in_ch, out_ch, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "        if use_dropout:\n",
    "            layers += [nn.Dropout(0.5)]\n",
    "        self.block = nn.Sequential(*layers)\n",
    "    def forward(self, x): return self.block(x)\n",
    "\n",
    "class Pix2PixGenerator(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=3, features=64):\n",
    "        super().__init__()\n",
    "        # downsample\n",
    "        self.down1 = nn.Sequential(nn.Conv2d(in_channels, features, 4, 2, 1), nn.LeakyReLU(0.2))\n",
    "        self.down2 = UNetBlock(features,     features*2)\n",
    "        self.down3 = UNetBlock(features*2,   features*4)\n",
    "        self.down4 = UNetBlock(features*4,   features*8)\n",
    "        self.down5 = UNetBlock(features*8,   features*8)\n",
    "        self.down6 = UNetBlock(features*8,   features*8)\n",
    "        # bottleneck (keep >0 spatial size)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features*8, features*8, 4, 1, 1),  # e.g. 7â†’6â†’5 etc\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # upsample\n",
    "        self.up1 = UNetBlock(features*8,     features*8, down=False, use_dropout=True)\n",
    "        self.up2 = UNetBlock(features*8*2,   features*8, down=False, use_dropout=True)\n",
    "        self.up3 = UNetBlock(features*8*2,   features*8, down=False, use_dropout=True)\n",
    "        self.up4 = UNetBlock(features*8*2,   features*4, down=False)\n",
    "        self.up5 = UNetBlock(features*4*2,   features*2, down=False)\n",
    "        self.up6 = UNetBlock(features*2*2,   features,   down=False)\n",
    "        # final â†’ may overshoot 224, so weâ€™ll adaptively pool\n",
    "        self.final_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features*2, out_channels, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)    # 224â†’112\n",
    "        d2 = self.down2(d1)   # 112â†’56\n",
    "        d3 = self.down3(d2)   # 56â†’28\n",
    "        d4 = self.down4(d3)   # 28â†’14\n",
    "        d5 = self.down5(d4)   # 14â†’7\n",
    "        d6 = self.down6(d5)   # 7â†’3\n",
    "        bt = self.bottleneck(d6)        # 3â†’2\n",
    "        u1 = self.up1(bt)                # 2â†’4\n",
    "        u2 = self.up2(torch.cat([u1, nn.functional.interpolate(d6, u1.shape[2:])], 1))  # 4â†’8\n",
    "        u3 = self.up3(torch.cat([u2, nn.functional.interpolate(d5, u2.shape[2:])], 1))  # 8â†’16\n",
    "        u4 = self.up4(torch.cat([u3, nn.functional.interpolate(d4, u3.shape[2:])], 1))  # 16â†’32\n",
    "        u5 = self.up5(torch.cat([u4, nn.functional.interpolate(d3, u4.shape[2:])], 1))  # 32â†’64\n",
    "        u6 = self.up6(torch.cat([u5, nn.functional.interpolate(d2, u5.shape[2:])], 1))  # 64â†’128\n",
    "        final = self.final_up(torch.cat([u6, nn.functional.interpolate(d1, u6.shape[2:])], 1))  # 128â†’256\n",
    "        # bring back to exactly 224\n",
    "        return nn.functional.interpolate(final, size=(224,224), mode='bilinear', align_corners=False)\n",
    "\n",
    "class Pix2PixDiscriminator(nn.Module):\n",
    "    def __init__(self, in_channels=4, features=64):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features,   4,2,1), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(features,   features*2,  4,2,1), nn.BatchNorm2d(features*2), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(features*2, features*4,  4,2,1), nn.BatchNorm2d(features*4), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(features*4, features*8,  4,2,1), nn.BatchNorm2d(features*8), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(features*8, 1,           4,1,0), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, mask, img):\n",
    "        # mask: [B,1,224,224], img:[B,3,224,224] â†’ concatâ†’[B,4,224,224]\n",
    "        return self.model(torch.cat([mask, img], dim=1))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gen  = Pix2PixGenerator(in_channels=1, out_channels=3)\n",
    "disc = Pix2PixDiscriminator(in_channels=1+3)\n",
    "        \n",
    "def train_pix2pix(\n",
    "    gen, disc, loader, device,\n",
    "    num_epochs=100,\n",
    "    lr_G=1e-4,      # Slower generator\n",
    "    lr_D=4e-4,      # Faster discriminator  \n",
    "    Î»_adv=1.0,      # Adversarial loss weight\n",
    "    Î»_dice=10.0,    # Dice loss weight (reasonable for 0-1 range loss)\n",
    "    Î»_lovasz=10.0,  # LovÃ¡sz loss weight  \n",
    "    Î»_ce=1.0,       # Cross-entropy weight (CE is usually 0-5 range)\n",
    "    save_dir=r\"D:\\Updated\\pix2pix\"\n",
    "):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Different learning rates to prevent discriminator dominance\n",
    "    opt_G = optim.Adam(gen.parameters(), lr=lr_G, betas=(0.5, 0.999))\n",
    "    opt_D = optim.Adam(disc.parameters(), lr=lr_D, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Loss functions\n",
    "    bce_loss = nn.BCEWithLogitsLoss()  # More stable\n",
    "    dice_loss_fn = DiceLoss()\n",
    "    ce_loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    gen.to(device)\n",
    "    disc.to(device)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        gen.train()\n",
    "        disc.train()\n",
    "        \n",
    "        for i, (mask, real_img) in enumerate(loader):\n",
    "            mask = mask.to(device)      # [B,1,224,224]\n",
    "            real_img = real_img.to(device)  # [B,3,224,224]\n",
    "            B = mask.size(0)\n",
    "            \n",
    "            # --- Train Discriminator (every step) ---\n",
    "            opt_D.zero_grad()\n",
    "            \n",
    "            # Add slight noise to prevent overfitting\n",
    "            noise_std = 0.05\n",
    "            real_noisy = real_img + noise_std * torch.randn_like(real_img)\n",
    "            \n",
    "            fake_img = gen(mask)\n",
    "            fake_noisy = fake_img.detach() + noise_std * torch.randn_like(fake_img)\n",
    "            \n",
    "            # Real and fake predictions\n",
    "            pred_real = disc(mask, real_noisy)\n",
    "            pred_fake = disc(mask, fake_noisy)\n",
    "            \n",
    "            # Binary labels\n",
    "            valid = torch.ones_like(pred_real)\n",
    "            fake_labels = torch.zeros_like(pred_fake)\n",
    "            \n",
    "            # Discriminator loss with label smoothing\n",
    "            loss_D_real = bce_loss(pred_real, valid * 0.9)  # Label smoothing\n",
    "            loss_D_fake = bce_loss(pred_fake, fake_labels)\n",
    "            loss_D = 0.5 * (loss_D_real + loss_D_fake)\n",
    "            \n",
    "            loss_D.backward()\n",
    "            opt_D.step()\n",
    "            \n",
    "            # --- Train Generator (every 2 steps to balance training) ---\n",
    "            if i % 2 == 0:\n",
    "                opt_G.zero_grad()\n",
    "                \n",
    "                fake_img = gen(mask)\n",
    "                \n",
    "                # 1. Adversarial loss\n",
    "                pred_fake = disc(mask, fake_img)\n",
    "                loss_G_adv = Î»_adv * bce_loss(pred_fake, torch.ones_like(pred_fake))\n",
    "                \n",
    "                # 2. Segmentation losses (your key insight!)\n",
    "                # Convert real_img to class targets\n",
    "                targets = real_img.argmax(dim=1) if real_img.shape[1] > 1 else real_img.squeeze(1).long()\n",
    "                \n",
    "                # Calculate raw losses first\n",
    "                dice_loss_raw = dice_loss_fn(fake_img, targets)\n",
    "                lovasz_loss_raw = lovasz_softmax(fake_img, targets)  \n",
    "                ce_loss_raw = ce_loss_fn(fake_img, targets)\n",
    "                \n",
    "                # Apply weights\n",
    "                dice_loss = Î»_dice * dice_loss_raw\n",
    "                lovasz_loss = Î»_lovasz * lovasz_loss_raw\n",
    "                ce_loss = Î»_ce * ce_loss_raw\n",
    "                \n",
    "                # Combined generator loss\n",
    "                loss_G = loss_G_adv + dice_loss + lovasz_loss + ce_loss\n",
    "                \n",
    "                loss_G.backward()\n",
    "                opt_G.step()\n",
    "            \n",
    "            # Logging with discriminator accuracy\n",
    "            if i % 50 == 0:\n",
    "                with torch.no_grad():\n",
    "                    d_real_acc = (torch.sigmoid(pred_real) > 0.5).float().mean()\n",
    "                    d_fake_acc = (torch.sigmoid(pred_fake) < 0.5).float().mean()\n",
    "                    d_overall_acc = (d_real_acc + d_fake_acc) / 2\n",
    "                \n",
    "                print(f\"[E{epoch}/{num_epochs} B{i}/{len(loader)}] \"\n",
    "                      f\"D: {loss_D.item():.3f} (Acc: {d_overall_acc:.2f}) | \"\n",
    "                      f\"G: {loss_G.item():.3f} \"\n",
    "                      f\"(Adv: {loss_G_adv.item():.2f}, Dice: {dice_loss_raw.item():.3f}, \"\n",
    "                      f\"Lovasz: {lovasz_loss_raw.item():.3f}, CE: {ce_loss_raw.item():.3f})\")\n",
    "        \n",
    "        # Save samples every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            gen.eval()\n",
    "            with torch.no_grad():\n",
    "                m, r = next(iter(loader))\n",
    "                m, r = m.to(device), r.to(device)\n",
    "                sample = gen(m)\n",
    "                \n",
    "                for idx in range(min(3, B)):\n",
    "                    save_image(sample[idx], \n",
    "                              os.path.join(save_dir, f\"ep{epoch}_gen{idx}.png\"),\n",
    "                              normalize=True)\n",
    "                    save_image(m[idx],\n",
    "                              os.path.join(save_dir, f\"ep{epoch}_mask{idx}.png\"))\n",
    "                    save_image(r[idx],\n",
    "                              os.path.join(save_dir, f\"ep{epoch}_real{idx}.png\"),\n",
    "                              normalize=True)\n",
    "    \n",
    "    print(\"âœ… Training complete.\")\n",
    "\n",
    "train_pix2pix(gen, disc, train_loader, device,\n",
    "              num_epochs=200,\n",
    "              lr_G=1e-4,\n",
    "              lr_D=4e-4, \n",
    "              Î»_adv=1.0,      # Keep adversarial loss low\n",
    "              Î»_dice=10,      # Your segmentation losses remain strong\n",
    "              Î»_lovasz=10,\n",
    "              Î»_ce=1,\n",
    "              save_dir=r\"D:\\Updated\\pix2pix\\Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = Pix2PixDataset(\n",
    "    image_dir=r\"D:\\Updated\\val\\images\",\n",
    "    mask_dir=r\"D:\\Updated\\val\\masks\"\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Reverse CLASS_MAP\n",
    "REVERSE_CLASS_MAP = {\n",
    "    0: (0, 0, 0),\n",
    "    1: (255, 0, 0),\n",
    "    2: (0, 255, 0),\n",
    "    3: (0, 0, 255)\n",
    "}\n",
    "\n",
    "def class_to_colored_mask(class_mask_tensor):\n",
    "    \"\"\"\n",
    "    Converts a 1xHxW tensor of class indices to a colored RGB PIL image.\n",
    "    \"\"\"\n",
    "    class_mask = class_mask_tensor.squeeze().cpu().numpy().astype(np.uint8)\n",
    "    h, w = class_mask.shape\n",
    "    rgb_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "    for class_idx, rgb in REVERSE_CLASS_MAP.items():\n",
    "        rgb_mask[class_mask == class_idx] = rgb\n",
    "\n",
    "    return Image.fromarray(rgb_mask)\n",
    "\n",
    "def generate_and_save(gen_model, dataloader, save_dir, device, num_samples=491):\n",
    "    os.makedirs(os.path.join(save_dir, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, \"masks\"), exist_ok=True)\n",
    "\n",
    "    gen_model.eval()\n",
    "    saved = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mask_batch, _ in dataloader:\n",
    "            mask_batch = mask_batch.to(device)\n",
    "            fake_imgs = gen_model(mask_batch)\n",
    "\n",
    "            for i in range(mask_batch.size(0)):\n",
    "                if saved >= num_samples:\n",
    "                    print(f\"âœ… Done saving {saved} image-mask pairs.\")\n",
    "                    return\n",
    "\n",
    "                img = fake_imgs[i]\n",
    "                mask = mask_batch[i]\n",
    "\n",
    "                # Save image\n",
    "                save_image(img, os.path.join(save_dir, \"images\", f\"img_{saved:03d}.png\"), normalize=True)\n",
    "\n",
    "                # Save colored mask\n",
    "                colored_mask = class_to_colored_mask(mask)\n",
    "                colored_mask.save(os.path.join(save_dir, \"masks\", f\"mask_{saved:03d}.png\"))\n",
    "\n",
    "                saved += 1\n",
    "\n",
    "    print(f\"âœ… Done saving {saved} image-mask pairs.\")\n",
    "\n",
    "\n",
    "generate_and_save(gen, val_loader, r\"D:\\Updated\\synthetic_dataset\", device, num_samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_save(gen, val_loader, r\"D:\\Updated\\synthetic_dataset\", device, num_samples=520)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "save_dir = r\"D:\\Updated\\synthetic_dataset\"\n",
    "gen_path = os.path.join(save_dir, 'pix2pix_generator.pth')\n",
    "disc_path = os.path.join(save_dir, 'pix2pix_discriminator.pth')\n",
    "torch.save(gen.state_dict(), gen_path)\n",
    "torch.save(disc.state_dict(), disc_path)\n",
    "print(f\"ðŸ§  Generator saved to {gen_path}\")\n",
    "print(f\"ðŸ›¡ï¸ Discriminator saved to {disc_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gen = Pix2PixGenerator(in_channels=1, out_channels=3).to(device)\n",
    "disc = Pix2PixDiscriminator(in_channels=4).to(device)\n",
    "\n",
    "train_pix2pix(gen, disc, train_loader, device, num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "CLASS_MAP = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0,    # Background\n",
    "}\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "def rgb_to_class(mask):\n",
    "    mask = np.array(mask)\n",
    "    class_mask = np.zeros(mask.shape[:2], dtype=np.int64)\n",
    "\n",
    "    for rgb, cls in CLASS_MAP.items():\n",
    "        match = np.all(mask == rgb, axis=-1)\n",
    "        class_mask[match] = cls\n",
    "\n",
    "    return class_mask\n",
    "\n",
    "class CustomColorMaskDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, size=(128, 128)):\n",
    "        self.image_paths = sorted([os.path.join(image_dir, fname) for fname in os.listdir(image_dir)])\n",
    "        self.mask_paths = sorted([os.path.join(mask_dir, fname) for fname in os.listdir(mask_dir)])\n",
    "        self.size = size\n",
    "\n",
    "        self.image_transform = transforms.Compose([\n",
    "            transforms.Resize(size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5]*3, [0.5]*3),\n",
    "        ])\n",
    "        self.mask_transform = transforms.Compose([\n",
    "            transforms.Resize(size, interpolation=Image.NEAREST),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        mask = Image.open(self.mask_paths[idx]).convert(\"RGB\")\n",
    "\n",
    "        image = self.image_transform(image)\n",
    "        mask = self.mask_transform(mask)\n",
    "        mask = rgb_to_class(mask)\n",
    "\n",
    "        return image, torch.from_numpy(mask).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator that produces both image and mask\n",
    "class PairedGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super(PairedGenerator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Shared encoder for noise\n",
    "        self.shared_encoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512 * 7 * 7),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Shared convolutional layers\n",
    "        self.shared_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),  # 7 -> 14\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),  # 14 -> 28\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),   # 28 -> 56\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),    # 56 -> 112\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(32, 16, 4, stride=2, padding=1),    # 112 -> 224\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Separate heads for image and mask\n",
    "        self.image_head = nn.Sequential(\n",
    "            nn.Conv2d(16, 3, 3, padding=1),\n",
    "            nn.Tanh()  # Output in range [-1, 1]\n",
    "        )\n",
    "        \n",
    "        self.mask_head = nn.Sequential(\n",
    "            nn.Conv2d(16, 4, 3, padding=1),\n",
    "            nn.Softmax(dim=1)  # 4 classes with softmax\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        # Shared processing\n",
    "        x = self.shared_encoder(z)\n",
    "        x = x.view(x.size(0), 512, 7, 7)\n",
    "        x = self.shared_conv(x)\n",
    "        \n",
    "        # Generate image and mask\n",
    "        fake_image = self.image_head(x)\n",
    "        fake_mask = self.mask_head(x)\n",
    "        \n",
    "        return fake_image, fake_mask\n",
    "\n",
    "# Discriminator for both image and mask\n",
    "class PairedDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PairedDiscriminator, self).__init__()\n",
    "        \n",
    "        # Image discriminator branch\n",
    "        self.image_conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, stride=2, padding=1),  # 224 -> 112\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1),  # 112 -> 56\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Mask discriminator branch\n",
    "        self.mask_conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 4, stride=2, padding=1),  # 224 -> 112\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1),  # 112 -> 56\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Combined discriminator\n",
    "        self.combined_conv = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),  # 56 -> 28\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1),  # 28 -> 14\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 1, 4, stride=1, padding=1),     # 14 -> 13\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, image, mask):\n",
    "        # Process image and mask separately\n",
    "        img_features = self.image_conv(image)\n",
    "        \n",
    "        # Convert mask to single channel if needed\n",
    "        if mask.dim() == 4 and mask.size(1) > 1:\n",
    "            mask = torch.argmax(mask, dim=1, keepdim=True).float()\n",
    "        elif mask.dim() == 3:\n",
    "            mask = mask.unsqueeze(1).float()\n",
    "        \n",
    "        mask_features = self.mask_conv(mask)\n",
    "        \n",
    "        # Combine features\n",
    "        combined = torch.cat([img_features, mask_features], dim=1)\n",
    "        output = self.combined_conv(combined)\n",
    "        \n",
    "        return output\n",
    "\n",
    "def train_paired_gan(generator, discriminator, dataloader, device, num_epochs=500, latent_dim=100):\n",
    "    # Optimizers\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Loss functions\n",
    "    criterion_GAN = nn.BCELoss()\n",
    "    criterion_CE = nn.CrossEntropyLoss()\n",
    "    criterion_L1 = nn.L1Loss()\n",
    "    \n",
    "    # Learning rate schedulers\n",
    "    scheduler_G = optim.lr_scheduler.ReduceLROnPlateau(optimizer_G, 'min', patience=10, factor=0.5)\n",
    "    scheduler_D = optim.lr_scheduler.ReduceLROnPlateau(optimizer_D, 'min', patience=10, factor=0.5)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss_G = 0\n",
    "        epoch_loss_D = 0\n",
    "        \n",
    "        for i, (real_images, real_masks) in enumerate(dataloader):\n",
    "            batch_size = real_images.size(0)\n",
    "            \n",
    "            # Move to device\n",
    "            real_images = real_images.to(device)\n",
    "            real_masks = real_masks.to(device)\n",
    "            \n",
    "            # Create labels\n",
    "            real_labels = torch.ones(batch_size, 1, 13, 13).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1, 13, 13).to(device)\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            # Real pairs\n",
    "            real_output = discriminator(real_images, real_masks)\n",
    "            loss_D_real = criterion_GAN(real_output, real_labels)\n",
    "            \n",
    "            # Fake pairs\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_images, fake_masks = generator(z)\n",
    "            fake_output = discriminator(fake_images.detach(), fake_masks.detach())\n",
    "            loss_D_fake = criterion_GAN(fake_output, fake_labels)\n",
    "            \n",
    "            # Total discriminator loss\n",
    "            loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # Generate fake pairs\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_images, fake_masks = generator(z)\n",
    "            \n",
    "            # Adversarial loss\n",
    "            fake_output = discriminator(fake_images, fake_masks)\n",
    "            loss_G_GAN = criterion_GAN(fake_output, real_labels)\n",
    "            \n",
    "            # Additional losses for better quality (optional)\n",
    "            # You can add feature matching loss, perceptual loss, etc.\n",
    "            \n",
    "            # Total generator loss\n",
    "            loss_G = loss_G_GAN\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            epoch_loss_G += loss_G.item()\n",
    "            epoch_loss_D += loss_D.item()\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f\"Epoch [{epoch}/{num_epochs}], Batch [{i}/{len(dataloader)}], \"\n",
    "                      f\"Loss D: {loss_D.item():.4f}, Loss G: {loss_G.item():.4f}\")\n",
    "        \n",
    "        # Average losses\n",
    "        avg_loss_G = epoch_loss_G / len(dataloader)\n",
    "        avg_loss_D = epoch_loss_D / len(dataloader)\n",
    "        \n",
    "        # Step schedulers\n",
    "        scheduler_G.step(avg_loss_G)\n",
    "        scheduler_D.step(avg_loss_D)\n",
    "        \n",
    "        print(f\"Epoch [{epoch}/{num_epochs}] - Avg Loss D: {avg_loss_D:.4f}, Avg Loss G: {avg_loss_G:.4f}\")\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# generator = PairedGenerator(latent_dim=100).to(device)\n",
    "# discriminator = PairedDiscriminator().to(device)\n",
    "# train_paired_gan(generator, discriminator, train_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_generated_images(fake_images, fake_masks, num_images=3):\n",
    "    \"\"\"Display generated images and corresponding masks.\"\"\"\n",
    "    fake_images = (fake_images + 1) / 2  # Convert from [-1, 1] to [0, 1] for visualization\n",
    "    fake_masks = torch.argmax(fake_masks, dim=1)  # Convert one-hot encoded mask to class indices\n",
    "\n",
    "    # Convert tensor to numpy arrays for visualization\n",
    "    fake_images = fake_images.cpu().detach().numpy()  # Shape: [B, 3, 224, 224]\n",
    "    fake_masks = fake_masks.cpu().detach().numpy()  # Shape: [B, 224, 224]\n",
    "    \n",
    "    # Plotting num_images samples\n",
    "    for i in range(num_images):\n",
    "        # Create a subplot for each generated image-mask pair\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        \n",
    "        # Show the generated image\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(np.transpose(fake_images[i], (1, 2, 0)))  # Convert from [3, H, W] to [H, W, 3]\n",
    "        plt.title(f\"Generated Image {i + 1}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Show the corresponding mask\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(fake_masks[i], cmap='tab20b')  # Using a color map for multi-class masks\n",
    "        plt.title(f\"Generated Mask {i + 1}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "def train_paired_gan(generator, discriminator, dataloader, device, num_epochs=500, latent_dim=100, show_every_epoch=5, num_samples=3):\n",
    "    # Optimizers\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Loss functions\n",
    "    criterion_GAN = nn.BCELoss()\n",
    "    criterion_CE = nn.CrossEntropyLoss()\n",
    "    criterion_L1 = nn.L1Loss()\n",
    "    \n",
    "    # Learning rate schedulers\n",
    "    scheduler_G = optim.lr_scheduler.ReduceLROnPlateau(optimizer_G, 'min', patience=10, factor=0.5)\n",
    "    scheduler_D = optim.lr_scheduler.ReduceLROnPlateau(optimizer_D, 'min', patience=10, factor=0.5)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss_G = 0\n",
    "        epoch_loss_D = 0\n",
    "        \n",
    "        for i, (real_images, real_masks) in enumerate(dataloader):\n",
    "            batch_size = real_images.size(0)\n",
    "            \n",
    "            # Move to device\n",
    "            real_images = real_images.to(device)\n",
    "            real_masks = real_masks.to(device)\n",
    "            \n",
    "            # Create labels\n",
    "            real_labels = torch.ones(batch_size, 1, 13, 13).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1, 13, 13).to(device)\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            # Real pairs\n",
    "            real_output = discriminator(real_images, real_masks)\n",
    "            loss_D_real = criterion_GAN(real_output, real_labels)\n",
    "            \n",
    "            # Fake pairs\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_images, fake_masks = generator(z)\n",
    "            fake_output = discriminator(fake_images.detach(), fake_masks.detach())\n",
    "            loss_D_fake = criterion_GAN(fake_output, fake_labels)\n",
    "            \n",
    "            # Total discriminator loss\n",
    "            loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # Generate fake pairs\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_images, fake_masks = generator(z)\n",
    "            \n",
    "            # Adversarial loss\n",
    "            fake_output = discriminator(fake_images, fake_masks)\n",
    "            loss_G_GAN = criterion_GAN(fake_output, real_labels)\n",
    "            \n",
    "            # Additional losses for better quality (optional)\n",
    "            # You can add feature matching loss, perceptual loss, etc.\n",
    "            \n",
    "            # Total generator loss\n",
    "            loss_G = loss_G_GAN\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            epoch_loss_G += loss_G.item()\n",
    "            epoch_loss_D += loss_D.item()\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f\"Epoch [{epoch}/{num_epochs}], Batch [{i}/{len(dataloader)}], \"\n",
    "                      f\"Loss D: {loss_D.item():.4f}, Loss G: {loss_G.item():.4f}\")\n",
    "        \n",
    "        # Average losses\n",
    "        avg_loss_G = epoch_loss_G / len(dataloader)\n",
    "        avg_loss_D = epoch_loss_D / len(dataloader)\n",
    "        \n",
    "        # Step schedulers\n",
    "        scheduler_G.step(avg_loss_G)\n",
    "        scheduler_D.step(avg_loss_D)\n",
    "        \n",
    "        print(f\"Epoch [{epoch}/{num_epochs}] - Avg Loss D: {avg_loss_D:.4f}, Avg Loss G: {avg_loss_G:.4f}\")\n",
    "        \n",
    "        # Visualize every 'show_every_epoch' epochs\n",
    "        if (epoch + 1) % show_every_epoch == 0:\n",
    "            # Generate some samples after every 5 epochs\n",
    "            with torch.no_grad():\n",
    "                z = torch.randn(num_samples, latent_dim).to(device)\n",
    "                fake_images, fake_masks = generator(z)\n",
    "                show_generated_images(fake_images, fake_masks, num_images=num_samples)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = PairedGenerator(latent_dim=100).to(device)\n",
    "discriminator = PairedDiscriminator().to(device)\n",
    "train_paired_gan(generator, discriminator, train_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_pairs(generator, device, num_samples=100, latent_dim=100):\n",
    "    \"\"\"Generate synthetic image-mask pairs for testing.\"\"\"\n",
    "    generator.eval()\n",
    "    synthetic_images = []\n",
    "    synthetic_masks = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, num_samples, 16):  # Generate in batches\n",
    "            batch_size = min(16, num_samples - i)\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            \n",
    "            fake_images, fake_masks = generator(z)\n",
    "            \n",
    "            # Convert to numpy for saving\n",
    "            fake_images = fake_images.cpu().numpy()\n",
    "            fake_masks = torch.argmax(fake_masks, dim=1).cpu().numpy()\n",
    "            \n",
    "            synthetic_images.extend(fake_images)\n",
    "            synthetic_masks.extend(fake_masks)\n",
    "    \n",
    "    return synthetic_images, synthetic_masks\n",
    "\n",
    "Generate synthetic pairs for testing\n",
    "synthetic_images, synthetic_masks = generate_synthetic_pairs(generator, device, num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),  # 224 -> 112\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),  # 112 -> 56\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),  # 56 -> 28\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),  # 28 -> 56\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),  # 56 -> 112\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),  # 112 -> 224\n",
    "            nn.Tanh(),  # Output images in range [-1, 1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(6, 64, 4, stride=2, padding=1),  # Concatenate image (3) and mask (3) (6 channels)\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 1, 4, stride=1, padding=1),  # Output single probability per patch\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pix2pix(generator, discriminator, train_dataloader, device, num_epochs=500):\n",
    "    # Optimizers\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Loss functions\n",
    "    criterion_GAN = nn.MSELoss()\n",
    "    criterion_L1 = nn.L1Loss()\n",
    "    \n",
    "    # Learning rate schedulers\n",
    "    scheduler_G = optim.lr_scheduler.ReduceLROnPlateau(optimizer_G, 'min', patience=5, factor=0.5)\n",
    "    scheduler_D = optim.lr_scheduler.ReduceLROnPlateau(optimizer_D, 'min', patience=5, factor=0.5)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss_G = 0\n",
    "        epoch_loss_D = 0\n",
    "        \n",
    "        for i, (real_image, real_mask) in enumerate(train_dataloader):\n",
    "            batch_size = real_image.size(0)\n",
    "            \n",
    "            # Move to device\n",
    "            real_image = real_image.to(device)  # [B, 3, 224, 224]\n",
    "            real_mask = real_mask.to(device)    # [B, 4, 224, 224] (one-hot)\n",
    "            \n",
    "            # Convert one-hot mask to single channel for generator input\n",
    "            mask_single_channel = torch.argmax(real_mask, dim=1, keepdim=True).float()  # [B, 1, 224, 224]\n",
    "            \n",
    "            # Create labels\n",
    "            real_labels = torch.ones(batch_size, 1, 28, 28).to(device)  # Adjust size based on discriminator output\n",
    "            fake_labels = torch.zeros(batch_size, 1, 28, 28).to(device)\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            # Real pairs (image + mask)\n",
    "            real_input = torch.cat((real_image, mask_single_channel), 1)  # [B, 4, 224, 224]\n",
    "            real_output = discriminator(real_input)\n",
    "            loss_D_real = criterion_GAN(real_output, real_labels)\n",
    "            \n",
    "            # Generate fake mask\n",
    "            fake_mask = generator(real_image)  # [B, 4, 224, 224] (one-hot output)\n",
    "            fake_mask_single = torch.argmax(fake_mask, dim=1, keepdim=True).float()  # [B, 1, 224, 224]\n",
    "            \n",
    "            # Fake pairs (image + generated mask)\n",
    "            fake_input = torch.cat((real_image, fake_mask_single.detach()), 1)\n",
    "            fake_output = discriminator(fake_input)\n",
    "            loss_D_fake = criterion_GAN(fake_output, fake_labels)\n",
    "            \n",
    "            # Total discriminator loss\n",
    "            loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # Generate fake mask\n",
    "            fake_mask = generator(real_image)  # [B, 4, 224, 224]\n",
    "            fake_mask_single = torch.argmax(fake_mask, dim=1, keepdim=True).float()  # [B, 1, 224, 224]\n",
    "            \n",
    "            # Adversarial loss\n",
    "            fake_input = torch.cat((real_image, fake_mask_single), 1)\n",
    "            fake_output = discriminator(fake_input)\n",
    "            loss_G_GAN = criterion_GAN(fake_output, real_labels)\n",
    "            \n",
    "            # L1 loss (pixel-wise loss between one-hot encoded masks)\n",
    "            loss_G_L1 = criterion_L1(fake_mask, real_mask) * 100\n",
    "            \n",
    "            # Total generator loss\n",
    "            loss_G = loss_G_GAN + loss_G_L1\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            epoch_loss_G += loss_G.item()\n",
    "            epoch_loss_D += loss_D.item()\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f\"Epoch [{epoch}/{num_epochs}], Batch [{i}/{len(train_dataloader)}], \"\n",
    "                      f\"Loss D: {loss_D.item():.4f}, Loss G: {loss_G.item():.4f}\")\n",
    "        \n",
    "        # Average losses for the epoch\n",
    "        avg_loss_G = epoch_loss_G / len(train_dataloader)\n",
    "        avg_loss_D = epoch_loss_D / len(train_dataloader)\n",
    "        \n",
    "        # Step schedulers\n",
    "        scheduler_G.step(avg_loss_G)\n",
    "        scheduler_D.step(avg_loss_D)\n",
    "        \n",
    "        print(f\"Epoch [{epoch}/{num_epochs}] completed - Avg Loss D: {avg_loss_D:.4f}, Avg Loss G: {avg_loss_G:.4f}\")\n",
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "train_pix2pix(generator, discriminator, train_dataloader, device, num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the generator and discriminator\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss functions\n",
    "criterion_GAN = nn.MSELoss()  # Adversarial loss\n",
    "criterion_L1 = nn.L1Loss()    # L1 loss for image quality\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler_G = optim.lr_scheduler.ReduceLROnPlateau(optimizer_G, 'min', patience=5, factor=0.5)\n",
    "scheduler_D = optim.lr_scheduler.ReduceLROnPlateau(optimizer_D, 'min', patience=5, factor=0.5)\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (real_image, real_mask) in enumerate(train_dataloader):\n",
    "        # During training, make sure that both images and masks are on the correct device\n",
    "        real_image, real_mask = real_image.to(device), real_mask.to(device)\n",
    "        \n",
    "        # Debugging: Check the shape of the real_image and real_mask before modification\n",
    "        print(f\"Before processing - real_image shape: {real_image.shape}\")\n",
    "        print(f\"Before processing - real_mask shape: {real_mask.shape}\")\n",
    "        \n",
    "        # If the mask is one-hot encoded (i.e., it has more than one channel)\n",
    "        if real_mask.size(1) > 1:  # If more than one channel, it's one-hot encoded\n",
    "            real_mask = real_mask.argmax(dim=1, keepdim=False)  # Convert to single-channel mask\n",
    "            # Debugging: Check the shape of the real_mask after argmax\n",
    "            print(f\"After argmax - real_mask shape: {real_mask.shape}\")\n",
    "        \n",
    "        print(f\"real_image shape (expected): {real_image.shape}\")\n",
    "        print(f\"real_mask shape (expected): {real_mask.shape}\")\n",
    "        \n",
    "        # Concatenate the real image and real mask along the channel dimension (dimension 1)\n",
    "        real_input = torch.cat((real_image, real_mask), 1)  # Now real_input should have shape (batch_size, 4, 224, 224)\n",
    "        \n",
    "        # Debugging: Check the shape of the concatenated tensor\n",
    "        print(f\"real_input shape after concatenation: {real_input.shape}\")\n",
    "        \n",
    "        # Forward pass through the discriminator\n",
    "        real_output = discriminator(real_input)  # (batch_size, 1, 224, 224)\n",
    "        loss_D_real = criterion_GAN(real_output, torch.ones_like(real_output))  # Real labels are 1\n",
    "\n",
    "# Continue with the rest of your training code...\n",
    "\n",
    "        \n",
    "        # Train the Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # Generator adversarial loss\n",
    "        fake_output = discriminator(torch.cat((real_image, fake_image), 1))\n",
    "        loss_G_GAN = criterion_GAN(fake_output, torch.ones_like(fake_output))\n",
    "        \n",
    "        # L1 loss for image quality\n",
    "        loss_G_L1 = criterion_L1(fake_image, real_mask) * 100  # Weight the L1 loss\n",
    "        \n",
    "        # Total Generator Loss\n",
    "        loss_G = loss_G_GAN + loss_G_L1\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    # Scheduler step\n",
    "    scheduler_G.step(loss_G)\n",
    "    scheduler_D.step(loss_D)\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}], Loss D: {loss_D.item()}, Loss G: {loss_G.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "\n",
    "# Constants for 224x224\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "CHANNELS = 3  # RGB images\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "# Class mapping from RGB to class index\n",
    "CLASS_MAP = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0,  # Background\n",
    "}\n",
    "\n",
    "# Directory paths for your dataset\n",
    "image_dir = r\"D:\\augmented_dataset\\images\"\n",
    "mask_dir = r\"D:\\augmented_dataset\\masks\"\n",
    "\n",
    "train_image_dir = r\"D:\\Updated\\train\\images\"\n",
    "train_mask_dir = r\"D:\\Updated\\train\\masks\"\n",
    "val_image_dir = r\"D:\\Updated\\val\\images\"\n",
    "val_mask_dir = r\"D:\\Updated\\val\\masks\"\n",
    "\n",
    "# Function to naturally sort filenames\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "# Convert RGB mask to class index mask\n",
    "def rgb_to_class(mask_array):\n",
    "    height, width, _ = mask_array.shape\n",
    "    class_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    for rgb, class_idx in CLASS_MAP.items():\n",
    "        matches = np.all(mask_array == rgb, axis=-1)\n",
    "        class_mask[matches] = class_idx\n",
    "    return class_mask\n",
    "\n",
    "# Preprocess dataset\n",
    "def preprocess_filtered_dataset(image_dir, mask_dir):\n",
    "    image_filenames = sorted(os.listdir(image_dir), key=natural_sort_key)\n",
    "    mask_filenames = sorted(os.listdir(mask_dir), key=natural_sort_key)\n",
    "\n",
    "    valid_image_paths = []\n",
    "    valid_mask_paths = []\n",
    "\n",
    "    for img_file, mask_file in zip(image_filenames, mask_filenames):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "        if os.path.exists(img_path) and os.path.exists(mask_path):\n",
    "            valid_image_paths.append(img_path)\n",
    "            valid_mask_paths.append(mask_path)\n",
    "        else:\n",
    "            print(f\"âš ï¸ Skipping {img_file}: Missing image or mask\")\n",
    "\n",
    "    num_images = len(valid_image_paths)\n",
    "    X = np.zeros((num_images, IMG_HEIGHT, IMG_WIDTH, CHANNELS), dtype=np.float32)\n",
    "    y = np.zeros((num_images, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES), dtype=np.float32)\n",
    "\n",
    "    for idx, (img_path, mask_path) in enumerate(zip(valid_image_paths, valid_mask_paths)):\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "\n",
    "        mask = cv2.imread(mask_path)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        class_mask = rgb_to_class(mask)\n",
    "        one_hot_mask = to_categorical(class_mask, num_classes=NUM_CLASSES)\n",
    "\n",
    "        X[idx] = img\n",
    "        y[idx] = one_hot_mask\n",
    "\n",
    "        del img, mask, class_mask, one_hot_mask\n",
    "        gc.collect()\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Load dataset\n",
    "X_train, y_train = preprocess_filtered_dataset(train_image_dir, train_mask_dir)\n",
    "X_val, y_val = preprocess_filtered_dataset(val_image_dir, val_mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# Generator: Takes noise and produces both image and mask\n",
    "def build_maskgan_generator(latent_dim=100):\n",
    "    \"\"\"\n",
    "    Generator that takes random noise and produces both image and corresponding mask\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=(latent_dim,))\n",
    "    \n",
    "    # Start with dense layer and reshape\n",
    "    x = layers.Dense(7 * 7 * 512)(inputs)  # 7*7*512 = 25088\n",
    "    x = layers.Reshape((7, 7, 512))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Upsampling: 7x7 -> 14x14\n",
    "    x = layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Upsampling: 14x14 -> 28x28\n",
    "    x = layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Upsampling: 28x28 -> 56x56\n",
    "    x = layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Upsampling: 56x56 -> 112x112\n",
    "    x = layers.Conv2DTranspose(32, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Upsampling: 112x112 -> 224x224\n",
    "    x = layers.Conv2DTranspose(16, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Output branches\n",
    "    # Image output: 3 channels (RGB), values in [-1, 1]\n",
    "    image_output = layers.Conv2D(3, kernel_size=3, activation='tanh', padding='same', name='image_output')(x)\n",
    "    \n",
    "    # Mask output: 4 classes, softmax activation\n",
    "    mask_output = layers.Conv2D(4, kernel_size=3, activation='softmax', padding='same', name='mask_output')(x)\n",
    "    \n",
    "    return Model(inputs, [image_output, mask_output], name='generator')\n",
    "\n",
    "# Discriminator: Takes image and mask pairs and determines if they're real or fake\n",
    "def build_maskgan_discriminator():\n",
    "    \"\"\"\n",
    "    Discriminator that takes both image and mask and determines if the pair is real or fake\n",
    "    \"\"\"\n",
    "    # Two separate inputs\n",
    "    image_input = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3), name='image_input')\n",
    "    mask_input = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 4), name='mask_input')\n",
    "    \n",
    "    # Concatenate image and mask along channel dimension\n",
    "    # Result: (224, 224, 7) - 3 channels for image + 4 channels for mask\n",
    "    x = layers.Concatenate()([image_input, mask_input])\n",
    "    \n",
    "    # Convolutional layers for feature extraction\n",
    "    # 224x224 -> 112x112\n",
    "    x = layers.Conv2D(64, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # 112x112 -> 56x56\n",
    "    x = layers.Conv2D(128, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # 56x56 -> 28x28\n",
    "    x = layers.Conv2D(256, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # 28x28 -> 14x14\n",
    "    x = layers.Conv2D(512, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # 14x14 -> 7x7\n",
    "    x = layers.Conv2D(1024, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Final classification\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)  # Output: probability of being real\n",
    "    \n",
    "    return Model([image_input, mask_input], x, name='discriminator')\n",
    "\n",
    "# Combined GAN model\n",
    "def build_maskgan(generator, discriminator):\n",
    "    \"\"\"\n",
    "    Combined GAN model for training the generator\n",
    "    \"\"\"\n",
    "    # Freeze discriminator weights during generator training\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    # Input: random noise\n",
    "    gan_input = layers.Input(shape=(100,))  # latent dimension\n",
    "    \n",
    "    # Generate image and mask\n",
    "    gen_image, gen_mask = generator(gan_input)\n",
    "    \n",
    "    # Discriminator evaluates the generated pair\n",
    "    gan_output = discriminator([gen_image, gen_mask])\n",
    "    \n",
    "    return Model(gan_input, gan_output, name='maskgan')\n",
    "\n",
    "# Initialize the models\n",
    "print(\"ðŸš€ Building MaskGAN models...\")\n",
    "\n",
    "# Create models\n",
    "generator = build_maskgan_generator(latent_dim=100)\n",
    "discriminator = build_maskgan_discriminator()\n",
    "gan_model = build_maskgan(generator, discriminator)\n",
    "\n",
    "# Compile models\n",
    "discriminator.compile(\n",
    "    optimizer=Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "gan_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "\n",
    "# Print model summaries\n",
    "print(\"\\nðŸ“Š Generator Summary:\")\n",
    "generator.summary()\n",
    "\n",
    "print(\"\\nðŸ“Š Discriminator Summary:\")\n",
    "discriminator.summary()\n",
    "\n",
    "print(\"\\nðŸ“Š GAN Model Summary:\")\n",
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Constants\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "def build_maskgan_generator(latent_dim=100):\n",
    "    \"\"\"\n",
    "    Generator that produces both image and mask from noise\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=(latent_dim,))\n",
    "    \n",
    "    # Dense and reshape\n",
    "    x = layers.Dense(14 * 14 * 512)(inputs)\n",
    "    x = layers.Reshape((14, 14, 512))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # 14x14 -> 28x28\n",
    "    x = layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # 28x28 -> 56x56\n",
    "    x = layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # 56x56 -> 112x112\n",
    "    x = layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # 112x112 -> 224x224\n",
    "    x = layers.Conv2DTranspose(32, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # Output layers\n",
    "    image_output = layers.Conv2D(3, kernel_size=3, activation='tanh', padding='same', name='image_output')(x)\n",
    "    mask_output = layers.Conv2D(4, kernel_size=3, activation='softmax', padding='same', name='mask_output')(x)\n",
    "    \n",
    "    return Model(inputs, [image_output, mask_output], name='generator')\n",
    "\n",
    "def build_maskgan_discriminator():\n",
    "    \"\"\"\n",
    "    Discriminator that takes image and mask pair\n",
    "    \"\"\"\n",
    "    image_input = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3), name='image_input')\n",
    "    mask_input = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 4), name='mask_input')\n",
    "    \n",
    "    # Concatenate inputs\n",
    "    x = layers.Concatenate()([image_input, mask_input])\n",
    "    \n",
    "    # Convolutional layers\n",
    "    x = layers.Conv2D(64, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Conv2D(256, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Conv2D(512, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Final layers\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    return Model([image_input, mask_input], x, name='discriminator')\n",
    "\n",
    "def build_maskgan(generator, discriminator):\n",
    "    \"\"\"\n",
    "    Combined GAN model\n",
    "    \"\"\"\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    gan_input = layers.Input(shape=(100,))\n",
    "    gen_image, gen_mask = generator(gan_input)\n",
    "    gan_output = discriminator([gen_image, gen_mask])\n",
    "    \n",
    "    return Model(gan_input, gan_output, name='maskgan')\n",
    "\n",
    "# Debugging and data validation functions\n",
    "def validate_data(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Validate input data and print statistics\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸ” Data Validation:\")\n",
    "    print(f\"X_train shape: {X_train.shape}, dtype: {X_train.dtype}\")\n",
    "    print(f\"X_train range: [{X_train.min():.3f}, {X_train.max():.3f}]\")\n",
    "    print(f\"y_train shape: {y_train.shape}, dtype: {y_train.dtype}\")\n",
    "    print(f\"y_train range: [{y_train.min():.3f}, {y_train.max():.3f}]\")\n",
    "    \n",
    "    # Check if masks are one-hot encoded\n",
    "    mask_sums = np.sum(y_train, axis=-1)\n",
    "    print(f\"Mask sum statistics: mean={mask_sums.mean():.3f}, std={mask_sums.std():.3f}\")\n",
    "    \n",
    "    # Check class distribution\n",
    "    class_counts = np.sum(y_train, axis=(0, 1, 2))\n",
    "    print(f\"Class distribution: {class_counts}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def debug_discriminator_inputs(real_images, real_masks, fake_images, fake_masks):\n",
    "    \"\"\"\n",
    "    Debug discriminator inputs\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸ” Discriminator Input Debug:\")\n",
    "    print(f\"Real images: {real_images.shape}, range: [{real_images.min():.3f}, {real_images.max():.3f}]\")\n",
    "    print(f\"Real masks: {real_masks.shape}, range: [{real_masks.min():.3f}, {real_masks.max():.3f}]\")\n",
    "    print(f\"Fake images: {fake_images.shape}, range: [{fake_images.min():.3f}, {fake_images.max():.3f}]\")\n",
    "    print(f\"Fake masks: {fake_masks.shape}, range: [{fake_masks.min():.3f}, {fake_masks.max():.3f}]\")\n",
    "\n",
    "# Initialize models\n",
    "print(\"ðŸš€ Building MaskGAN models...\")\n",
    "generator = build_maskgan_generator(latent_dim=100)\n",
    "discriminator = build_maskgan_discriminator()\n",
    "gan_model = build_maskgan(generator, discriminator)\n",
    "\n",
    "# Compile with proper metrics\n",
    "discriminator.compile(\n",
    "    optimizer=Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "gan_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“Š Model Architecture:\")\n",
    "print(f\"Generator parameters: {generator.count_params():,}\")\n",
    "print(f\"Discriminator parameters: {discriminator.count_params():,}\")\n",
    "\n",
    "def train_maskgan_debug(generator, discriminator, gan_model, X_train, y_train, epochs=50, batch_size=16):\n",
    "    \"\"\"\n",
    "    Training function with extensive debugging\n",
    "    \"\"\"\n",
    "    # Validate data first\n",
    "    validate_data(X_train, y_train)\n",
    "    \n",
    "    batches_per_epoch = len(X_train) // batch_size\n",
    "    print(f\"\\nðŸŽ¯ Training Setup:\")\n",
    "    print(f\"Total samples: {len(X_train)}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Batches per epoch: {batches_per_epoch}\")\n",
    "    print(f\"Epochs: {epochs}\")\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'd_loss_real': [],\n",
    "        'd_loss_fake': [],\n",
    "        'd_acc_real': [],\n",
    "        'd_acc_fake': [],\n",
    "        'g_loss': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nðŸ“ˆ Epoch {epoch + 1}/{epochs}\")\n",
    "        \n",
    "        epoch_d_loss_real = []\n",
    "        epoch_d_loss_fake = []\n",
    "        epoch_d_acc_real = []\n",
    "        epoch_d_acc_fake = []\n",
    "        epoch_g_loss = []\n",
    "        \n",
    "        for batch_idx in range(batches_per_epoch):\n",
    "            # Get real batch\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "            real_images = X_train[start_idx:end_idx]\n",
    "            real_masks = y_train[start_idx:end_idx]\n",
    "            \n",
    "            # Generate fake batch\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "            fake_images, fake_masks = generator.predict(noise, verbose=0)\n",
    "            \n",
    "            # Debug first batch of first epoch\n",
    "            if epoch == 0 and batch_idx == 0:\n",
    "                debug_discriminator_inputs(real_images, real_masks, fake_images, fake_masks)\n",
    "            \n",
    "            # Create labels - NO LABEL SMOOTHING for debugging\n",
    "            real_labels = np.ones((batch_size, 1))\n",
    "            fake_labels = np.zeros((batch_size, 1))\n",
    "            \n",
    "            # Train discriminator on real data\n",
    "            d_loss_real = discriminator.train_on_batch([real_images, real_masks], real_labels)\n",
    "            \n",
    "            # Train discriminator on fake data\n",
    "            d_loss_fake = discriminator.train_on_batch([fake_images, fake_masks], fake_labels)\n",
    "            \n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "            g_loss = gan_model.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            # Store losses\n",
    "            epoch_d_loss_real.append(d_loss_real[0])\n",
    "            epoch_d_loss_fake.append(d_loss_fake[0])\n",
    "            epoch_d_acc_real.append(d_loss_real[1])\n",
    "            epoch_d_acc_fake.append(d_loss_fake[1])\n",
    "            epoch_g_loss.append(g_loss)\n",
    "            \n",
    "            # Print progress\n",
    "            if batch_idx % 50 == 0:\n",
    "                print(f\"  Batch {batch_idx}/{batches_per_epoch}:\")\n",
    "                print(f\"    D_real: {d_loss_real[0]:.4f} (acc: {d_loss_real[1]:.3f})\")\n",
    "                print(f\"    D_fake: {d_loss_fake[0]:.4f} (acc: {d_loss_fake[1]:.3f})\")\n",
    "                print(f\"    G_loss: {g_loss:.4f}\")\n",
    "                \n",
    "                # Additional debugging for first few batches\n",
    "                if batch_idx < 3:\n",
    "                    # Test discriminator predictions\n",
    "                    real_pred = discriminator.predict([real_images[:1], real_masks[:1]], verbose=0)\n",
    "                    fake_pred = discriminator.predict([fake_images[:1], fake_masks[:1]], verbose=0)\n",
    "                    print(f\"    Real prediction: {real_pred[0][0]:.4f}\")\n",
    "                    print(f\"    Fake prediction: {fake_pred[0][0]:.4f}\")\n",
    "        \n",
    "        # Calculate epoch averages\n",
    "        avg_d_loss_real = np.mean(epoch_d_loss_real)\n",
    "        avg_d_loss_fake = np.mean(epoch_d_loss_fake)\n",
    "        avg_d_acc_real = np.mean(epoch_d_acc_real)\n",
    "        avg_d_acc_fake = np.mean(epoch_d_acc_fake)\n",
    "        avg_g_loss = np.mean(epoch_g_loss)\n",
    "        \n",
    "        # Store in history\n",
    "        history['d_loss_real'].append(avg_d_loss_real)\n",
    "        history['d_loss_fake'].append(avg_d_loss_fake)\n",
    "        history['d_acc_real'].append(avg_d_acc_real)\n",
    "        history['d_acc_fake'].append(avg_d_acc_fake)\n",
    "        history['g_loss'].append(avg_g_loss)\n",
    "        \n",
    "        print(f\"ðŸ“Š Epoch {epoch + 1} Summary:\")\n",
    "        print(f\"  D_loss_real: {avg_d_loss_real:.4f} (acc: {avg_d_acc_real:.3f})\")\n",
    "        print(f\"  D_loss_fake: {avg_d_loss_fake:.4f} (acc: {avg_d_acc_fake:.3f})\")\n",
    "        print(f\"  G_loss: {avg_g_loss:.4f}\")\n",
    "        \n",
    "        # Generate sample images\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            save_debug_samples(generator, epoch + 1)\n",
    "    \n",
    "    return history\n",
    "\n",
    "def save_debug_samples(generator, epoch, num_samples=4):\n",
    "    \"\"\"\n",
    "    Save sample images with detailed analysis\n",
    "    \"\"\"\n",
    "    noise = np.random.normal(0, 1, (num_samples, 100))\n",
    "    gen_images, gen_masks = generator.predict(noise, verbose=0)\n",
    "    \n",
    "    # Convert images from [-1, 1] to [0, 1]\n",
    "    gen_images_display = (gen_images + 1) / 2\n",
    "    \n",
    "    # Get mask class predictions\n",
    "    gen_masks_class = np.argmax(gen_masks, axis=-1)\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig, axes = plt.subplots(4, num_samples, figsize=(16, 16))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Original generated image\n",
    "        axes[0, i].imshow(gen_images_display[i])\n",
    "        axes[0, i].set_title(f'Generated Image {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Class mask\n",
    "        axes[1, i].imshow(gen_masks_class[i], cmap='tab10', vmin=0, vmax=3)\n",
    "        axes[1, i].set_title(f'Class Mask {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # Brain probability (class 1)\n",
    "        axes[2, i].imshow(gen_masks[i][:, :, 1], cmap='hot', vmin=0, vmax=1)\n",
    "        axes[2, i].set_title(f'Brain Prob {i+1}')\n",
    "        axes[2, i].axis('off')\n",
    "        \n",
    "        # Mask entropy (uncertainty)\n",
    "        mask_entropy = -np.sum(gen_masks[i] * np.log(gen_masks[i] + 1e-8), axis=-1)\n",
    "        axes[3, i].imshow(mask_entropy, cmap='viridis')\n",
    "        axes[3, i].set_title(f'Mask Entropy {i+1}')\n",
    "        axes[3, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'debug_samples_epoch_{epoch}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"ðŸ’¾ Debug samples saved: debug_samples_epoch_{epoch}.png\")\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"ðŸ“Š Generation Statistics:\")\n",
    "    print(f\"  Image range: [{gen_images.min():.3f}, {gen_images.max():.3f}]\")\n",
    "    print(f\"  Mask range: [{gen_masks.min():.3f}, {gen_masks.max():.3f}]\")\n",
    "    print(f\"  Mask sum range: [{np.sum(gen_masks, axis=-1).min():.3f}, {np.sum(gen_masks, axis=-1).max():.3f}]\")\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot comprehensive training history\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(history['d_loss_real']) + 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Discriminator losses\n",
    "    axes[0, 0].plot(epochs, history['d_loss_real'], label='D_loss_real')\n",
    "    axes[0, 0].plot(epochs, history['d_loss_fake'], label='D_loss_fake')\n",
    "    axes[0, 0].set_title('Discriminator Losses')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Discriminator accuracies\n",
    "    axes[0, 1].plot(epochs, history['d_acc_real'], label='D_acc_real')\n",
    "    axes[0, 1].plot(epochs, history['d_acc_fake'], label='D_acc_fake')\n",
    "    axes[0, 1].set_title('Discriminator Accuracies')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Generator loss\n",
    "    axes[1, 0].plot(epochs, history['g_loss'], label='G_loss', color='red')\n",
    "    axes[1, 0].set_title('Generator Loss')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Loss')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # Combined view\n",
    "    axes[1, 1].plot(epochs, history['d_loss_real'], label='D_loss_real', alpha=0.7)\n",
    "    axes[1, 1].plot(epochs, history['d_loss_fake'], label='D_loss_fake', alpha=0.7)\n",
    "    axes[1, 1].plot(epochs, history['g_loss'], label='G_loss', alpha=0.7)\n",
    "    axes[1, 1].set_title('All Losses Combined')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Loss')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history_debug.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Test the model\n",
    "print(\"\\nðŸ§ª Testing model compatibility...\")\n",
    "noise = np.random.normal(0, 1, (1, 100))\n",
    "gen_image, gen_mask = generator.predict(noise, verbose=0)\n",
    "print(f\"âœ… Generator outputs: Image {gen_image.shape}, Mask {gen_mask.shape}\")\n",
    "\n",
    "disc_output = discriminator.predict([gen_image, gen_mask], verbose=0)\n",
    "print(f\"âœ… Discriminator output: {disc_output.shape}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Debug version ready!\")\n",
    "print(\"\\nðŸ“ Usage:\")\n",
    "print(\"# Make sure your data is properly normalized:\")\n",
    "print(\"X_train_normalized = (X_train * 2) - 1  # Convert [0,1] to [-1,1]\")\n",
    "print(\"# Start debug training:\")\n",
    "print(\"history = train_maskgan_debug(generator, discriminator, gan_model, X_train_normalized, y_train, epochs=50, batch_size=16)\")\n",
    "print(\"# Plot results:\")\n",
    "print(\"plot_training_history(history)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure proper normalization\n",
    "X_train_normalized = (X_train * 2) - 1  # Convert [0,1] to [-1,1]\n",
    "\n",
    "# Start debug training with fewer epochs\n",
    "history = train_maskgan_debug(generator, discriminator, gan_model, \n",
    "                             X_train_normalized, y_train, epochs=20, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure proper normalization\n",
    "X_train_normalized = (X_train * 2) - 1  # Convert [0,1] to [-1,1]\n",
    "\n",
    "# Start debug training with fewer epochs\n",
    "history = train_maskgan_debug(generator, discriminator, gan_model, \n",
    "                             X_train_normalized, y_train, epochs=4000, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_maskgan_generator((IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES))\n",
    "discriminator = build_maskgan_discriminator((IMG_HEIGHT, IMG_WIDTH, 3))  # Image size (3 channels)\n",
    "gan_model = build_maskgan(generator, discriminator)\n",
    "\n",
    "# Compile the models\n",
    "discriminator.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')\n",
    "gan_model.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')\n",
    "\n",
    "train_maskgan(generator, discriminator, gan_model, X_train, y_train, epochs=1000, batch_size=16, visualize_interval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import re\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# âœ… Constants for 224x224\n",
    "IMG_HEIGHT = 224  # Ensure height is 224\n",
    "IMG_WIDTH = 224   # Ensure width is 224\n",
    "CHANNELS = 3  # RGB images\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "# âœ… Class mapping from RGB to class index\n",
    "CLASS_MAP = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0,  # Background\n",
    "}\n",
    "\n",
    "image_dir = r\"D:\\augmented_dataset\\images\"\n",
    "mask_dir = r\"D:\\augmented_dataset\\masks\"\n",
    "\n",
    "# # âœ… Define destination directories\n",
    "train_image_dir = r\"D:\\Updated\\train\\images\"\n",
    "train_mask_dir = r\"D:\\Updated\\train\\masks\"\n",
    "val_image_dir = r\"D:\\Updated\\val\\images\"\n",
    "val_mask_dir = r\"D:\\Updated\\val\\masks\"\n",
    "test_image_dir = r\"D:\\Updated\\test\\images\"\n",
    "test_mask_dir = r\"D:\\Updated\\test\\masks\"\n",
    "\n",
    "# âœ… Fix sorting issue using natural sorting\n",
    "def natural_sort_key(s):\n",
    "    \"\"\"Sort filenames numerically instead of lexicographically.\"\"\"\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "# âœ… Convert RGB mask to class index mask\n",
    "def rgb_to_class(mask_array):\n",
    "    \"\"\"Convert RGB mask to single-channel class index mask.\"\"\"\n",
    "    height, width, _ = mask_array.shape\n",
    "    class_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    for rgb, class_idx in CLASS_MAP.items():\n",
    "        matches = np.all(mask_array == rgb, axis=-1)  # Ensure exact match\n",
    "        class_mask[matches] = class_idx\n",
    "\n",
    "    return class_mask\n",
    "\n",
    "# âœ… Preprocess Filtered Dataset for 224x224\n",
    "def preprocess_filtered_dataset(image_dir, mask_dir):\n",
    "    \"\"\"Preprocess images & masks: normalize, resize, and convert masks to one-hot encoding.\"\"\"\n",
    "\n",
    "    # âœ… Load and sort filenames correctly\n",
    "    image_filenames = sorted(os.listdir(image_dir), key=natural_sort_key)\n",
    "    mask_filenames = sorted(os.listdir(mask_dir), key=natural_sort_key)\n",
    "\n",
    "    valid_image_paths = []\n",
    "    valid_mask_paths = []\n",
    "\n",
    "    # âœ… Ensure each image has a corresponding mask\n",
    "    for img_file, mask_file in zip(image_filenames, mask_filenames):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "        if os.path.exists(img_path) and os.path.exists(mask_path):\n",
    "            valid_image_paths.append(img_path)\n",
    "            valid_mask_paths.append(mask_path)\n",
    "        else:\n",
    "            print(f\"âš ï¸ Skipping {img_file}: Missing image or mask\")\n",
    "\n",
    "    num_images = len(valid_image_paths)\n",
    "\n",
    "    # âœ… Initialize arrays\n",
    "    X = np.zeros((num_images, IMG_HEIGHT, IMG_WIDTH, CHANNELS), dtype=np.float32)\n",
    "    y = np.zeros((num_images, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES), dtype=np.float32)  # One-hot encoded masks\n",
    "\n",
    "    print(f\"ðŸš€ Processing {num_images} filtered images and masks...\")\n",
    "\n",
    "    for idx, (img_path, mask_path) in enumerate(zip(valid_image_paths, valid_mask_paths)):\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"âœ… Processed {idx}/{num_images} images\")\n",
    "\n",
    "        # âœ… Load and Resize Image\n",
    "        img = cv2.imread(img_path)  # Read image in BGR format\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))  # Resize to (224,224)\n",
    "        img = img.astype(np.float32) / 255.0  # Normalize\n",
    "\n",
    "        # âœ… Load and Resize Mask\n",
    "        mask = cv2.imread(mask_path)  # Read mask in BGR format\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)  # Resize mask correctly\n",
    "\n",
    "        # âœ… Convert RGB mask to class mask\n",
    "        class_mask = rgb_to_class(mask)\n",
    "\n",
    "        # âœ… One-hot encode the class mask\n",
    "        one_hot_mask = to_categorical(class_mask, num_classes=NUM_CLASSES)\n",
    "\n",
    "        # âœ… Store preprocessed data\n",
    "        X[idx] = img\n",
    "        y[idx] = one_hot_mask\n",
    "\n",
    "        # âœ… Clear memory to prevent memory leaks\n",
    "        del img, mask, class_mask, one_hot_mask\n",
    "        gc.collect()\n",
    "\n",
    "    return X, y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # âœ… Process dataset splits\n",
    "X_train, y_train = preprocess_filtered_dataset(train_image_dir, train_mask_dir)\n",
    "# X_val, y_val = preprocess_filtered_dataset(val_image_dir, val_mask_dir)\n",
    "# X_test, y_test = preprocess_filtered_dataset(test_image_dir, test_mask_dir)\n",
    "\n",
    "# âœ… Print dataset information\n",
    "print(\"\\nâœ… Dataset Splits:\")\n",
    "print(f\"  - Training set: {X_train.shape}, {y_train.shape}\")\n",
    "# print(f\"  - Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "# print(f\"  - Test set: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = preprocess_filtered_dataset(val_image_dir, val_mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Constants for 224x224 images\n",
    "IMG_HEIGHT = 224  # Changed from 256 to 224\n",
    "IMG_WIDTH = 224   # Changed from 256 to 224\n",
    "CHANNELS = 3  # RGB images\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "def conv_block(inputs, filters, kernel_size=(3, 3), padding='same', strides=1):\n",
    "    \"\"\"\n",
    "    Double convolution block with batch normalization\n",
    "    \"\"\"\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=strides, padding=padding)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters, kernel_size, padding=padding)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_segnet(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Build SegNet model\n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    # Block 1\n",
    "    conv1 = conv_block(inputs, 64)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(conv1)\n",
    "    \n",
    "    # Block 2\n",
    "    conv2 = conv_block(pool1, 128)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(conv2)\n",
    "    \n",
    "    # Block 3\n",
    "    conv3 = conv_block(pool2, 256)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(conv3)\n",
    "    \n",
    "    # Block 4\n",
    "    conv4 = conv_block(pool3, 512)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(conv4)\n",
    "    \n",
    "    # Bridge\n",
    "    conv5 = conv_block(pool4, 1024)\n",
    "    \n",
    "    # Decoder\n",
    "    # Block 4\n",
    "    up4 = layers.UpSampling2D(size=(2, 2))(conv5)\n",
    "    up4 = layers.concatenate([up4, conv4], axis=-1)\n",
    "    up_conv4 = conv_block(up4, 512)\n",
    "    \n",
    "    # Block 3\n",
    "    up3 = layers.UpSampling2D(size=(2, 2))(up_conv4)\n",
    "    up3 = layers.concatenate([up3, conv3], axis=-1)\n",
    "    up_conv3 = conv_block(up3, 256)\n",
    "    \n",
    "    # Block 2\n",
    "    up2 = layers.UpSampling2D(size=(2, 2))(up_conv3)\n",
    "    up2 = layers.concatenate([up2, conv2], axis=-1)\n",
    "    up_conv2 = conv_block(up2, 128)\n",
    "    \n",
    "    # Block 1\n",
    "    up1 = layers.UpSampling2D(size=(2, 2))(up_conv2)\n",
    "    up1 = layers.concatenate([up1, conv1], axis=-1)\n",
    "    up_conv1 = conv_block(up1, 64)\n",
    "    \n",
    "    # Output\n",
    "    outputs = layers.Conv2D(num_classes, (1, 1), activation='softmax')(up_conv1)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "model = build_segnet(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), \n",
    "                     num_classes=NUM_CLASSES)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# # âœ… Dice Coefficient Metric\n",
    "# def dice_coefficient(y_true, y_pred):\n",
    "#     smooth = 1e-15\n",
    "#     y_true = tf.cast(y_true, tf.float32)\n",
    "#     y_pred = tf.cast(y_pred, tf.float32)\n",
    "#     intersection = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "#     union = tf.reduce_sum(y_true, axis=[1,2,3]) + tf.reduce_sum(y_pred, axis=[1,2,3])\n",
    "#     dice = (2. * intersection + smooth) / (union + smooth)\n",
    "#     return tf.reduce_mean(dice)\n",
    "\n",
    "# def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "#     class_weights = tf.constant([0.3794, 0.7521, 69.7061, 49.3458], dtype=tf.float32)\n",
    "\n",
    "#     # Ensure y_true has the same shape as y_pred\n",
    "#     y_true = tf.cast(y_true, tf.float32)  # Make sure it's float32 for numerical stability\n",
    "#     y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)  # Avoid log(0)\n",
    "\n",
    "#     # Compute categorical cross-entropy\n",
    "#     loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)  # Sum over the last axis (class axis)\n",
    "\n",
    "#     # Reshape the class weights to match the loss shape\n",
    "#     class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))  # [1, 1, 1, 4]\n",
    "\n",
    "#     # Apply the class weights\n",
    "#     weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)  # Broadcast weights over the batch and spatial dimensions\n",
    "\n",
    " #     return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# # âœ… Dice Loss\n",
    "# def dice_loss(y_true, y_pred):\n",
    "#     smooth = 1e-6\n",
    "#     y_true = tf.cast(y_true, y_pred.dtype)\n",
    "#     intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "#     union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "#     dice = (2. * intersection + smooth) / (union + smooth)\n",
    "#     return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# # âœ… Combined Loss Function\n",
    "# def combined_loss(y_true, y_pred):\n",
    "#     return weighted_categorical_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "# # âœ… Custom Dice Coefficient Metric for Each Class\n",
    "# class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "#     def __init__(self, class_idx, name=None, **kwargs):  \n",
    "#         if name is None:\n",
    "#             name = f\"DiceClass{class_idx}\"  \n",
    "#         super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "#         self.class_idx = class_idx\n",
    "#         self.dice = self.add_weight(name=\"dice\", initializer=\"zeros\")\n",
    "\n",
    "#     def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "#         y_true_class = y_true[..., self.class_idx]\n",
    "#         y_pred_class = y_pred[..., self.class_idx]\n",
    "\n",
    "#         intersection = tf.reduce_sum(y_true_class * y_pred_class, axis=[1, 2])\n",
    "#         union = tf.reduce_sum(y_true_class, axis=[1, 2]) + tf.reduce_sum(y_pred_class, axis=[1, 2])\n",
    "\n",
    "#         dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "#         self.dice.assign(tf.reduce_mean(dice))\n",
    "\n",
    "#     def result(self):\n",
    "#         return self.dice\n",
    "\n",
    "# # âœ… Function to Get Class-wise Metrics\n",
    "# def class_wise_metrics(num_classes=4):\n",
    "#     return [DiceCoefficient(i) for i in range(num_classes)] + [tf.keras.metrics.MeanIoU(num_classes=num_classes)]\n",
    "\n",
    "# # âœ… Compile the Model\n",
    "# model.compile(\n",
    "#     optimizer=Adam(learning_rate=1e-4),\n",
    "#     loss=combined_loss,\n",
    "#     metrics=class_wise_metrics(4)  # Number of classes (adjust if needed)\n",
    "# )\n",
    "\n",
    "# # âœ… Train the Model with the **Filtered Dataset**\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,  # Use the loaded and split data\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     epochs=50,\n",
    "#     batch_size=16,  # Adjust based on available resources\n",
    "#     callbacks=[\n",
    "#         EarlyStopping(\n",
    "#             monitor='val_loss', \n",
    "#             patience=7, \n",
    "#             restore_best_weights=True\n",
    "#         ),\n",
    "#         ReduceLROnPlateau(\n",
    "#             monitor='val_loss', \n",
    "#             factor=0.5, \n",
    "#             patience=3, \n",
    "#             min_lr=1e-6\n",
    "#         ),\n",
    "#         ModelCheckpoint(\n",
    "#             '/kaggle/working/best_unet_model_filtered.keras',  # Save in Kaggle working directory with .keras extension\n",
    "#             monitor='val_loss',\n",
    "#             save_best_only=True\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# âœ… Dice Coefficient Metric\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1,2,3]) + tf.reduce_sum(y_pred, axis=[1,2,3])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "# âœ… Weighted Categorical Crossentropy\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    class_weights = tf.constant([0.3776, 0.7605, 65.8554, 46.2381], dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "    class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))\n",
    "    weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)\n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# âœ… Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# âœ… Custom Dice Coefficient Metric for Each Class\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_idx, name=None, **kwargs):  \n",
    "        if name is None:\n",
    "            name = f\"DiceClass{class_idx}\"  \n",
    "        super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        self.class_idx = class_idx\n",
    "        self.dice = self.add_weight(name=\"dice\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_class = y_true[..., self.class_idx]\n",
    "        y_pred_class = y_pred[..., self.class_idx]\n",
    "        intersection = tf.reduce_sum(y_true_class * y_pred_class, axis=[1, 2])\n",
    "        union = tf.reduce_sum(y_true_class, axis=[1, 2]) + tf.reduce_sum(y_pred_class, axis=[1, 2])\n",
    "        dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "        self.dice.assign(tf.reduce_mean(dice))\n",
    "\n",
    "    def result(self):\n",
    "        return self.dice\n",
    "\n",
    "# âœ… Function to Get Class-wise Metrics\n",
    "def class_wise_metrics(num_classes=4):\n",
    "    return [DiceCoefficient(i) for i in range(num_classes)] + [tf.keras.metrics.MeanIoU(num_classes=num_classes)]\n",
    "\n",
    "# âœ… Create Data Generator\n",
    "def create_train_generator(X, y, batch_size=16):\n",
    "    data_gen_args = dict(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    \n",
    "    seed = 42\n",
    "    image_generator = image_datagen.flow(X, batch_size=batch_size, seed=seed)\n",
    "    mask_generator = mask_datagen.flow(y, batch_size=batch_size, seed=seed)\n",
    "    \n",
    "    while True:\n",
    "        X_batch = next(image_generator)\n",
    "        y_batch = next(mask_generator)\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "# âœ… Create the generator\n",
    "train_generator = create_train_generator(X_train, y_train, batch_size=16)\n",
    "\n",
    "# âœ… Compile the Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# âœ… Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "def lovasz_softmax_loss(y_true, y_pred, ignore_background=False):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    num_classes = tf.shape(y_true)[-1]\n",
    "    start_class = tf.constant(1 if ignore_background else 0)\n",
    "\n",
    "    def compute_class_loss(c):\n",
    "        y_true_class = y_true[..., c]\n",
    "        y_pred_class = y_pred[..., c]\n",
    "\n",
    "        y_true_flat = tf.reshape(y_true_class, [-1])\n",
    "        y_pred_flat = tf.reshape(y_pred_class, [-1])\n",
    "\n",
    "        errors = tf.abs(y_true_flat - y_pred_flat)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], sorted=True)\n",
    "        y_true_sorted = tf.gather(y_true_flat, perm)\n",
    "\n",
    "        gts = tf.reduce_sum(y_true_sorted)\n",
    "        intersection = gts - tf.cumsum(y_true_sorted)\n",
    "        union = gts + tf.cumsum(1. - y_true_sorted)\n",
    "        jaccard = 1. - intersection / union\n",
    "        grad = tf.concat([[jaccard[0]], jaccard[1:] - jaccard[:-1]], 0)\n",
    "\n",
    "        return tf.tensordot(errors_sorted, grad, axes=1)\n",
    "\n",
    "    # Loop through each class using tf.while_loop\n",
    "    losses = tf.TensorArray(dtype=tf.float32, size=num_classes)\n",
    "\n",
    "    def loop_cond(c, losses):\n",
    "        return tf.less(c, num_classes)\n",
    "\n",
    "    def loop_body(c, losses):\n",
    "        loss_c = compute_class_loss(c)\n",
    "        losses = losses.write(c, loss_c)\n",
    "        return c + 1, losses\n",
    "\n",
    "    _, losses = tf.while_loop(loop_cond, loop_body, [start_class, losses])\n",
    "    return tf.reduce_mean(losses.stack())\n",
    "\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss_val = 1 - tf.reduce_mean(dice)\n",
    "\n",
    "    lovasz_loss_val = lovasz_softmax_loss(y_true, tf.nn.softmax(y_pred), ignore_background=False)\n",
    "\n",
    "    return lovasz_loss_val + dice_loss_val\n",
    "\n",
    "\n",
    "# Usage in model compilation\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(4)  # Number of classes\n",
    ")\n",
    "\n",
    "# âœ… Train the Model with the Data Generator\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(X_train) // 16,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=10, \n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss', \n",
    "            factor=0.5, \n",
    "            patience=3, \n",
    "            min_lr=1e-6\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            'best_unet_model_onlineDA_128_lovaszloss_segnet.keras',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Number of classes (adjust if needed)\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# âœ… Dice Coefficient (Mean across all classes)\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "# âœ… Weighted Categorical Crossentropy\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    class_weights = tf.constant([0.3776, 0.7605, 65.8554, 46.2381], dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "    class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))\n",
    "    weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)\n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# âœ… Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# âœ… LovÃ¡sz-Softmax Loss\n",
    "def lovasz_softmax_loss(y_true, y_pred, ignore_background=False):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    num_classes = tf.shape(y_true)[-1]\n",
    "    start_class = tf.constant(1 if ignore_background else 0)\n",
    "\n",
    "    def compute_class_loss(c):\n",
    "        y_true_class = y_true[..., c]\n",
    "        y_pred_class = y_pred[..., c]\n",
    "\n",
    "        y_true_flat = tf.reshape(y_true_class, [-1])\n",
    "        y_pred_flat = tf.reshape(y_pred_class, [-1])\n",
    "\n",
    "        errors = tf.abs(y_true_flat - y_pred_flat)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], sorted=True)\n",
    "        y_true_sorted = tf.gather(y_true_flat, perm)\n",
    "\n",
    "        gts = tf.reduce_sum(y_true_sorted)\n",
    "        intersection = gts - tf.cumsum(y_true_sorted)\n",
    "        union = gts + tf.cumsum(1. - y_true_sorted)\n",
    "        jaccard = 1. - intersection / union\n",
    "        grad = tf.concat([[jaccard[0]], jaccard[1:] - jaccard[:-1]], 0)\n",
    "\n",
    "        return tf.tensordot(errors_sorted, grad, axes=1)\n",
    "\n",
    "    # Loop through classes using tf.while_loop\n",
    "    losses = tf.TensorArray(dtype=tf.float32, size=num_classes)\n",
    "\n",
    "    def loop_cond(c, losses):\n",
    "        return tf.less(c, num_classes)\n",
    "\n",
    "    def loop_body(c, losses):\n",
    "        loss_c = compute_class_loss(c)\n",
    "        losses = losses.write(c, loss_c)\n",
    "        return c + 1, losses\n",
    "\n",
    "    _, losses = tf.while_loop(loop_cond, loop_body, [start_class, losses])\n",
    "    return tf.reduce_mean(losses.stack())\n",
    "\n",
    "# âœ… Combined Loss\n",
    "def combined_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice_loss_val = 1 - (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss_val = tf.reduce_mean(dice_loss_val)\n",
    "    \n",
    "    lovasz_loss_val = lovasz_softmax_loss(y_true, tf.nn.softmax(y_pred), ignore_background=False)\n",
    "    return lovasz_loss_val + dice_loss_val\n",
    "\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_idx=0, name=None, **kwargs):  # <- default class_idx=0 to avoid missing arg\n",
    "        if name is None:\n",
    "            name = f\"DiceClass{class_idx}\"\n",
    "        super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        self.class_idx = class_idx\n",
    "        self.dice = self.add_weight(name=\"dice\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_class = y_true[..., self.class_idx]\n",
    "        y_pred_class = y_pred[..., self.class_idx]\n",
    "        intersection = tf.reduce_sum(y_true_class * y_pred_class, axis=[1, 2])\n",
    "        union = tf.reduce_sum(y_true_class, axis=[1, 2]) + tf.reduce_sum(y_pred_class, axis=[1, 2])\n",
    "        dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "        self.dice.assign(tf.reduce_mean(dice))\n",
    "\n",
    "    def result(self):\n",
    "        return self.dice\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"class_idx\": self.class_idx})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        if \"class_idx\" not in config:\n",
    "            # Try to extract class index from name like \"DiceClass2\"\n",
    "            name = config.get(\"name\", \"DiceClass0\")\n",
    "            if name.startswith(\"DiceClass\"):\n",
    "                config[\"class_idx\"] = int(name.replace(\"DiceClass\", \"\"))\n",
    "            else:\n",
    "                config[\"class_idx\"] = 0\n",
    "        return cls(**config)\n",
    "\n",
    "# âœ… Helper to load Dice metrics by name\n",
    "def dice_metric_loader(name):\n",
    "    if name.startswith(\"DiceClass\"):\n",
    "        class_idx = int(name.replace(\"DiceClass\", \"\"))\n",
    "        return DiceCoefficient(class_idx=class_idx)\n",
    "    raise ValueError(f\"Unknown Dice metric name: {name}\")\n",
    "\n",
    "# âœ… Register all custom objects for loading the model\n",
    "custom_objects = {\n",
    "    'combined_loss': combined_loss,\n",
    "    'lovasz_softmax_loss': lovasz_softmax_loss,\n",
    "    'MeanIoU': tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES),\n",
    "    'DiceCoefficient': DiceCoefficient,\n",
    "}\n",
    "\n",
    "# âœ… Add DiceClass0â€“3 dynamically\n",
    "for i in range(NUM_CLASSES):\n",
    "    custom_objects[f'DiceClass{i}'] = dice_metric_loader(f'DiceClass{i}')\n",
    "\n",
    "# âœ… Load the model\n",
    "model_segnet = load_model('C:\\\\Users\\\\User\\\\best_unet_model_onlineDA_128_lovaszloss_segnet.keras', custom_objects=custom_objects)\n",
    "\n",
    "print(\"âœ… Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class ImageMaskGenerator(Sequence):\n",
    "    def __init__(self, image_paths, mask_paths, batch_size=4, num_classes=4, img_size=(224, 224), shuffle=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.image_paths))\n",
    "        self.CLASS_MAP = {\n",
    "            (255, 0, 0): 1,\n",
    "            (0, 255, 0): 2,\n",
    "            (0, 0, 255): 3,\n",
    "            (0, 0, 0): 0,\n",
    "        }\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_images = []\n",
    "        batch_masks = []\n",
    "\n",
    "        for i in batch_indices:\n",
    "            img = cv2.imread(self.image_paths[i])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, self.img_size)\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "\n",
    "            mask = cv2.imread(self.mask_paths[i])\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "            mask = cv2.resize(mask, self.img_size, interpolation=cv2.INTER_NEAREST)\n",
    "            mask = self.rgb_to_class(mask)\n",
    "            mask = tf.keras.utils.to_categorical(mask, num_classes=self.num_classes)\n",
    "\n",
    "            batch_images.append(img)\n",
    "            batch_masks.append(mask)\n",
    "\n",
    "        return np.array(batch_images), np.array(batch_masks)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def rgb_to_class(self, mask_array):\n",
    "        h, w, _ = mask_array.shape\n",
    "        class_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "        for rgb, class_idx in self.CLASS_MAP.items():\n",
    "            matches = np.all(mask_array == rgb, axis=-1)\n",
    "            class_mask[matches] = class_idx\n",
    "        return class_mask\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "def load_paths(image_dir, mask_dir):\n",
    "    images = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.png')])\n",
    "    masks = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith('.png')])\n",
    "    return images, masks\n",
    "\n",
    "train_imgs, train_masks = load_paths(train_image_dir, train_mask_dir)\n",
    "val_imgs, val_masks = load_paths(val_image_dir, val_mask_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageMaskGenerator(train_imgs, train_masks, batch_size=8)\n",
    "val_gen = ImageMaskGenerator(val_imgs, val_masks, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(X_train, y_train, X_val, y_val, batch_size=8, epochs=3, repeats=1):\n",
    "    from tensorflow.keras import backend as K\n",
    "    import gc\n",
    "\n",
    "    epoch_times_all = []\n",
    "    power_samples_all = []\n",
    "\n",
    "    for r in range(repeats):\n",
    "        print(f\"\\nðŸ” Repeat {r+1}/{repeats}\")\n",
    "\n",
    "        # Clean up previous session\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "        model = tf.keras.models.load_model(\n",
    "            'C:\\\\Users\\\\User\\\\best_unet_model_onlineDA_128_lovaszloss_segnet.keras',\n",
    "            custom_objects=custom_objects\n",
    "        )\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Power monitoring\n",
    "        power_proc = subprocess.Popen(\n",
    "            ['nvidia-smi', '--query-gpu=power.draw', '--format=csv,noheader,nounits', '-lms', '500'],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "            text=True\n",
    "        )\n",
    "\n",
    "        # # Train all epochs in one go\n",
    "        # model.fit(\n",
    "        #     X_train, y_train,\n",
    "        #     batch_size=batch_size,\n",
    "        #     epochs=epochs,\n",
    "        #     validation_data=(X_val, y_val),\n",
    "        #     verbose=1\n",
    "        # )\n",
    "        model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=epochs,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "\n",
    "        end = time.time()\n",
    "        total_time = end - start\n",
    "        avg_epoch_time = total_time / epochs\n",
    "        epoch_times_all.extend([avg_epoch_time] * epochs)\n",
    "\n",
    "        # Handle power logs\n",
    "        power_proc.terminate()\n",
    "        try:\n",
    "            power_output = power_proc.stdout.read().strip().split('\\n')\n",
    "            power_values = [float(line) for line in power_output if line.strip()]\n",
    "            avg_power = np.mean(power_values)\n",
    "            power_samples_all.extend([avg_power] * epochs)\n",
    "            print(f\"âš¡ Avg Power: {avg_power:.2f} W\")\n",
    "        except:\n",
    "            print(\"âš ï¸ Power log failed.\")\n",
    "            power_samples_all.extend([np.nan] * epochs)\n",
    "\n",
    "        # Final cleanup\n",
    "        del model\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "\n",
    "    return epoch_times_all, power_samples_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_times, power_vals = run_training(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Compute stats\n",
    "epoch_times = np.array(epoch_times)\n",
    "power_vals = np.array(power_vals)\n",
    "\n",
    "mean_time = np.mean(epoch_times)\n",
    "std_time = np.std(epoch_times)\n",
    "\n",
    "mean_power = np.nanmean(power_vals)\n",
    "energy_per_epoch_wh = (mean_power * mean_time) / 3600\n",
    "\n",
    "# Estimate GFLOPS per epoch (assuming 4 GFLOPs/sample)\n",
    "samples_per_epoch = len(X_train)\n",
    "estimated_flops_per_sample = 4e9  # 4 GFLOPs\n",
    "gflops = (2 * estimated_flops_per_sample * samples_per_epoch) / (mean_time * 1e9)\n",
    "\n",
    "print(\"\\nðŸ“Š Summary:\")\n",
    "print(f\"â±ï¸  Average epoch time: {mean_time:.2f} Â± {std_time:.2f} sec\")\n",
    "print(f\"âš™ï¸  Estimated GFLOPS: {gflops:.2f}\")\n",
    "print(f\"âš¡ Average power: {mean_power:.2f} W\")\n",
    "print(f\"ðŸ”‹ Energy per epoch: {energy_per_epoch_wh:.4f} Wh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, Concatenate, BatchNormalization, Activation\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "import gc\n",
    "\n",
    "# Constants\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "class ResizeLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"Custom layer to resize images.\"\"\"\n",
    "    def __init__(self, target_size, **kwargs):\n",
    "        super(ResizeLayer, self).__init__(**kwargs)\n",
    "        self.target_size = target_size\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.image.resize(inputs, self.target_size, method='bilinear')\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(ResizeLayer, self).get_config()\n",
    "        config.update({\"target_size\": self.target_size})\n",
    "        return config\n",
    "\n",
    "def conv_block(x, filters, kernel_size=3, padding='same', activation='relu'):\n",
    "    \"\"\"Helper function for creating a conv block with BN and activation.\"\"\"\n",
    "    x = Conv2D(filters, kernel_size, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    # Add a second conv to increase parameters\n",
    "    x = Conv2D(filters, kernel_size, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "def build_full_inceptionresnetv2_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), num_classes=NUM_CLASSES):\n",
    "    \"\"\"\n",
    "    Build a full UNet model with InceptionResNetV2 backbone with 60-70M parameters\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Input shape of the image\n",
    "        num_classes: Number of output classes\n",
    "        \n",
    "    Returns:\n",
    "        Keras Model instance with UNet architecture\n",
    "    \"\"\"\n",
    "    # Input layer (no fixed batch size)\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Create a full InceptionResNetV2 model to use as backbone\n",
    "    base_model = InceptionResNetV2(\n",
    "        input_tensor=inputs,\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling=None\n",
    "    )\n",
    "    \n",
    "    # Make all layers trainable as requested\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Extract features from all encoder levels\n",
    "    # Standard blocks in InceptionResNetV2\n",
    "    encoder1 = base_model.get_layer('activation').output  # 111x111x64\n",
    "    encoder2 = base_model.get_layer('activation_3').output  # 55x55x192\n",
    "    encoder3 = base_model.get_layer('block35_10_ac').output  # 27x27x320\n",
    "    encoder4 = base_model.get_layer('block17_20_ac').output  # 13x13x1088\n",
    "    encoder5 = base_model.get_layer('conv_7b_ac').output  # 6x6x2080\n",
    "    \n",
    "    # Use the bottleneck as is - don't reduce its channels\n",
    "    bottleneck = encoder5  # 6x6x2080\n",
    "    \n",
    "    # First, reduce the bottleneck dimensions to control parameter count\n",
    "    bottleneck = Conv2D(512, 1, padding='same')(bottleneck)\n",
    "    bottleneck = BatchNormalization()(bottleneck)\n",
    "    bottleneck = Activation('relu')(bottleneck)\n",
    "    \n",
    "    # Level 5 to 4: 6x6 -> 13x13\n",
    "    up4 = UpSampling2D(size=(2, 2))(bottleneck)\n",
    "    up4 = ResizeLayer(target_size=(encoder4.shape[1], encoder4.shape[2]))(up4)\n",
    "    up4 = conv_block(up4, 512, kernel_size=3)  # Reduced filters\n",
    "    \n",
    "    # Reduce skip connection channels before concatenation\n",
    "    skip4 = Conv2D(256, 1, padding='same')(encoder4)\n",
    "    skip4 = BatchNormalization()(skip4)\n",
    "    skip4 = Activation('relu')(skip4)\n",
    "    \n",
    "    # Concatenate with skip connection\n",
    "    merge4 = Concatenate()([up4, skip4])\n",
    "    merge4 = conv_block(merge4, 384)  # Reduced filters\n",
    "    \n",
    "    # Level 4 to 3: 13x13 -> 27x27\n",
    "    up3 = UpSampling2D(size=(2, 2))(merge4)\n",
    "    up3 = ResizeLayer(target_size=(encoder3.shape[1], encoder3.shape[2]))(up3)\n",
    "    up3 = conv_block(up3, 384, kernel_size=3)  # Reduced filters\n",
    "    \n",
    "    # Reduce skip connection channels\n",
    "    skip3 = Conv2D(128, 1, padding='same')(encoder3)\n",
    "    skip3 = BatchNormalization()(skip3)\n",
    "    skip3 = Activation('relu')(skip3)\n",
    "    \n",
    "    # Concatenate with skip connection\n",
    "    merge3 = Concatenate()([up3, skip3])\n",
    "    merge3 = conv_block(merge3, 192)  # Reduced filters\n",
    "    \n",
    "    # Level 3 to 2: 27x27 -> 55x55\n",
    "    up2 = UpSampling2D(size=(2, 2))(merge3)\n",
    "    up2 = ResizeLayer(target_size=(encoder2.shape[1], encoder2.shape[2]))(up2)\n",
    "    up2 = conv_block(up2, 192, kernel_size=3)  # Reduced filters\n",
    "    \n",
    "    # Reduce skip connection channels\n",
    "    skip2 = Conv2D(96, 1, padding='same')(encoder2)\n",
    "    skip2 = BatchNormalization()(skip2)\n",
    "    skip2 = Activation('relu')(skip2)\n",
    "    \n",
    "    # Concatenate with skip connection\n",
    "    merge2 = Concatenate()([up2, skip2])\n",
    "    merge2 = conv_block(merge2, 96)  # Reduced filters\n",
    "    \n",
    "    # Level 2 to 1: 55x55 -> 111x111\n",
    "    up1 = UpSampling2D(size=(2, 2))(merge2)\n",
    "    up1 = ResizeLayer(target_size=(encoder1.shape[1], encoder1.shape[2]))(up1)\n",
    "    up1 = conv_block(up1, 96, kernel_size=3)  # Reduced filters\n",
    "    \n",
    "    # Reduce skip connection channels\n",
    "    skip1 = Conv2D(48, 1, padding='same')(encoder1)\n",
    "    skip1 = BatchNormalization()(skip1)\n",
    "    skip1 = Activation('relu')(skip1)\n",
    "    \n",
    "    # Concatenate with skip connection\n",
    "    merge1 = Concatenate()([up1, skip1])\n",
    "    merge1 = conv_block(merge1, 48)  # Reduced filters\n",
    "    \n",
    "    # Final upsampling to original resolution: 111x111 -> 224x224\n",
    "    up_final = UpSampling2D(size=(2, 2))(merge1)\n",
    "    up_final = conv_block(up_final, 32)  # Reduced filters\n",
    "    \n",
    "    # Ensure final size matches input\n",
    "    if up_final.shape[1] != input_shape[0] or up_final.shape[2] != input_shape[1]:\n",
    "        up_final = ResizeLayer(target_size=(input_shape[0], input_shape[1]))(up_final)\n",
    "    \n",
    "    # Add a final segmentation head\n",
    "    outputs = Conv2D(num_classes, 1, activation='softmax', dtype='float32')(up_final)\n",
    "    \n",
    "    # Create and return the model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "print(\"Creating full InceptionResNetV2-UNet model...\")\n",
    "model = build_full_inceptionresnetv2_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), num_classes=NUM_CLASSES)\n",
    "print(\"Model created successfully!\")\n",
    "\n",
    "# Clear memory\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "class ResizeLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"Custom layer to resize images.\"\"\"\n",
    "    def __init__(self, target_size, **kwargs):\n",
    "        super(ResizeLayer, self).__init__(**kwargs)\n",
    "        self.target_size = target_size\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.image.resize(inputs, self.target_size, method='bilinear')\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(ResizeLayer, self).get_config()\n",
    "        config.update({\"target_size\": self.target_size})\n",
    "        return config\n",
    "\n",
    "# Number of classes (adjust if needed)\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# âœ… Dice Coefficient (Mean across all classes)\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "# âœ… Weighted Categorical Crossentropy\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    class_weights = tf.constant([0.3776, 0.7605, 65.8554, 46.2381], dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "    class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))\n",
    "    weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)\n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# âœ… Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# âœ… LovÃ¡sz-Softmax Loss\n",
    "def lovasz_softmax_loss(y_true, y_pred, ignore_background=False):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    num_classes = tf.shape(y_true)[-1]\n",
    "    start_class = tf.constant(1 if ignore_background else 0)\n",
    "\n",
    "    def compute_class_loss(c):\n",
    "        y_true_class = y_true[..., c]\n",
    "        y_pred_class = y_pred[..., c]\n",
    "\n",
    "        y_true_flat = tf.reshape(y_true_class, [-1])\n",
    "        y_pred_flat = tf.reshape(y_pred_class, [-1])\n",
    "\n",
    "        errors = tf.abs(y_true_flat - y_pred_flat)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], sorted=True)\n",
    "        y_true_sorted = tf.gather(y_true_flat, perm)\n",
    "\n",
    "        gts = tf.reduce_sum(y_true_sorted)\n",
    "        intersection = gts - tf.cumsum(y_true_sorted)\n",
    "        union = gts + tf.cumsum(1. - y_true_sorted)\n",
    "        jaccard = 1. - intersection / union\n",
    "        grad = tf.concat([[jaccard[0]], jaccard[1:] - jaccard[:-1]], 0)\n",
    "\n",
    "        return tf.tensordot(errors_sorted, grad, axes=1)\n",
    "\n",
    "    # Loop through classes using tf.while_loop\n",
    "    losses = tf.TensorArray(dtype=tf.float32, size=num_classes)\n",
    "\n",
    "    def loop_cond(c, losses):\n",
    "        return tf.less(c, num_classes)\n",
    "\n",
    "    def loop_body(c, losses):\n",
    "        loss_c = compute_class_loss(c)\n",
    "        losses = losses.write(c, loss_c)\n",
    "        return c + 1, losses\n",
    "\n",
    "    _, losses = tf.while_loop(loop_cond, loop_body, [start_class, losses])\n",
    "    return tf.reduce_mean(losses.stack())\n",
    "\n",
    "# âœ… Combined Loss\n",
    "def combined_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice_loss_val = 1 - (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss_val = tf.reduce_mean(dice_loss_val)\n",
    "    \n",
    "    lovasz_loss_val = lovasz_softmax_loss(y_true, tf.nn.softmax(y_pred), ignore_background=False)\n",
    "    return lovasz_loss_val + dice_loss_val\n",
    "\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_idx=0, name=None, **kwargs):  # <- default class_idx=0 to avoid missing arg\n",
    "        if name is None:\n",
    "            name = f\"DiceClass{class_idx}\"\n",
    "        super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        self.class_idx = class_idx\n",
    "        self.dice = self.add_weight(name=\"dice\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_class = y_true[..., self.class_idx]\n",
    "        y_pred_class = y_pred[..., self.class_idx]\n",
    "        intersection = tf.reduce_sum(y_true_class * y_pred_class, axis=[1, 2])\n",
    "        union = tf.reduce_sum(y_true_class, axis=[1, 2]) + tf.reduce_sum(y_pred_class, axis=[1, 2])\n",
    "        dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "        self.dice.assign(tf.reduce_mean(dice))\n",
    "\n",
    "    def result(self):\n",
    "        return self.dice\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"class_idx\": self.class_idx})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        if \"class_idx\" not in config:\n",
    "            # Try to extract class index from name like \"DiceClass2\"\n",
    "            name = config.get(\"name\", \"DiceClass0\")\n",
    "            if name.startswith(\"DiceClass\"):\n",
    "                config[\"class_idx\"] = int(name.replace(\"DiceClass\", \"\"))\n",
    "            else:\n",
    "                config[\"class_idx\"] = 0\n",
    "        return cls(**config)\n",
    "\n",
    "# âœ… Helper to load Dice metrics by name\n",
    "def dice_metric_loader(name):\n",
    "    if name.startswith(\"DiceClass\"):\n",
    "        class_idx = int(name.replace(\"DiceClass\", \"\"))\n",
    "        return DiceCoefficient(class_idx=class_idx)\n",
    "    raise ValueError(f\"Unknown Dice metric name: {name}\")\n",
    "\n",
    "# âœ… Register all custom objects for loading the model\n",
    "custom_objects = {\n",
    "    'ResizeLayer': ResizeLayer,\n",
    "    'combined_loss': combined_loss,\n",
    "    'lovasz_softmax_loss': lovasz_softmax_loss,\n",
    "    'MeanIoU': tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES),\n",
    "    'DiceCoefficient': DiceCoefficient,\n",
    "}\n",
    "\n",
    "# âœ… Add DiceClass0â€“3 dynamically\n",
    "for i in range(NUM_CLASSES):\n",
    "    custom_objects[f'DiceClass{i}'] = dice_metric_loader(f'DiceClass{i}')\n",
    "\n",
    "# âœ… Load the model\n",
    "model_inceptionresnetv2 = load_model('lovaszloss_unet++_inceptionresnetv2.keras', custom_objects=custom_objects)\n",
    "\n",
    "print(\"âœ… Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAFE custom_objects (no functions returning arrays)\n",
    "custom_objects = {\n",
    "    'ResizeLayer': ResizeLayer,\n",
    "    'combined_loss': combined_loss,\n",
    "    'lovasz_softmax_loss': lovasz_softmax_loss,\n",
    "    'MeanIoU': tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES),\n",
    "    'DiceCoefficient': DiceCoefficient,  # needed to deserialize\n",
    "}\n",
    "\n",
    "# Add DiceClass0â€“3 safely as instances\n",
    "for i in range(NUM_CLASSES):\n",
    "    custom_objects[f'DiceClass{i}'] = DiceCoefficient(class_idx=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_gen, val_gen, model_path, custom_objects, batch_size=8, epochs=3, repeats=1):\n",
    "    import subprocess\n",
    "    import time\n",
    "    import numpy as np\n",
    "    from tensorflow.keras import backend as K\n",
    "    import gc\n",
    "\n",
    "    epoch_times_all = []\n",
    "    power_samples_all = []\n",
    "\n",
    "    for r in range(repeats):\n",
    "        print(f\"\\nðŸ” Repeat {r+1}/{repeats}\")\n",
    "\n",
    "        # âœ… Clean up previous session\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "        # âœ… Reload the model (InceptionResNetV2-UNet++)\n",
    "        model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n",
    "\n",
    "        # âœ… Start timing and power monitoring\n",
    "        start = time.time()\n",
    "\n",
    "        power_proc = subprocess.Popen(\n",
    "            ['nvidia-smi', '--query-gpu=power.draw', '--format=csv,noheader,nounits', '-lms', '500'],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "            text=True\n",
    "        )\n",
    "\n",
    "        # âœ… Train using generator (saves memory)\n",
    "        model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=epochs,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # âœ… Stop timing\n",
    "        end = time.time()\n",
    "        total_time = end - start\n",
    "        avg_epoch_time = total_time / epochs\n",
    "        epoch_times_all.extend([avg_epoch_time] * epochs)\n",
    "\n",
    "        # âœ… Stop and process power readings\n",
    "        power_proc.terminate()\n",
    "        try:\n",
    "            power_output = power_proc.stdout.read().strip().split('\\n')\n",
    "            power_values = [float(line) for line in power_output if line.strip()]\n",
    "            avg_power = np.mean(power_values)\n",
    "            power_samples_all.extend([avg_power] * epochs)\n",
    "            print(f\"âš¡ Avg Power: {avg_power:.2f} W\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Power log failed: {e}\")\n",
    "            power_samples_all.extend([np.nan] * epochs)\n",
    "\n",
    "        # âœ… Cleanup\n",
    "        del model\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "\n",
    "    return epoch_times_all, power_samples_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'lovaszloss_unet++_inceptionresnetv2.keras'\n",
    "\n",
    "epoch_times, power_vals = run_training(\n",
    "    train_gen=train_gen,\n",
    "    val_gen=val_gen,\n",
    "    model_path=model_path,\n",
    "    custom_objects=custom_objects,\n",
    "    batch_size=4,\n",
    "    epochs=3,\n",
    "    repeats=1\n",
    ")\n",
    "\n",
    "# Compute stats\n",
    "epoch_times = np.array(epoch_times)\n",
    "power_vals = np.array(power_vals)\n",
    "\n",
    "mean_time = np.mean(epoch_times)\n",
    "std_time = np.std(epoch_times)\n",
    "\n",
    "mean_power = np.nanmean(power_vals)\n",
    "energy_per_epoch_wh = (mean_power * mean_time) / 3600\n",
    "\n",
    "# Estimate GFLOPS per epoch (assuming 4 GFLOPs/sample)\n",
    "samples_per_epoch = len(X_train)\n",
    "estimated_flops_per_sample = 4e9  # 4 GFLOPs\n",
    "gflops = (2 * estimated_flops_per_sample * samples_per_epoch) / (mean_time * 1e9)\n",
    "\n",
    "print(\"\\nðŸ“Š Summary:\")\n",
    "print(f\"â±ï¸  Average epoch time: {mean_time:.2f} Â± {std_time:.2f} sec\")\n",
    "print(f\"âš™ï¸  Estimated GFLOPS: {gflops:.2f}\")\n",
    "print(f\"âš¡ Average power: {mean_power:.2f} W\")\n",
    "print(f\"ðŸ”‹ Energy per epoch: {energy_per_epoch_wh:.4f} Wh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Add\n",
    "from tensorflow.keras.layers import Dense, Dropout, Layer, Reshape, Permute, Multiply, Concatenate\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, LayerNormalization, UpSampling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "\n",
    "class ResizeToMatchLayer(Layer):\n",
    "    \"\"\"Layer to resize input to match target tensor's spatial dimensions.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ResizeToMatchLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x, target = inputs\n",
    "        # Get spatial dimensions of target tensor\n",
    "        target_shape = tf.shape(target)\n",
    "        target_height, target_width = target_shape[1], target_shape[2]\n",
    "        \n",
    "        # Resize x to match target's spatial dimensions\n",
    "        return tf.image.resize(x, [target_height, target_width], method='bilinear')\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[1][1], input_shape[1][2], input_shape[0][3])\n",
    "\n",
    "def conv_block(x, filters, kernel_size=3, strides=1, padding='same', use_bn=True, activation='relu'):\n",
    "    \"\"\"Standard convolution block with BatchNorm and activation.\"\"\"\n",
    "    x = Conv2D(filters, kernel_size, strides=strides, padding=padding)(x)\n",
    "    \n",
    "    if use_bn:\n",
    "        x = BatchNormalization()(x)\n",
    "    \n",
    "    if activation:\n",
    "        x = Activation(activation)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def attention_gate(x, g, inter_channels):\n",
    "    \"\"\"\n",
    "    Attention Gate as described in Attention U-Net paper.\n",
    "    Args:\n",
    "        x: Feature map from skip connection (from encoder)\n",
    "        g: Gating signal from previous decoder layer\n",
    "        inter_channels: Number of channels in intermediate representations\n",
    "    \"\"\"\n",
    "    # Resize gating signal to match feature map's spatial dimensions if needed\n",
    "    g = ResizeToMatchLayer()([g, x])\n",
    "    \n",
    "    # Intermediate representation for input feature map\n",
    "    theta_x = Conv2D(inter_channels, 1, use_bias=False, padding='same')(x)\n",
    "    \n",
    "    # Intermediate representation for gating signal\n",
    "    phi_g = Conv2D(inter_channels, 1, use_bias=False, padding='same')(g)\n",
    "    \n",
    "    # Element-wise sum and ReLU\n",
    "    f = Activation('relu')(Add()([theta_x, phi_g]))\n",
    "    \n",
    "    # 1x1 convolution followed by sigmoid to get attention coefficients\n",
    "    psi_f = Conv2D(1, 1, use_bias=False, padding='same')(f)\n",
    "    att_map = Activation('sigmoid')(psi_f)\n",
    "    \n",
    "    # Apply attention\n",
    "    return Multiply()([x, att_map])\n",
    "\n",
    "def decoder_block(x, skip_connection, filters, use_attention=True):\n",
    "    \"\"\"Decoder block for Attention U-Net.\"\"\"\n",
    "    # Upsampling\n",
    "    x = UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "    \n",
    "    # Ensure dimensions match for concatenation\n",
    "    x = ResizeToMatchLayer()([x, skip_connection])\n",
    "    \n",
    "    # Apply attention mechanism if specified\n",
    "    if use_attention:\n",
    "        # Generate attention-gated skip connection\n",
    "        skip_connection = attention_gate(skip_connection, x, filters // 2)\n",
    "    \n",
    "    # Concatenate with skip connection\n",
    "    x = Concatenate()([x, skip_connection])\n",
    "    \n",
    "    # Apply two convolution blocks\n",
    "    x = conv_block(x, filters, 3, padding='same')\n",
    "    x = conv_block(x, filters, 3, padding='same')\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_efficientnet_attention_unet(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Build an Attention U-Net model with EfficientNetB4 backbone for semantic segmentation.\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Input shape of the image (height, width, channels)\n",
    "        num_classes: Number of segmentation classes\n",
    "        \n",
    "    Returns:\n",
    "        A Keras Model instance\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "        \n",
    "    # Load EfficientNetB4 with pre-trained weights as encoder backbone\n",
    "    # All layers are trainable for fine-tuning\n",
    "    base_model = EfficientNetB4(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_tensor=inputs\n",
    "    )\n",
    "    \n",
    "    # Reduce filter count to control parameter count since we're not freezing any layers\n",
    "    initial_filters = 32\n",
    "    \n",
    "    # Get skip connections from appropriate layers\n",
    "    skip1 = base_model.get_layer('block1b_add').output        # 1/2 scale (112x112)\n",
    "    skip2 = base_model.get_layer('block2d_add').output        # 1/4 scale (56x56)\n",
    "    skip3 = base_model.get_layer('block3d_add').output        # 1/8 scale (28x28)\n",
    "    skip4 = base_model.get_layer('block5e_add').output        # 1/16 scale (14x14)\n",
    "    \n",
    "    # Bridge (bottleneck)\n",
    "    bridge = base_model.get_layer('top_activation').output    # 1/32 scale (7x7)\n",
    "    \n",
    "    \n",
    "    # Reduce channels for each skip connection to control parameter count\n",
    "    skip1_conv = conv_block(skip1, initial_filters)\n",
    "    skip2_conv = conv_block(skip2, initial_filters * 2)\n",
    "    skip3_conv = conv_block(skip3, initial_filters * 4)\n",
    "    skip4_conv = conv_block(skip4, initial_filters * 8)\n",
    "    \n",
    "    # Reduce channels in bridge\n",
    "    bridge_conv = conv_block(bridge, initial_filters * 16)\n",
    "    \n",
    "    # Decoder pathway with attention gates\n",
    "    d1 = decoder_block(bridge_conv, skip4_conv, initial_filters * 8, use_attention=True)  # 1/16\n",
    "    d2 = decoder_block(d1, skip3_conv, initial_filters * 4, use_attention=True)           # 1/8\n",
    "    d3 = decoder_block(d2, skip2_conv, initial_filters * 2, use_attention=True)           # 1/4\n",
    "    d4 = decoder_block(d3, skip1_conv, initial_filters, use_attention=True)               # 1/2\n",
    "    \n",
    "    # Final upsampling to original image size\n",
    "    final = UpSampling2D(size=(2, 2), interpolation='bilinear')(d4)\n",
    "    \n",
    "    # Final convolution to generate segmentation map\n",
    "    outputs = Conv2D(num_classes, 1, padding='same', activation='softmax')(final)\n",
    "    \n",
    "    # Create and return the model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_efficientnet_attention_unet(input_shape=(224, 224, 3), num_classes=4)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "# âœ… Weighted Categorical Crossentropy\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    class_weights = tf.constant([0.3776, 0.7605, 65.8554, 46.2381], dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "    class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))\n",
    "    weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)\n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# âœ… Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# âœ… LovÃ¡sz-Softmax Loss\n",
    "def lovasz_softmax_loss(y_true, y_pred, ignore_background=False):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    num_classes = tf.shape(y_true)[-1]\n",
    "    start_class = tf.constant(1 if ignore_background else 0)\n",
    "\n",
    "    def compute_class_loss(c):\n",
    "        y_true_class = y_true[..., c]\n",
    "        y_pred_class = y_pred[..., c]\n",
    "\n",
    "        y_true_flat = tf.reshape(y_true_class, [-1])\n",
    "        y_pred_flat = tf.reshape(y_pred_class, [-1])\n",
    "\n",
    "        errors = tf.abs(y_true_flat - y_pred_flat)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], sorted=True)\n",
    "        y_true_sorted = tf.gather(y_true_flat, perm)\n",
    "\n",
    "        gts = tf.reduce_sum(y_true_sorted)\n",
    "        intersection = gts - tf.cumsum(y_true_sorted)\n",
    "        union = gts + tf.cumsum(1. - y_true_sorted)\n",
    "        jaccard = 1. - intersection / union\n",
    "        grad = tf.concat([[jaccard[0]], jaccard[1:] - jaccard[:-1]], 0)\n",
    "\n",
    "        return tf.tensordot(errors_sorted, grad, axes=1)\n",
    "\n",
    "    # Loop through classes using tf.while_loop\n",
    "    losses = tf.TensorArray(dtype=tf.float32, size=num_classes)\n",
    "\n",
    "    def loop_cond(c, losses):\n",
    "        return tf.less(c, num_classes)\n",
    "\n",
    "    def loop_body(c, losses):\n",
    "        loss_c = compute_class_loss(c)\n",
    "        losses = losses.write(c, loss_c)\n",
    "        return c + 1, losses\n",
    "\n",
    "    _, losses = tf.while_loop(loop_cond, loop_body, [start_class, losses])\n",
    "    return tf.reduce_mean(losses.stack())\n",
    "\n",
    "# âœ… Combined Loss\n",
    "def combined_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice_loss_val = 1 - (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss_val = tf.reduce_mean(dice_loss_val)\n",
    "    \n",
    "    lovasz_loss_val = lovasz_softmax_loss(y_true, tf.nn.softmax(y_pred), ignore_background=False)\n",
    "    return lovasz_loss_val + dice_loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1,2,3]) + tf.reduce_sum(y_pred, axis=[1,2,3])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "# âœ… Weighted Categorical Crossentropy\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    class_weights = tf.constant([0.3776, 0.7605, 65.8554, 46.2381], dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "    class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))\n",
    "    weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)\n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# âœ… Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# âœ… Custom Dice Coefficient Metric for Each Class\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_idx, name=None, **kwargs):  \n",
    "        if name is None:\n",
    "            name = f\"DiceClass{class_idx}\"  \n",
    "        super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        self.class_idx = class_idx\n",
    "        self.dice = self.add_weight(name=\"dice\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_class = y_true[..., self.class_idx]\n",
    "        y_pred_class = y_pred[..., self.class_idx]\n",
    "        intersection = tf.reduce_sum(y_true_class * y_pred_class, axis=[1, 2])\n",
    "        union = tf.reduce_sum(y_true_class, axis=[1, 2]) + tf.reduce_sum(y_pred_class, axis=[1, 2])\n",
    "        dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "        self.dice.assign(tf.reduce_mean(dice))\n",
    "\n",
    "    def result(self):\n",
    "        return self.dice\n",
    "\n",
    "# âœ… Function to Get Class-wise Metrics\n",
    "def class_wise_metrics(num_classes=4):\n",
    "    return [DiceCoefficient(i) for i in range(num_classes)] + [tf.keras.metrics.MeanIoU(num_classes=num_classes)]\n",
    "\n",
    "model_efficientnetb4 = build_efficientnet_attention_unet(input_shape=(224, 224, 3), num_classes=4)\n",
    "model_efficientnetb4.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(4)  # Number of classes\n",
    ")\n",
    "model_efficientnetb4.load_weights(\"efficientnet_attention_unet_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects_efficientnet = {\n",
    "    'combined_loss': combined_loss,\n",
    "    'dice_loss': dice_loss,\n",
    "    'weighted_categorical_crossentropy': weighted_categorical_crossentropy,\n",
    "    'DiceCoefficient': DiceCoefficient,\n",
    "    'MeanIoU': tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES)\n",
    "}\n",
    "\n",
    "# Dynamically add DiceClass0â€“3\n",
    "for i in range(NUM_CLASSES):\n",
    "    custom_objects_efficientnet[f'DiceClass{i}'] = DiceCoefficient(class_idx=i)\n",
    "\n",
    "def load_efficientnetb4_model():\n",
    "    model = build_efficientnet_attention_unet(input_shape=(224, 224, 3), num_classes=4)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss=combined_loss,\n",
    "        metrics=class_wise_metrics(4)\n",
    "    )\n",
    "    model.load_weights(\"efficientnet_attention_unet_weights.h5\")\n",
    "    return model\n",
    "\n",
    "def run_training(train_gen, val_gen, model_loader_fn, custom_objects, batch_size=8, epochs=3, repeats=1):\n",
    "    import subprocess\n",
    "    import time\n",
    "    import numpy as np\n",
    "    from tensorflow.keras import backend as K\n",
    "    import gc\n",
    "\n",
    "    epoch_times_all = []\n",
    "    power_samples_all = []\n",
    "\n",
    "    for r in range(repeats):\n",
    "        print(f\"\\nðŸ” Repeat {r+1}/{repeats}\")\n",
    "\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "        # Build and load model\n",
    "        model = model_loader_fn()\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        power_proc = subprocess.Popen(\n",
    "            ['nvidia-smi', '--query-gpu=power.draw', '--format=csv,noheader,nounits', '-lms', '500'],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "            text=True\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=epochs,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        end = time.time()\n",
    "        total_time = end - start\n",
    "        avg_epoch_time = total_time / epochs\n",
    "        epoch_times_all.extend([avg_epoch_time] * epochs)\n",
    "\n",
    "        power_proc.terminate()\n",
    "        try:\n",
    "            power_output = power_proc.stdout.read().strip().split('\\n')\n",
    "            power_values = [float(line) for line in power_output if line.strip()]\n",
    "            avg_power = np.mean(power_values)\n",
    "            power_samples_all.extend([avg_power] * epochs)\n",
    "            print(f\"âš¡ Avg Power: {avg_power:.2f} W\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Power log failed: {e}\")\n",
    "            power_samples_all.extend([np.nan] * epochs)\n",
    "\n",
    "        del model\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "\n",
    "    return epoch_times_all, power_samples_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "epoch_times, power_vals = run_training(\n",
    "    train_gen=train_gen,\n",
    "    val_gen=val_gen,\n",
    "    model_loader_fn=load_efficientnetb4_model,  # note: function, not string path\n",
    "    custom_objects=custom_objects_efficientnet,\n",
    "    batch_size=4,\n",
    "    epochs=3,\n",
    "    repeats=1\n",
    ")\n",
    "\n",
    "epoch_times = np.array(epoch_times)\n",
    "power_vals = np.array(power_vals)\n",
    "\n",
    "mean_time = np.mean(epoch_times)\n",
    "std_time = np.std(epoch_times)\n",
    "mean_power = np.nanmean(power_vals)\n",
    "energy_wh = (mean_power * mean_time) / 3600\n",
    "\n",
    "samples_per_epoch = len(train_gen) * train_gen.batch_size\n",
    "flops_per_sample = 4e9  # adjust if you have exact FLOPs\n",
    "gflops = (2 * flops_per_sample * samples_per_epoch) / (mean_time * 1e9)\n",
    "\n",
    "print(\"\\nðŸ“Š Summary:\")\n",
    "print(f\"â±ï¸  Avg epoch time: {mean_time:.2f} Â± {std_time:.2f} sec\")\n",
    "print(f\"âš™ï¸  Estimated GFLOPS: {gflops:.2f}\")\n",
    "print(f\"âš¡  Avg power: {mean_power:.2f} W\")\n",
    "print(f\"ðŸ”‹  Avg energy/epoch: {energy_wh:.4f} Wh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "# Constants for 224x224 images\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "def convolution_block(inputs, filters, kernel_size=3, dilation_rate=1, padding='same', use_bias=False):\n",
    "    \"\"\"\n",
    "    Standard convolution block with batch normalization and ReLU activation\n",
    "    \"\"\"\n",
    "    x = layers.Conv2D(\n",
    "        filters, \n",
    "        kernel_size, \n",
    "        padding=padding,\n",
    "        dilation_rate=dilation_rate,\n",
    "        use_bias=use_bias\n",
    "    )(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def ASPP(inputs):\n",
    "    \"\"\"\n",
    "    Atrous Spatial Pyramid Pooling module for DeepLabV3+\n",
    "    \"\"\"\n",
    "    # ASPP with different dilation rates\n",
    "    b0 = convolution_block(inputs, 256, kernel_size=1, dilation_rate=1)\n",
    "    b1 = convolution_block(inputs, 256, kernel_size=3, dilation_rate=6)\n",
    "    b2 = convolution_block(inputs, 256, kernel_size=3, dilation_rate=12)\n",
    "    b3 = convolution_block(inputs, 256, kernel_size=3, dilation_rate=18)\n",
    "    \n",
    "    # Global context - simplified approach\n",
    "    b4 = layers.GlobalAveragePooling2D()(inputs)\n",
    "    b4 = layers.Reshape((1, 1, inputs.shape[-1]))(b4)\n",
    "    b4 = convolution_block(b4, 256, kernel_size=1)\n",
    "    # Use fixed upsampling instead of dynamic\n",
    "    b4 = layers.UpSampling2D(size=(inputs.shape[1], inputs.shape[2]))(b4)\n",
    "    \n",
    "    # Concatenate all branches\n",
    "    x = layers.Concatenate()([b0, b1, b2, b3, b4])\n",
    "    \n",
    "    # Final 1x1 convolution\n",
    "    output = convolution_block(x, 256, kernel_size=1)\n",
    "    return output\n",
    "\n",
    "def build_deeplabv3_plus_xception(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    DeepLabV3+ model with Xception backbone\n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Xception as backbone (with output stride of 16)\n",
    "    base_model = Xception(\n",
    "        input_tensor=inputs,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Don't freeze any layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Extract features from Xception\n",
    "    # The entry flow ends with 'block4_sepconv2_bn' which is a good low-level feature point\n",
    "    low_level_features = base_model.get_layer('block4_sepconv2_bn').output\n",
    "    # The final features from the exit flow\n",
    "    high_level_features = base_model.output\n",
    "    \n",
    "    # Process low-level features\n",
    "    low_level_features = convolution_block(low_level_features, 48, kernel_size=1)\n",
    "    \n",
    "    # Process high-level features with ASPP\n",
    "    x = ASPP(high_level_features)\n",
    "    \n",
    "    # Calculate upsampling factor for high-level features to match low-level features\n",
    "    hl_shape = high_level_features.shape\n",
    "    ll_shape = low_level_features.shape\n",
    "    h_factor = ll_shape[1] // hl_shape[1]\n",
    "    w_factor = ll_shape[2] // hl_shape[2]\n",
    "    \n",
    "    # Upsample high-level features to match low-level features\n",
    "    x = layers.UpSampling2D(size=(h_factor, w_factor), interpolation='bilinear')(x)\n",
    "    \n",
    "    # Concatenate features\n",
    "    x = layers.Concatenate()([x, low_level_features])\n",
    "    \n",
    "    # Apply convolution blocks\n",
    "    x = convolution_block(x, 256, kernel_size=3)\n",
    "    x = convolution_block(x, 256, kernel_size=3)\n",
    "    \n",
    "    # Calculate upsampling factor needed to reach 224x224\n",
    "    current_shape = x.shape\n",
    "    h_factor = IMG_HEIGHT // current_shape[1]\n",
    "    w_factor = IMG_WIDTH // current_shape[2]\n",
    "    \n",
    "    # Final upsampling to original size (224x224)\n",
    "    x = layers.UpSampling2D(size=(h_factor, w_factor), interpolation='bilinear')(x)\n",
    "    \n",
    "    # Ensure exact dimensions with a reshape if needed\n",
    "    x = layers.Reshape((IMG_HEIGHT, IMG_WIDTH, int(current_shape[3])))(x)\n",
    "    \n",
    "    # Final convolution for output (224, 224, 4)\n",
    "    outputs = layers.Conv2D(num_classes, kernel_size=1, padding='same', activation='softmax')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "model = build_deeplabv3_plus_xception(input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), \n",
    "                                     num_classes=NUM_CLASSES)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Number of classes (adjust if needed)\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# âœ… Dice Coefficient (Mean across all classes)\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "# âœ… Weighted Categorical Crossentropy\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    class_weights = tf.constant([0.3776, 0.7605, 65.8554, 46.2381], dtype=tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0)\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "    class_weights = tf.reshape(class_weights, (1, 1, 1, NUM_CLASSES))\n",
    "    weighted_loss = loss * tf.reduce_sum(class_weights, axis=-1)\n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# âœ… Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# âœ… LovÃ¡sz-Softmax Loss\n",
    "def lovasz_softmax_loss(y_true, y_pred, ignore_background=False):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    num_classes = tf.shape(y_true)[-1]\n",
    "    start_class = tf.constant(1 if ignore_background else 0)\n",
    "\n",
    "    def compute_class_loss(c):\n",
    "        y_true_class = y_true[..., c]\n",
    "        y_pred_class = y_pred[..., c]\n",
    "\n",
    "        y_true_flat = tf.reshape(y_true_class, [-1])\n",
    "        y_pred_flat = tf.reshape(y_pred_class, [-1])\n",
    "\n",
    "        errors = tf.abs(y_true_flat - y_pred_flat)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], sorted=True)\n",
    "        y_true_sorted = tf.gather(y_true_flat, perm)\n",
    "\n",
    "        gts = tf.reduce_sum(y_true_sorted)\n",
    "        intersection = gts - tf.cumsum(y_true_sorted)\n",
    "        union = gts + tf.cumsum(1. - y_true_sorted)\n",
    "        jaccard = 1. - intersection / union\n",
    "        grad = tf.concat([[jaccard[0]], jaccard[1:] - jaccard[:-1]], 0)\n",
    "\n",
    "        return tf.tensordot(errors_sorted, grad, axes=1)\n",
    "\n",
    "    # Loop through classes using tf.while_loop\n",
    "    losses = tf.TensorArray(dtype=tf.float32, size=num_classes)\n",
    "\n",
    "    def loop_cond(c, losses):\n",
    "        return tf.less(c, num_classes)\n",
    "\n",
    "    def loop_body(c, losses):\n",
    "        loss_c = compute_class_loss(c)\n",
    "        losses = losses.write(c, loss_c)\n",
    "        return c + 1, losses\n",
    "\n",
    "    _, losses = tf.while_loop(loop_cond, loop_body, [start_class, losses])\n",
    "    return tf.reduce_mean(losses.stack())\n",
    "\n",
    "# âœ… Combined Loss\n",
    "def combined_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice_loss_val = 1 - (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss_val = tf.reduce_mean(dice_loss_val)\n",
    "    \n",
    "    lovasz_loss_val = lovasz_softmax_loss(y_true, tf.nn.softmax(y_pred), ignore_background=False)\n",
    "    return lovasz_loss_val + dice_loss_val\n",
    "\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_idx=0, name=None, **kwargs):  # <- default class_idx=0 to avoid missing arg\n",
    "        if name is None:\n",
    "            name = f\"DiceClass{class_idx}\"\n",
    "        super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        self.class_idx = class_idx\n",
    "        self.dice = self.add_weight(name=\"dice\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_class = y_true[..., self.class_idx]\n",
    "        y_pred_class = y_pred[..., self.class_idx]\n",
    "        intersection = tf.reduce_sum(y_true_class * y_pred_class, axis=[1, 2])\n",
    "        union = tf.reduce_sum(y_true_class, axis=[1, 2]) + tf.reduce_sum(y_pred_class, axis=[1, 2])\n",
    "        dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "        self.dice.assign(tf.reduce_mean(dice))\n",
    "\n",
    "    def result(self):\n",
    "        return self.dice\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"class_idx\": self.class_idx})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        if \"class_idx\" not in config:\n",
    "            # Try to extract class index from name like \"DiceClass2\"\n",
    "            name = config.get(\"name\", \"DiceClass0\")\n",
    "            if name.startswith(\"DiceClass\"):\n",
    "                config[\"class_idx\"] = int(name.replace(\"DiceClass\", \"\"))\n",
    "            else:\n",
    "                config[\"class_idx\"] = 0\n",
    "        return cls(**config)\n",
    "\n",
    "# âœ… Helper to load Dice metrics by name\n",
    "def dice_metric_loader(name):\n",
    "    if name.startswith(\"DiceClass\"):\n",
    "        class_idx = int(name.replace(\"DiceClass\", \"\"))\n",
    "        return DiceCoefficient(class_idx=class_idx)\n",
    "    raise ValueError(f\"Unknown Dice metric name: {name}\")\n",
    "\n",
    "\n",
    "\n",
    "custom_objects = {\n",
    "    'combined_loss': combined_loss,\n",
    "    'lovasz_softmax_loss': lovasz_softmax_loss,\n",
    "    'MeanIoU': tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES),\n",
    "    'DiceCoefficient': DiceCoefficient,\n",
    "}\n",
    "\n",
    "# âœ… Add DiceClass0â€“3 dynamically\n",
    "for i in range(NUM_CLASSES):\n",
    "    custom_objects[f'DiceClass{i}'] = dice_metric_loader(f'DiceClass{i}')\n",
    "\n",
    "# âœ… Load the model\n",
    "model_xception = load_model('lovaszloss_deeplabv3_xception.keras', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects_xception = {\n",
    "    'combined_loss': combined_loss,\n",
    "    'lovasz_softmax_loss': lovasz_softmax_loss,\n",
    "    'MeanIoU': tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES),\n",
    "    'DiceCoefficient': DiceCoefficient,\n",
    "}\n",
    "\n",
    "# Add DiceClass0â€“3 directly\n",
    "for i in range(NUM_CLASSES):\n",
    "    custom_objects_xception[f'DiceClass{i}'] = DiceCoefficient(class_idx=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_gen, val_gen, model_loader_fn, custom_objects, batch_size=8, epochs=3, repeats=1):\n",
    "    import subprocess\n",
    "    import time\n",
    "    import numpy as np\n",
    "    from tensorflow.keras import backend as K\n",
    "    import gc\n",
    "\n",
    "    epoch_times_all = []\n",
    "    power_samples_all = []\n",
    "\n",
    "    for r in range(repeats):\n",
    "        print(f\"\\nðŸ” Repeat {r+1}/{repeats}\")\n",
    "\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "        # Build and load model\n",
    "        model = model_loader_fn()\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        power_proc = subprocess.Popen(\n",
    "            ['nvidia-smi', '--query-gpu=power.draw', '--format=csv,noheader,nounits', '-lms', '500'],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "            text=True\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=epochs,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        end = time.time()\n",
    "        total_time = end - start\n",
    "        avg_epoch_time = total_time / epochs\n",
    "        epoch_times_all.extend([avg_epoch_time] * epochs)\n",
    "\n",
    "        power_proc.terminate()\n",
    "        try:\n",
    "            power_output = power_proc.stdout.read().strip().split('\\n')\n",
    "            power_values = [float(line) for line in power_output if line.strip()]\n",
    "            avg_power = np.mean(power_values)\n",
    "            power_samples_all.extend([avg_power] * epochs)\n",
    "            print(f\"âš¡ Avg Power: {avg_power:.2f} W\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Power log failed: {e}\")\n",
    "            power_samples_all.extend([np.nan] * epochs)\n",
    "\n",
    "        del model\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "\n",
    "    return epoch_times_all, power_samples_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_deeplabv3_xception_model():\n",
    "    return tf.keras.models.load_model(\n",
    "        'lovaszloss_deeplabv3_xception.keras',\n",
    "        custom_objects=custom_objects_xception\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "epoch_times, power_vals = run_training(\n",
    "    train_gen=train_gen,\n",
    "    val_gen=val_gen,\n",
    "    model_loader_fn=load_deeplabv3_xception_model,\n",
    "    custom_objects=custom_objects_xception,\n",
    "    batch_size=8,\n",
    "    epochs=3,\n",
    "    repeats=1\n",
    ")\n",
    "\n",
    "epoch_times = np.array(epoch_times)\n",
    "power_vals = np.array(power_vals)\n",
    "\n",
    "mean_time = np.mean(epoch_times)\n",
    "std_time = np.std(epoch_times)\n",
    "mean_power = np.nanmean(power_vals)\n",
    "energy_wh = (mean_power * mean_time) / 3600\n",
    "\n",
    "samples_per_epoch = len(train_gen) * train_gen.batch_size\n",
    "flops_per_sample = 4e9  # Rough estimate for Xception-based DeepLab\n",
    "gflops = (2 * flops_per_sample * samples_per_epoch) / (mean_time * 1e9)\n",
    "\n",
    "print(\"\\nðŸ“Š Summary:\")\n",
    "print(f\"â±ï¸  Avg epoch time: {mean_time:.2f} Â± {std_time:.2f} sec\")\n",
    "print(f\"âš™ï¸  Estimated GFLOPS: {gflops:.2f}\")\n",
    "print(f\"âš¡  Avg power: {mean_power:.2f} W\")\n",
    "print(f\"ðŸ”‹  Avg energy/epoch: {energy_wh:.4f} Wh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class SoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, apply_softmax=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            models (list): List of pretrained tf.keras.Model instances.\n",
    "            apply_softmax (bool): Apply softmax to logits before averaging.\n",
    "        \"\"\"\n",
    "        super(SoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        prob_sum = 0\n",
    "\n",
    "        for model in self.models:\n",
    "            logits = model(x, training=training)\n",
    "            probs = tf.nn.softmax(logits, axis=-1) if self.apply_softmax else logits\n",
    "            prob_sum += probs\n",
    "\n",
    "        avg_prob = prob_sum / len(self.models)\n",
    "        final_pred = tf.argmax(avg_prob, axis=-1)  # shape: [B, H, W]\n",
    "        return final_pred\n",
    "\n",
    "# Assume you have trained models: model1, model2, model3\n",
    "ensemble_model = SoftVotingEnsemble([model_segnet, model_inceptionresnetv2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SoftVotingEnsemble(tf.keras.Model):\n",
    "#     def __init__(self, models, apply_softmax=True, return_probs=False):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             models (list): List of pretrained tf.keras.Model instances.\n",
    "#             apply_softmax (bool): Apply softmax to logits before averaging.\n",
    "#             return_probs (bool): If True, return averaged class probabilities (for loss/metrics).\n",
    "#                                  If False, return argmax predictions (for direct inference).\n",
    "#         \"\"\"\n",
    "#         super(SoftVotingEnsemble, self).__init__()\n",
    "#         self.models = models\n",
    "#         self.apply_softmax = apply_softmax\n",
    "#         self.return_probs = return_probs\n",
    "\n",
    "#     def call(self, x, training=False):\n",
    "#         prob_sum = 0\n",
    "#         for model in self.models:\n",
    "#             logits = model(x, training=training)\n",
    "#             probs = tf.nn.softmax(logits, axis=-1) if self.apply_softmax else logits\n",
    "#             prob_sum += probs\n",
    "#         avg_prob = prob_sum / len(self.models)\n",
    "        \n",
    "#         if self.return_probs:\n",
    "#             return avg_prob  # shape: [B, H, W, C]\n",
    "#         else:\n",
    "#             return tf.argmax(avg_prob, axis=-1)  # shape: [B, H, W]\n",
    "\n",
    "class SoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, apply_softmax=True, return_probs=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            models (list): List of pretrained tf.keras.Model instances.\n",
    "            apply_softmax (bool): Apply softmax to logits before averaging.\n",
    "            return_probs (bool): If True, return averaged class probabilities (for loss/metrics).\n",
    "                                 If False, return argmax predictions (for direct inference).\n",
    "        \"\"\"\n",
    "        super(SoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "        self.return_probs = return_probs\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        prob_sum = 0\n",
    "        for model in self.models:\n",
    "            output = model(x, training=training)\n",
    "\n",
    "            # Detect EfficientNet-like model (already softmaxed)\n",
    "            is_softmaxed = (\n",
    "                hasattr(model, \"name\") and \"efficientnet\" in model.name.lower()\n",
    "            )\n",
    "\n",
    "            if self.apply_softmax and not is_softmaxed:\n",
    "                probs = tf.nn.softmax(output, axis=-1)\n",
    "            else:\n",
    "                probs = output\n",
    "\n",
    "            prob_sum += probs\n",
    "\n",
    "        avg_prob = prob_sum / len(self.models)\n",
    "\n",
    "        if self.return_probs:\n",
    "            return avg_prob\n",
    "        else:\n",
    "            return tf.argmax(avg_prob, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# âœ… RGB to Class Index Conversion (for the test masks)\n",
    "RGB_TO_CLASS = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0     # Background\n",
    "}\n",
    "\n",
    "# âœ… Function to convert RGB masks to class index masks\n",
    "def rgb_to_class_mask(rgb_mask):\n",
    "    # Create a mask initialized with zeros (for background class)\n",
    "    class_mask = np.zeros(rgb_mask.shape[:2], dtype=int)\n",
    "\n",
    "    # Loop through the RGB_TO_CLASS dictionary\n",
    "    for rgb, class_idx in RGB_TO_CLASS.items():\n",
    "        # Identify the pixels with the current RGB value and assign them the class index\n",
    "        match_mask = np.all(rgb_mask == np.array(rgb), axis=-1)\n",
    "        class_mask[match_mask] = class_idx\n",
    "\n",
    "    return class_mask\n",
    "\n",
    "# âœ… Function to calculate Dice Similarity Coefficient (DSC)\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# âœ… Function to calculate IoU (Intersection over Union)\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-15)\n",
    "\n",
    "# âœ… Function to calculate Hausdorff Distance\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')  # Return inf if no points for either true or pred class\n",
    "\n",
    "    forward_hausdorff = directed_hausdorff(true_points, pred_points)[0]\n",
    "    reverse_hausdorff = directed_hausdorff(pred_points, true_points)[0]\n",
    "    return max(forward_hausdorff, reverse_hausdorff)\n",
    "\n",
    "# âœ… Function to calculate Average Surface Distance (ASD)\n",
    "def average_surface_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')  # Return inf if no points for either true or pred class\n",
    "\n",
    "    distances = []\n",
    "    for true_point in true_points:\n",
    "        distances.append(np.min(np.linalg.norm(pred_points - true_point, axis=1)))\n",
    "    return np.mean(distances)\n",
    "\n",
    "# âœ… Function to evaluate the model on the test set class-wise\n",
    "def evaluate_classwise_metrics(model, X_test, y_test, num_classes=4, batch_size=16):\n",
    "    # Predict in batches\n",
    "    y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)  # Convert to class index prediction\n",
    "\n",
    "    # Convert y_test to class index format (since it's one-hot encoded)\n",
    "    y_test_class = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    # Initialize lists to store class-wise metrics\n",
    "    class_metrics = {i: {'dice': [], 'iou': [], 'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'hausdorff': [], 'asd': []} for i in range(num_classes)}\n",
    "\n",
    "    # Calculate metrics for each test sample\n",
    "    for i in range(len(X_test)):\n",
    "        true_mask = y_test_class[i]  # one-hot -> class index\n",
    "        pred_mask = y_pred[i]\n",
    "\n",
    "        # For each class (0: Background, 1: Brain, 2: CSP, 3: LV)\n",
    "        for class_idx in range(num_classes):\n",
    "            true_class_mask = (true_mask == class_idx).astype(int)\n",
    "            pred_class_mask = (pred_mask == class_idx).astype(int)\n",
    "\n",
    "            # Dice Coefficient\n",
    "            class_metrics[class_idx]['dice'].append(dice_coefficient(true_class_mask, pred_class_mask))\n",
    "            # IoU\n",
    "            class_metrics[class_idx]['iou'].append(iou(true_class_mask, pred_class_mask))\n",
    "            # Precision\n",
    "            class_metrics[class_idx]['precision'].append(precision_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # Recall\n",
    "            class_metrics[class_idx]['recall'].append(recall_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # F1 Score\n",
    "            class_metrics[class_idx]['f1'].append(f1_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # Accuracy\n",
    "            class_metrics[class_idx]['accuracy'].append(accuracy_score(true_class_mask.flatten(), pred_class_mask.flatten()))\n",
    "            # # Hausdorff Distance\n",
    "            # class_metrics[class_idx]['hausdorff'].append(hausdorff_distance(true_class_mask, pred_class_mask))\n",
    "            # # Average Surface Distance\n",
    "            # class_metrics[class_idx]['asd'].append(average_surface_distance(true_class_mask, pred_class_mask))\n",
    "\n",
    "    # Print class-wise metrics in percentage\n",
    "    print(f\"{'Class':<10}{'Dice Coefficient (%)':<20}{'IoU (%)':<20}{'Precision (%)':<20}{'Recall (%)':<20}{'F1 Score (%)':<20}{'Accuracy (%)':<20}{'Hausdorff Distance':<20}{'Avg Surface Distance':<20}\")\n",
    "    print('-' * 180)\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        print(f\"Class {class_idx}:\")\n",
    "        print(f\"  Dice Coefficient: {np.mean(class_metrics[class_idx]['dice']) * 100:.2f}%\")\n",
    "        print(f\"  IoU: {np.mean(class_metrics[class_idx]['iou']) * 100:.2f}%\")\n",
    "        print(f\"  Precision: {np.mean(class_metrics[class_idx]['precision']) * 100:.2f}%\")\n",
    "        print(f\"  Recall: {np.mean(class_metrics[class_idx]['recall']) * 100:.2f}%\")\n",
    "        print(f\"  F1 Score: {np.mean(class_metrics[class_idx]['f1']) * 100:.2f}%\")\n",
    "        print(f\"  Accuracy: {np.mean(class_metrics[class_idx]['accuracy']) * 100:.2f}%\")\n",
    "        # print(f\"  Hausdorff Distance: {np.mean(class_metrics[class_idx]['hausdorff']):.4f}\")\n",
    "        # print(f\"  Average Surface Distance: {np.mean(class_metrics[class_idx]['asd']):.4f}\")\n",
    "        print(\"-\" * 180)\n",
    "\n",
    "    # Evaluate on test set to print overall test accuracy and loss\n",
    "    # test_loss, *test_metrics = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    # print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    for metric, value in zip(model.metrics_names[1:], test_metrics):\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# âœ… Call the evaluation function on the test set class-wise\n",
    "evaluate_classwise_metrics(model_segnet, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_wise_metrics(num_classes=4):\n",
    "    return [DiceCoefficient(i) for i in range(num_classes)] + [tf.keras.metrics.MeanIoU(num_classes=num_classes)]\n",
    "\n",
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_segnet, model_inceptionresnetv2],\n",
    "    apply_softmax=False,\n",
    "    return_probs=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "# âœ… RGB to Class Index Conversion (for the test masks)\n",
    "RGB_TO_CLASS = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0     # Background\n",
    "}\n",
    "\n",
    "# âœ… RGB mask to class mask\n",
    "def rgb_to_class_mask(rgb_mask):\n",
    "    class_mask = np.zeros(rgb_mask.shape[:2], dtype=int)\n",
    "    for rgb, class_idx in RGB_TO_CLASS.items():\n",
    "        match_mask = np.all(rgb_mask == np.array(rgb), axis=-1)\n",
    "        class_mask[match_mask] = class_idx\n",
    "    return class_mask\n",
    "\n",
    "# âœ… Dice\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# âœ… IoU\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-15)\n",
    "\n",
    "# âœ… Hausdorff Distance\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')\n",
    "    forward_hausdorff = directed_hausdorff(true_points, pred_points)[0]\n",
    "    reverse_hausdorff = directed_hausdorff(pred_points, true_points)[0]\n",
    "    return max(forward_hausdorff, reverse_hausdorff)\n",
    "\n",
    "# âœ… Average Surface Distance (ASD)\n",
    "def average_surface_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')\n",
    "    distances = [np.min(np.linalg.norm(pred_points - pt, axis=1)) for pt in true_points]\n",
    "    return np.mean(distances)\n",
    "\n",
    "# # âœ… Soft Voting Ensemble Model\n",
    "# class SoftVotingEnsemble(tf.keras.Model):\n",
    "#     def __init__(self, models, apply_softmax=True):\n",
    "#         super(SoftVotingEnsemble, self).__init__()\n",
    "#         self.models = models\n",
    "#         self.apply_softmax = apply_softmax\n",
    "\n",
    "#     def call(self, x, training=False):\n",
    "#         prob_sum = 0\n",
    "#         for model in self.models:\n",
    "#             logits = model(x, training=training)\n",
    "#             probs = tf.nn.softmax(logits, axis=-1) if self.apply_softmax else logits\n",
    "#             prob_sum += probs\n",
    "#         avg_prob = prob_sum / len(self.models)\n",
    "#         final_pred = tf.argmax(avg_prob, axis=-1)\n",
    "#         return final_pred\n",
    "\n",
    "# âœ… Evaluation Function (for normal + ensemble models)\n",
    "def evaluate_classwise_metrics(model, X_test, y_test, num_classes=4, batch_size=16, is_ensemble=False):\n",
    "    if is_ensemble:\n",
    "        y_pred = []\n",
    "        for i in range(0, len(X_test), batch_size):\n",
    "            batch_x = X_test[i:i+batch_size]\n",
    "            preds = model(batch_x, training=False).numpy()  # [B, H, W]\n",
    "            y_pred.extend(preds)\n",
    "        y_pred = np.array(y_pred)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "        y_pred = np.argmax(y_pred, axis=-1)  # [B, H, W]\n",
    "\n",
    "    y_test_class = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    class_metrics = {\n",
    "        i: {'dice': [], 'iou': [], 'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'hausdorff': [], 'asd': []}\n",
    "        for i in range(num_classes)\n",
    "    }\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        true_mask = y_test_class[i]\n",
    "        pred_mask = y_pred[i]\n",
    "        for class_idx in range(num_classes):\n",
    "            true_class_mask = (true_mask == class_idx).astype(int)\n",
    "            pred_class_mask = (pred_mask == class_idx).astype(int)\n",
    "\n",
    "            class_metrics[class_idx]['dice'].append(dice_coefficient(true_class_mask, pred_class_mask))\n",
    "            class_metrics[class_idx]['iou'].append(iou(true_class_mask, pred_class_mask))\n",
    "            class_metrics[class_idx]['precision'].append(precision_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['recall'].append(recall_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['f1'].append(f1_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['accuracy'].append(accuracy_score(true_class_mask.flatten(), pred_class_mask.flatten()))\n",
    "            # class_metrics[class_idx]['hausdorff'].append(hausdorff_distance(true_class_mask, pred_class_mask))\n",
    "            # class_metrics[class_idx]['asd'].append(average_surface_distance(true_class_mask, pred_class_mask))\n",
    "\n",
    "    # ðŸ“Š Print results\n",
    "    print(f\"{'Class':<10}{'Dice Coef (%)':<15}{'IoU (%)':<12}{'Precision (%)':<17}{'Recall (%)':<15}{'F1 Score (%)':<17}{'Accuracy (%)':<17}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        print(f\"{class_idx:<10}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['dice']) * 100:>10.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['iou']) * 100:>12.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['precision']) * 100:>17.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['recall']) * 100:>15.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['f1']) * 100:>17.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['accuracy']) * 100:>17.2f}\")\n",
    "        # Optional: Print Hausdorff and ASD if needed\n",
    "\n",
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_segnet, model_xception],\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_segnet, model_xception],\n",
    "    apply_softmax=False,\n",
    "    return_probs=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_segnet, model_efficientnetb4],\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_segnet, model_efficientnetb4],\n",
    "    apply_softmax=False,      # because both models already output probabilities\n",
    "    return_probs=True         # required for custom loss/metrics to work\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_xception, model_efficientnetb4],\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_xception, model_efficientnetb4],\n",
    "    apply_softmax=False,      # because both models already output probabilities\n",
    "    return_probs=True         # required for custom loss/metrics to work\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_inceptionresnetv2, model_efficientnetb4],\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_inceptionresnetv2, model_efficientnetb4],\n",
    "    apply_softmax=False,      # because both models already output probabilities\n",
    "    return_probs=True         # required for custom loss/metrics to work\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_segnet, model_inceptionresnetv2, model_efficientnetb4],\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_segnet, model_inceptionresnetv2, model_efficientnetb4],\n",
    "    apply_softmax=False,      # because both models already output probabilities\n",
    "    return_probs=True         # required for custom loss/metrics to work\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_xception, model_inceptionresnetv2, model_efficientnetb4],\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_xception, model_inceptionresnetv2, model_efficientnetb4],\n",
    "    apply_softmax=False,      # because both models already output probabilities\n",
    "    return_probs=True         # required for custom loss/metrics to work\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_segnet, model_xception, model_efficientnetb4],\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_segnet, model_xception, model_efficientnetb4],\n",
    "    apply_softmax=False,      # because both models already output probabilities\n",
    "    return_probs=True         # required for custom loss/metrics to work\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_segnet, model_xception, model_inceptionresnetv2, model_efficientnetb4],\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_segnet, model_xception, model_inceptionresnetv2, model_efficientnetb4],\n",
    "    apply_softmax=False,      # because both models already output probabilities\n",
    "    return_probs=True         # required for custom loss/metrics to work\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "# âœ… RGB to Class Index Conversion (for the test masks)\n",
    "RGB_TO_CLASS = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0     # Background\n",
    "}\n",
    "\n",
    "# âœ… RGB mask to class mask\n",
    "def rgb_to_class_mask(rgb_mask):\n",
    "    class_mask = np.zeros(rgb_mask.shape[:2], dtype=int)\n",
    "    for rgb, class_idx in RGB_TO_CLASS.items():\n",
    "        match_mask = np.all(rgb_mask == np.array(rgb), axis=-1)\n",
    "        class_mask[match_mask] = class_idx\n",
    "    return class_mask\n",
    "\n",
    "# âœ… Dice\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# âœ… IoU\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-15)\n",
    "\n",
    "# âœ… Hausdorff Distance\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')\n",
    "    forward_hausdorff = directed_hausdorff(true_points, pred_points)[0]\n",
    "    reverse_hausdorff = directed_hausdorff(pred_points, true_points)[0]\n",
    "    return max(forward_hausdorff, reverse_hausdorff)\n",
    "\n",
    "# âœ… Average Surface Distance (ASD)\n",
    "def average_surface_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')\n",
    "    distances = [np.min(np.linalg.norm(pred_points - pt, axis=1)) for pt in true_points]\n",
    "    return np.mean(distances)\n",
    "\n",
    "# âœ… Soft Voting Ensemble Model\n",
    "class SoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, apply_softmax=True):\n",
    "        super(SoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        prob_sum = 0\n",
    "        for model in self.models:\n",
    "            logits = model(x, training=training)\n",
    "            probs = tf.nn.softmax(logits, axis=-1) if self.apply_softmax else logits\n",
    "            prob_sum += probs\n",
    "        avg_prob = prob_sum / len(self.models)\n",
    "        final_pred = tf.argmax(avg_prob, axis=-1)\n",
    "        return final_pred\n",
    "\n",
    "# âœ… Evaluation Function (for normal + ensemble models)\n",
    "def evaluate_classwise_metrics(model, X_test, y_test, num_classes=4, batch_size=16, is_ensemble=False):\n",
    "    if is_ensemble:\n",
    "        y_pred = []\n",
    "        for i in range(0, len(X_test), batch_size):\n",
    "            batch_x = X_test[i:i+batch_size]\n",
    "            preds = model(batch_x, training=False).numpy()  # [B, H, W]\n",
    "            y_pred.extend(preds)\n",
    "        y_pred = np.array(y_pred)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "        y_pred = np.argmax(y_pred, axis=-1)  # [B, H, W]\n",
    "\n",
    "    y_test_class = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    class_metrics = {\n",
    "        i: {'dice': [], 'iou': [], 'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'hausdorff': [], 'asd': []}\n",
    "        for i in range(num_classes)\n",
    "    }\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        true_mask = y_test_class[i]\n",
    "        pred_mask = y_pred[i]\n",
    "        for class_idx in range(num_classes):\n",
    "            true_class_mask = (true_mask == class_idx).astype(int)\n",
    "            pred_class_mask = (pred_mask == class_idx).astype(int)\n",
    "\n",
    "            class_metrics[class_idx]['dice'].append(dice_coefficient(true_class_mask, pred_class_mask))\n",
    "            class_metrics[class_idx]['iou'].append(iou(true_class_mask, pred_class_mask))\n",
    "            class_metrics[class_idx]['precision'].append(precision_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['recall'].append(recall_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['f1'].append(f1_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['accuracy'].append(accuracy_score(true_class_mask.flatten(), pred_class_mask.flatten()))\n",
    "            # class_metrics[class_idx]['hausdorff'].append(hausdorff_distance(true_class_mask, pred_class_mask))\n",
    "            # class_metrics[class_idx]['asd'].append(average_surface_distance(true_class_mask, pred_class_mask))\n",
    "\n",
    "    # ðŸ“Š Print results\n",
    "    print(f\"{'Class':<10}{'Dice Coef (%)':<15}{'IoU (%)':<12}{'Precision (%)':<17}{'Recall (%)':<15}{'F1 Score (%)':<17}{'Accuracy (%)':<17}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        print(f\"{class_idx:<10}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['dice']) * 100:>10.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['iou']) * 100:>12.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['precision']) * 100:>17.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['recall']) * 100:>15.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['f1']) * 100:>17.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['accuracy']) * 100:>17.2f}\")\n",
    "        # Optional: Print Hausdorff and ASD if needed\n",
    "\n",
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_xception, model_inceptionresnetv2],\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_xception, model_inceptionresnetv2],\n",
    "    apply_softmax=False,\n",
    "    return_probs=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "# âœ… RGB to Class Index Conversion (for the test masks)\n",
    "RGB_TO_CLASS = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0     # Background\n",
    "}\n",
    "\n",
    "# âœ… RGB mask to class mask\n",
    "def rgb_to_class_mask(rgb_mask):\n",
    "    class_mask = np.zeros(rgb_mask.shape[:2], dtype=int)\n",
    "    for rgb, class_idx in RGB_TO_CLASS.items():\n",
    "        match_mask = np.all(rgb_mask == np.array(rgb), axis=-1)\n",
    "        class_mask[match_mask] = class_idx\n",
    "    return class_mask\n",
    "\n",
    "# âœ… Dice\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# âœ… IoU\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-15)\n",
    "\n",
    "# âœ… Hausdorff Distance\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')\n",
    "    forward_hausdorff = directed_hausdorff(true_points, pred_points)[0]\n",
    "    reverse_hausdorff = directed_hausdorff(pred_points, true_points)[0]\n",
    "    return max(forward_hausdorff, reverse_hausdorff)\n",
    "\n",
    "# âœ… Average Surface Distance (ASD)\n",
    "def average_surface_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')\n",
    "    distances = [np.min(np.linalg.norm(pred_points - pt, axis=1)) for pt in true_points]\n",
    "    return np.mean(distances)\n",
    "\n",
    "# âœ… Soft Voting Ensemble Model\n",
    "class SoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, apply_softmax=True):\n",
    "        super(SoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        prob_sum = 0\n",
    "        for model in self.models:\n",
    "            logits = model(x, training=training)\n",
    "            probs = tf.nn.softmax(logits, axis=-1) if self.apply_softmax else logits\n",
    "            prob_sum += probs\n",
    "        avg_prob = prob_sum / len(self.models)\n",
    "        final_pred = tf.argmax(avg_prob, axis=-1)\n",
    "        return final_pred\n",
    "\n",
    "# âœ… Evaluation Function (for normal + ensemble models)\n",
    "def evaluate_classwise_metrics(model, X_test, y_test, num_classes=4, batch_size=16, is_ensemble=False):\n",
    "    if is_ensemble:\n",
    "        y_pred = []\n",
    "        for i in range(0, len(X_test), batch_size):\n",
    "            batch_x = X_test[i:i+batch_size]\n",
    "            preds = model(batch_x, training=False).numpy()  # [B, H, W]\n",
    "            y_pred.extend(preds)\n",
    "        y_pred = np.array(y_pred)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "        y_pred = np.argmax(y_pred, axis=-1)  # [B, H, W]\n",
    "\n",
    "    y_test_class = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    class_metrics = {\n",
    "        i: {'dice': [], 'iou': [], 'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'hausdorff': [], 'asd': []}\n",
    "        for i in range(num_classes)\n",
    "    }\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        true_mask = y_test_class[i]\n",
    "        pred_mask = y_pred[i]\n",
    "        for class_idx in range(num_classes):\n",
    "            true_class_mask = (true_mask == class_idx).astype(int)\n",
    "            pred_class_mask = (pred_mask == class_idx).astype(int)\n",
    "\n",
    "            class_metrics[class_idx]['dice'].append(dice_coefficient(true_class_mask, pred_class_mask))\n",
    "            class_metrics[class_idx]['iou'].append(iou(true_class_mask, pred_class_mask))\n",
    "            class_metrics[class_idx]['precision'].append(precision_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['recall'].append(recall_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['f1'].append(f1_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['accuracy'].append(accuracy_score(true_class_mask.flatten(), pred_class_mask.flatten()))\n",
    "            # class_metrics[class_idx]['hausdorff'].append(hausdorff_distance(true_class_mask, pred_class_mask))\n",
    "            # class_metrics[class_idx]['asd'].append(average_surface_distance(true_class_mask, pred_class_mask))\n",
    "\n",
    "    # ðŸ“Š Print results\n",
    "    print(f\"{'Class':<10}{'Dice Coef (%)':<15}{'IoU (%)':<12}{'Precision (%)':<17}{'Recall (%)':<15}{'F1 Score (%)':<17}{'Accuracy (%)':<17}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        print(f\"{class_idx:<10}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['dice']) * 100:>10.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['iou']) * 100:>12.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['precision']) * 100:>17.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['recall']) * 100:>15.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['f1']) * 100:>17.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['accuracy']) * 100:>17.2f}\")\n",
    "\n",
    "# Optional: Print Hausdorff and ASD if needed\n",
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_xception, model_segnet, model_inceptionresnetv2],\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_xception, model_segnet, model_inceptionresnetv2],\n",
    "    apply_softmax=False,\n",
    "    return_probs=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = SoftVotingEnsemble(\n",
    "    models=[model_xception, model_segnet, model_inceptionresnetv2],\n",
    "    apply_softmax=False,\n",
    "    return_probs=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Majority Voting</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy import stats  # for mode\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class HardVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models):\n",
    "        super(HardVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            logits = model(x, training=training)\n",
    "            pred_mask = tf.argmax(logits, axis=-1)  # [B, H, W]\n",
    "            predictions.append(pred_mask)\n",
    "\n",
    "        stacked_preds = tf.stack(predictions, axis=0)  # [N_models, B, H, W]\n",
    "        stacked_preds = tf.transpose(stacked_preds, [1, 2, 3, 0])  # [B, H, W, N_models]\n",
    "\n",
    "        mode_preds = tf.numpy_function(\n",
    "            func=lambda x: stats.mode(x, axis=-1)[0],\n",
    "            inp=[stacked_preds],\n",
    "            Tout=tf.int64\n",
    "        )\n",
    "\n",
    "        return mode_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# from scipy import stats\n",
    "\n",
    "# class HardVotingEnsemble(tf.keras.Model):\n",
    "#     def __init__(self, models, num_classes):\n",
    "#         super(HardVotingEnsemble, self).__init__()\n",
    "#         self.models = models\n",
    "#         self.num_classes = num_classes\n",
    "\n",
    "#     def call(self, x, training=False):\n",
    "#         predictions = []\n",
    "#         for model in self.models:\n",
    "#             logits = model(x, training=training)               # [B, H, W, C]\n",
    "#             pred_mask = tf.argmax(logits, axis=-1)             # [B, H, W]\n",
    "#             predictions.append(pred_mask)\n",
    "\n",
    "#         stacked_preds = tf.stack(predictions, axis=0)          # [N_models, B, H, W]\n",
    "#         stacked_preds = tf.transpose(stacked_preds, [1, 2, 3, 0])  # [B, H, W, N_models]\n",
    "\n",
    "#         # Use numpy + scipy mode\n",
    "#         def compute_mode(x):\n",
    "#             mode, _ = stats.mode(x, axis=-1, keepdims=False)\n",
    "#             return mode.astype(np.int32)\n",
    "\n",
    "#         mode_preds = tf.numpy_function(\n",
    "#             func=compute_mode,\n",
    "#             inp=[stacked_preds],\n",
    "#             Tout=tf.int32\n",
    "#         )\n",
    "\n",
    "#         # Manually set output shape: [B, H, W]\n",
    "#         batch_size = tf.shape(x)[0]\n",
    "#         height = tf.shape(x)[1]\n",
    "#         width = tf.shape(x)[2]\n",
    "#         mode_preds.set_shape([None, None, None])  # Symbolic shape for [B, H, W]\n",
    "\n",
    "#         one_hot_preds = tf.one_hot(mode_preds, depth=self.num_classes)  # [B, H, W, C]\n",
    "#         return one_hot_preds\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# from scipy import stats\n",
    "\n",
    "# class HardVotingEnsemble(tf.keras.Model):\n",
    "#     def __init__(self, models, num_classes, return_probs=True):\n",
    "#         super(HardVotingEnsemble, self).__init__()\n",
    "#         self.models = models\n",
    "#         self.num_classes = num_classes\n",
    "#         self.return_probs = return_probs\n",
    "\n",
    "#     def call(self, x, training=False):\n",
    "#         predictions = []\n",
    "\n",
    "#         for model in self.models:\n",
    "#             output = model(x, training=training)\n",
    "\n",
    "#             # Handle EfficientNet-like models with built-in softmax\n",
    "#             is_softmaxed = hasattr(model, \"name\") and \"efficientnet\" in model.name.lower()\n",
    "#             probs = output if is_softmaxed else tf.nn.softmax(output, axis=-1)\n",
    "\n",
    "#             pred_mask = tf.argmax(probs, axis=-1)  # [B, H, W]\n",
    "#             predictions.append(pred_mask)\n",
    "\n",
    "#         stacked_preds = tf.stack(predictions, axis=0)  # [N_models, B, H, W]\n",
    "#         stacked_preds = tf.transpose(stacked_preds, [1, 2, 3, 0])  # [B, H, W, N_models]\n",
    "\n",
    "#         # Use scipy mode to find majority vote\n",
    "#         def compute_mode(x):\n",
    "#             mode, _ = stats.mode(x, axis=-1, keepdims=False)\n",
    "#             return mode.astype(np.int32)\n",
    "\n",
    "#         mode_preds = tf.numpy_function(\n",
    "#             func=compute_mode,\n",
    "#             inp=[stacked_preds],\n",
    "#             Tout=tf.int32\n",
    "#         )\n",
    "#         mode_preds.set_shape([None, None, None])  # [B, H, W]\n",
    "\n",
    "#         if self.return_probs:\n",
    "#             return tf.one_hot(mode_preds, depth=self.num_classes)  # [B, H, W, C]\n",
    "#         else:\n",
    "#             return mode_preds  # [B, H, W]\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "class HardVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, num_classes):\n",
    "        super(HardVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            logits = model(x, training=training)               # [B, H, W, C]\n",
    "            pred_mask = tf.argmax(logits, axis=-1)             # [B, H, W]\n",
    "            predictions.append(pred_mask)\n",
    "\n",
    "        stacked_preds = tf.stack(predictions, axis=0)          # [N_models, B, H, W]\n",
    "        stacked_preds = tf.transpose(stacked_preds, [1, 2, 3, 0])  # [B, H, W, N_models]\n",
    "\n",
    "        # Use numpy + scipy mode\n",
    "        def compute_mode(x):\n",
    "            mode, _ = stats.mode(x, axis=-1, keepdims=False)\n",
    "            return mode.astype(np.int32)\n",
    "\n",
    "        mode_preds = tf.numpy_function(\n",
    "            func=compute_mode,\n",
    "            inp=[stacked_preds],\n",
    "            Tout=tf.int32\n",
    "        )\n",
    "\n",
    "        # Manually set output shape: [B, H, W]\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        height = tf.shape(x)[1]\n",
    "        width = tf.shape(x)[2]\n",
    "        mode_preds.set_shape([None, None, None])  # Symbolic shape for [B, H, W]\n",
    "\n",
    "        one_hot_preds = tf.one_hot(mode_preds, depth=self.num_classes)  # [B, H, W, C]\n",
    "        return one_hot_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "# âœ… RGB to Class Index Conversion (for the test masks)\n",
    "RGB_TO_CLASS = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0     # Background\n",
    "}\n",
    "\n",
    "# âœ… RGB mask to class mask\n",
    "def rgb_to_class_mask(rgb_mask):\n",
    "    class_mask = np.zeros(rgb_mask.shape[:2], dtype=int)\n",
    "    for rgb, class_idx in RGB_TO_CLASS.items():\n",
    "        match_mask = np.all(rgb_mask == np.array(rgb), axis=-1)\n",
    "        class_mask[match_mask] = class_idx\n",
    "    return class_mask\n",
    "\n",
    "# âœ… Dice\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# âœ… IoU\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-15)\n",
    "\n",
    "# âœ… Hausdorff Distance\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')\n",
    "    forward_hausdorff = directed_hausdorff(true_points, pred_points)[0]\n",
    "    reverse_hausdorff = directed_hausdorff(pred_points, true_points)[0]\n",
    "    return max(forward_hausdorff, reverse_hausdorff)\n",
    "\n",
    "# âœ… Average Surface Distance (ASD)\n",
    "def average_surface_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')\n",
    "    distances = [np.min(np.linalg.norm(pred_points - pt, axis=1)) for pt in true_points]\n",
    "    return np.mean(distances)\n",
    "\n",
    "# âœ… Soft Voting Ensemble Model\n",
    "class SoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, apply_softmax=True):\n",
    "        super(SoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        prob_sum = 0\n",
    "        for model in self.models:\n",
    "            logits = model(x, training=training)\n",
    "            probs = tf.nn.softmax(logits, axis=-1) if self.apply_softmax else logits\n",
    "            prob_sum += probs\n",
    "        avg_prob = prob_sum / len(self.models)\n",
    "        final_pred = tf.argmax(avg_prob, axis=-1)\n",
    "        return final_pred\n",
    "\n",
    "# âœ… Evaluation Function (for normal + ensemble models)\n",
    "def evaluate_classwise_metrics(model, X_test, y_test, num_classes=4, batch_size=16, is_ensemble=False):\n",
    "    if is_ensemble:\n",
    "        y_pred = []\n",
    "        for i in range(0, len(X_test), batch_size):\n",
    "            batch_x = X_test[i:i+batch_size]\n",
    "            preds = model(batch_x, training=False).numpy()  # [B, H, W]\n",
    "            y_pred.extend(preds)\n",
    "        y_pred = np.array(y_pred)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "        y_pred = np.argmax(y_pred, axis=-1)  # [B, H, W]\n",
    "\n",
    "    y_test_class = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    class_metrics = {\n",
    "        i: {'dice': [], 'iou': [], 'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'hausdorff': [], 'asd': []}\n",
    "        for i in range(num_classes)\n",
    "    }\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        true_mask = y_test_class[i]\n",
    "        pred_mask = y_pred[i]\n",
    "        for class_idx in range(num_classes):\n",
    "            true_class_mask = (true_mask == class_idx).astype(int)\n",
    "            pred_class_mask = (pred_mask == class_idx).astype(int)\n",
    "\n",
    "            class_metrics[class_idx]['dice'].append(dice_coefficient(true_class_mask, pred_class_mask))\n",
    "            class_metrics[class_idx]['iou'].append(iou(true_class_mask, pred_class_mask))\n",
    "            class_metrics[class_idx]['precision'].append(precision_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['recall'].append(recall_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['f1'].append(f1_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['accuracy'].append(accuracy_score(true_class_mask.flatten(), pred_class_mask.flatten()))\n",
    "            # class_metrics[class_idx]['hausdorff'].append(hausdorff_distance(true_class_mask, pred_class_mask))\n",
    "            # class_metrics[class_idx]['asd'].append(average_surface_distance(true_class_mask, pred_class_mask))\n",
    "\n",
    "    # ðŸ“Š Print results\n",
    "    print(f\"{'Class':<10}{'Dice Coef (%)':<15}{'IoU (%)':<12}{'Precision (%)':<17}{'Recall (%)':<15}{'F1 Score (%)':<17}{'Accuracy (%)':<17}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        print(f\"{class_idx:<10}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['dice']) * 100:>10.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['iou']) * 100:>12.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['precision']) * 100:>17.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['recall']) * 100:>15.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['f1']) * 100:>17.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['accuracy']) * 100:>17.2f}\")\n",
    "        # Optional: Print Hausdorff and ASD if needed\n",
    "\n",
    "ensemble_model = HardVotingEnsemble([model_segnet, model_inceptionresnetv2])\n",
    "\n",
    "# Evaluate like before (same evaluation function as used with soft voting)\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "\n",
    "    dice_loss_val = 1 - (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss_val = tf.reduce_mean(dice_loss_val)\n",
    "\n",
    "    lovasz_loss_val = lovasz_softmax_loss(y_true, tf.nn.softmax(y_pred), ignore_background=False)\n",
    "    return lovasz_loss_val + dice_loss_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_ensemble = HardVotingEnsemble(\n",
    "    models=[model_segnet, model_inceptionresnetv2],\n",
    "    num_classes=4\n",
    ")\n",
    "\n",
    "hard_ensemble.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "hard_ensemble.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "# âœ… RGB to Class Index Conversion (for the test masks)\n",
    "RGB_TO_CLASS = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0     # Background\n",
    "}\n",
    "\n",
    "# âœ… RGB mask to class mask\n",
    "def rgb_to_class_mask(rgb_mask):\n",
    "    class_mask = np.zeros(rgb_mask.shape[:2], dtype=int)\n",
    "    for rgb, class_idx in RGB_TO_CLASS.items():\n",
    "        match_mask = np.all(rgb_mask == np.array(rgb), axis=-1)\n",
    "        class_mask[match_mask] = class_idx\n",
    "    return class_mask\n",
    "\n",
    "# âœ… Dice\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# âœ… IoU\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-15)\n",
    "\n",
    "# âœ… Hausdorff Distance\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')\n",
    "    forward_hausdorff = directed_hausdorff(true_points, pred_points)[0]\n",
    "    reverse_hausdorff = directed_hausdorff(pred_points, true_points)[0]\n",
    "    return max(forward_hausdorff, reverse_hausdorff)\n",
    "\n",
    "# âœ… Average Surface Distance (ASD)\n",
    "def average_surface_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')\n",
    "    distances = [np.min(np.linalg.norm(pred_points - pt, axis=1)) for pt in true_points]\n",
    "    return np.mean(distances)\n",
    "\n",
    "# âœ… Soft Voting Ensemble Model\n",
    "class SoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, apply_softmax=True):\n",
    "        super(SoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        prob_sum = 0\n",
    "        for model in self.models:\n",
    "            logits = model(x, training=training)\n",
    "            probs = tf.nn.softmax(logits, axis=-1) if self.apply_softmax else logits\n",
    "            prob_sum += probs\n",
    "        avg_prob = prob_sum / len(self.models)\n",
    "        final_pred = tf.argmax(avg_prob, axis=-1)\n",
    "        return final_pred\n",
    "\n",
    "# âœ… Evaluation Function (for normal + ensemble models)\n",
    "def evaluate_classwise_metrics(model, X_test, y_test, num_classes=4, batch_size=16, is_ensemble=False):\n",
    "    if is_ensemble:\n",
    "        y_pred = []\n",
    "        for i in range(0, len(X_test), batch_size):\n",
    "            batch_x = X_test[i:i+batch_size]\n",
    "            preds = model(batch_x, training=False).numpy()  # [B, H, W]\n",
    "            y_pred.extend(preds)\n",
    "        y_pred = np.array(y_pred)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "        y_pred = np.argmax(y_pred, axis=-1)  # [B, H, W]\n",
    "\n",
    "    y_test_class = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    class_metrics = {\n",
    "        i: {'dice': [], 'iou': [], 'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'hausdorff': [], 'asd': []}\n",
    "        for i in range(num_classes)\n",
    "    }\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        true_mask = y_test_class[i]\n",
    "        pred_mask = y_pred[i]\n",
    "        for class_idx in range(num_classes):\n",
    "            true_class_mask = (true_mask == class_idx).astype(int)\n",
    "            pred_class_mask = (pred_mask == class_idx).astype(int)\n",
    "\n",
    "            class_metrics[class_idx]['dice'].append(dice_coefficient(true_class_mask, pred_class_mask))\n",
    "            class_metrics[class_idx]['iou'].append(iou(true_class_mask, pred_class_mask))\n",
    "            class_metrics[class_idx]['precision'].append(precision_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['recall'].append(recall_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['f1'].append(f1_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['accuracy'].append(accuracy_score(true_class_mask.flatten(), pred_class_mask.flatten()))\n",
    "            # class_metrics[class_idx]['hausdorff'].append(hausdorff_distance(true_class_mask, pred_class_mask))\n",
    "            # class_metrics[class_idx]['asd'].append(average_surface_distance(true_class_mask, pred_class_mask))\n",
    "\n",
    "    # ðŸ“Š Print results\n",
    "    print(f\"{'Class':<10}{'Dice Coef (%)':<15}{'IoU (%)':<12}{'Precision (%)':<17}{'Recall (%)':<15}{'F1 Score (%)':<17}{'Accuracy (%)':<17}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        print(f\"{class_idx:<10}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['dice']) * 100:>10.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['iou']) * 100:>12.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['precision']) * 100:>17.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['recall']) * 100:>15.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['f1']) * 100:>17.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['accuracy']) * 100:>17.2f}\")\n",
    "        # Optional: Print Hausdorff and ASD if needed\n",
    "\n",
    "ensemble_model = HardVotingEnsemble([model_segnet, model_xception])\n",
    "\n",
    "# Evaluate like before (same evaluation function as used with soft voting)\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "# âœ… RGB to Class Index Conversion (for the test masks)\n",
    "RGB_TO_CLASS = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0     # Background\n",
    "}\n",
    "\n",
    "# âœ… RGB mask to class mask\n",
    "def rgb_to_class_mask(rgb_mask):\n",
    "    class_mask = np.zeros(rgb_mask.shape[:2], dtype=int)\n",
    "    for rgb, class_idx in RGB_TO_CLASS.items():\n",
    "        match_mask = np.all(rgb_mask == np.array(rgb), axis=-1)\n",
    "        class_mask[match_mask] = class_idx\n",
    "    return class_mask\n",
    "\n",
    "# âœ… Dice\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# âœ… IoU\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-15)\n",
    "\n",
    "# âœ… Hausdorff Distance\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')\n",
    "    forward_hausdorff = directed_hausdorff(true_points, pred_points)[0]\n",
    "    reverse_hausdorff = directed_hausdorff(pred_points, true_points)[0]\n",
    "    return max(forward_hausdorff, reverse_hausdorff)\n",
    "\n",
    "# âœ… Average Surface Distance (ASD)\n",
    "def average_surface_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')\n",
    "    distances = [np.min(np.linalg.norm(pred_points - pt, axis=1)) for pt in true_points]\n",
    "    return np.mean(distances)\n",
    "\n",
    "# âœ… Soft Voting Ensemble Model\n",
    "class SoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, apply_softmax=True):\n",
    "        super(SoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        prob_sum = 0\n",
    "        for model in self.models:\n",
    "            logits = model(x, training=training)\n",
    "            probs = tf.nn.softmax(logits, axis=-1) if self.apply_softmax else logits\n",
    "            prob_sum += probs\n",
    "        avg_prob = prob_sum / len(self.models)\n",
    "        final_pred = tf.argmax(avg_prob, axis=-1)\n",
    "        return final_pred\n",
    "\n",
    "# âœ… Evaluation Function (for normal + ensemble models)\n",
    "def evaluate_classwise_metrics(model, X_test, y_test, num_classes=4, batch_size=16, is_ensemble=False):\n",
    "    if is_ensemble:\n",
    "        y_pred = []\n",
    "        for i in range(0, len(X_test), batch_size):\n",
    "            batch_x = X_test[i:i+batch_size]\n",
    "            preds = model(batch_x, training=False).numpy()  # [B, H, W]\n",
    "            y_pred.extend(preds)\n",
    "        y_pred = np.array(y_pred)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "        y_pred = np.argmax(y_pred, axis=-1)  # [B, H, W]\n",
    "\n",
    "    y_test_class = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    class_metrics = {\n",
    "        i: {'dice': [], 'iou': [], 'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'hausdorff': [], 'asd': []}\n",
    "        for i in range(num_classes)\n",
    "    }\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        true_mask = y_test_class[i]\n",
    "        pred_mask = y_pred[i]\n",
    "        for class_idx in range(num_classes):\n",
    "            true_class_mask = (true_mask == class_idx).astype(int)\n",
    "            pred_class_mask = (pred_mask == class_idx).astype(int)\n",
    "\n",
    "            class_metrics[class_idx]['dice'].append(dice_coefficient(true_class_mask, pred_class_mask))\n",
    "            class_metrics[class_idx]['iou'].append(iou(true_class_mask, pred_class_mask))\n",
    "            class_metrics[class_idx]['precision'].append(precision_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['recall'].append(recall_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['f1'].append(f1_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['accuracy'].append(accuracy_score(true_class_mask.flatten(), pred_class_mask.flatten()))\n",
    "            # class_metrics[class_idx]['hausdorff'].append(hausdorff_distance(true_class_mask, pred_class_mask))\n",
    "            # class_metrics[class_idx]['asd'].append(average_surface_distance(true_class_mask, pred_class_mask))\n",
    "\n",
    "    # ðŸ“Š Print results\n",
    "    print(f\"{'Class':<10}{'Dice Coef (%)':<15}{'IoU (%)':<12}{'Precision (%)':<17}{'Recall (%)':<15}{'F1 Score (%)':<17}{'Accuracy (%)':<17}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        print(f\"{class_idx:<10}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['dice']) * 100:>10.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['iou']) * 100:>12.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['precision']) * 100:>17.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['recall']) * 100:>15.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['f1']) * 100:>17.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['accuracy']) * 100:>17.2f}\")\n",
    "        # Optional: Print Hausdorff and ASD if needed\n",
    "\n",
    "ensemble_model = HardVotingEnsemble([model_xception, model_inceptionresnetv2])\n",
    "\n",
    "# Evaluate like before (same evaluation function as used with soft voting)\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_ensemble = HardVotingEnsemble(\n",
    "    models=[model_xception, model_inceptionresnetv2],\n",
    "    num_classes=4\n",
    ")\n",
    "\n",
    "hard_ensemble.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "hard_ensemble.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "# âœ… RGB to Class Index Conversion (for the test masks)\n",
    "RGB_TO_CLASS = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0     # Background\n",
    "}\n",
    "\n",
    "# âœ… RGB mask to class mask\n",
    "def rgb_to_class_mask(rgb_mask):\n",
    "    class_mask = np.zeros(rgb_mask.shape[:2], dtype=int)\n",
    "    for rgb, class_idx in RGB_TO_CLASS.items():\n",
    "        match_mask = np.all(rgb_mask == np.array(rgb), axis=-1)\n",
    "        class_mask[match_mask] = class_idx\n",
    "    return class_mask\n",
    "\n",
    "# âœ… Dice\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# âœ… IoU\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-15)\n",
    "\n",
    "# âœ… Hausdorff Distance\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')\n",
    "    forward_hausdorff = directed_hausdorff(true_points, pred_points)[0]\n",
    "    reverse_hausdorff = directed_hausdorff(pred_points, true_points)[0]\n",
    "    return max(forward_hausdorff, reverse_hausdorff)\n",
    "\n",
    "# âœ… Average Surface Distance (ASD)\n",
    "def average_surface_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')\n",
    "    distances = [np.min(np.linalg.norm(pred_points - pt, axis=1)) for pt in true_points]\n",
    "    return np.mean(distances)\n",
    "\n",
    "# âœ… Soft Voting Ensemble Model\n",
    "class SoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, apply_softmax=True):\n",
    "        super(SoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        prob_sum = 0\n",
    "        for model in self.models:\n",
    "            logits = model(x, training=training)\n",
    "            probs = tf.nn.softmax(logits, axis=-1) if self.apply_softmax else logits\n",
    "            prob_sum += probs\n",
    "        avg_prob = prob_sum / len(self.models)\n",
    "        final_pred = tf.argmax(avg_prob, axis=-1)\n",
    "        return final_pred\n",
    "\n",
    "# âœ… Evaluation Function (for normal + ensemble models)\n",
    "def evaluate_classwise_metrics(model, X_test, y_test, num_classes=4, batch_size=16, is_ensemble=False):\n",
    "    if is_ensemble:\n",
    "        y_pred = []\n",
    "        for i in range(0, len(X_test), batch_size):\n",
    "            batch_x = X_test[i:i+batch_size]\n",
    "            preds = model(batch_x, training=False).numpy()  # [B, H, W]\n",
    "            y_pred.extend(preds)\n",
    "        y_pred = np.array(y_pred)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "        y_pred = np.argmax(y_pred, axis=-1)  # [B, H, W]\n",
    "\n",
    "    y_test_class = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    class_metrics = {\n",
    "        i: {'dice': [], 'iou': [], 'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'hausdorff': [], 'asd': []}\n",
    "        for i in range(num_classes)\n",
    "    }\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        true_mask = y_test_class[i]\n",
    "        pred_mask = y_pred[i]\n",
    "        for class_idx in range(num_classes):\n",
    "            true_class_mask = (true_mask == class_idx).astype(int)\n",
    "            pred_class_mask = (pred_mask == class_idx).astype(int)\n",
    "\n",
    "            class_metrics[class_idx]['dice'].append(dice_coefficient(true_class_mask, pred_class_mask))\n",
    "            class_metrics[class_idx]['iou'].append(iou(true_class_mask, pred_class_mask))\n",
    "            class_metrics[class_idx]['precision'].append(precision_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['recall'].append(recall_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['f1'].append(f1_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            class_metrics[class_idx]['accuracy'].append(accuracy_score(true_class_mask.flatten(), pred_class_mask.flatten()))\n",
    "            # class_metrics[class_idx]['hausdorff'].append(hausdorff_distance(true_class_mask, pred_class_mask))\n",
    "            # class_metrics[class_idx]['asd'].append(average_surface_distance(true_class_mask, pred_class_mask))\n",
    "\n",
    "    # ðŸ“Š Print results\n",
    "    print(f\"{'Class':<10}{'Dice Coef (%)':<15}{'IoU (%)':<12}{'Precision (%)':<17}{'Recall (%)':<15}{'F1 Score (%)':<17}{'Accuracy (%)':<17}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        print(f\"{class_idx:<10}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['dice']) * 100:>10.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['iou']) * 100:>12.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['precision']) * 100:>17.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['recall']) * 100:>15.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['f1']) * 100:>17.2f}\"\n",
    "              f\"{np.mean(class_metrics[class_idx]['accuracy']) * 100:>17.2f}\")\n",
    "        # Optional: Print Hausdorff and ASD if needed\n",
    "\n",
    "ensemble_model = HardVotingEnsemble([model_xception, model_segnet, model_inceptionresnetv2])\n",
    "\n",
    "# Evaluate like before (same evaluation function as used with soft voting)\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_ensemble = HardVotingEnsemble(\n",
    "    models=[model_xception, model_segnet, model_inceptionresnetv2],\n",
    "    num_classes=4\n",
    ")\n",
    "\n",
    "hard_ensemble.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "hard_ensemble.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = HardVotingEnsemble(\n",
    "    models=[model_segnet, model_efficientnetb4],\n",
    "    # num_classes=4,\n",
    "    # return_probs=False\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate like before (same evaluation function as used with soft voting)\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = HardVotingEnsemble(\n",
    "    models=[model_segnet, model_efficientnetb4],\n",
    "    num_classes=4\n",
    ")\n",
    "\n",
    "hard_ensemble.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "hard_ensemble.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = HardVotingEnsemble([model_xception, model_efficientnetb4], num_classes=4)\n",
    "\n",
    "# Evaluate like before (same evaluation function as used with soft voting)\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_ensemble = HardVotingEnsemble(\n",
    "    models=[model_xception, model_efficientnetb4],\n",
    "    num_classes=4\n",
    ")\n",
    "\n",
    "hard_ensemble.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "hard_ensemble.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = HardVotingEnsemble([model_efficientnetb4, model_inceptionresnetv2])\n",
    "    # num_classes=4,\n",
    "    # return_probs=False \n",
    "\n",
    "# Evaluate like before (same evaluation function as used with soft voting)\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_ensemble = HardVotingEnsemble(\n",
    "    models=[model_efficientnetb4, model_inceptionresnetv2],\n",
    "    num_classes=4\n",
    ")\n",
    "\n",
    "hard_ensemble.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "hard_ensemble.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = HardVotingEnsemble([model_xception, model_segnet, model_efficientnetb4])\n",
    "\n",
    "# Evaluate like before (same evaluation function as used with soft voting)\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_ensemble = HardVotingEnsemble(\n",
    "    models=[model_xception, model_segnet, model_efficientnetb4],\n",
    "    num_classes=4\n",
    ")\n",
    "\n",
    "hard_ensemble.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "hard_ensemble.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = HardVotingEnsemble([model_xception, model_efficientnetb4, model_inceptionresnetv2])\n",
    "\n",
    "# Evaluate like before (same evaluation function as used with soft voting)\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_ensemble = HardVotingEnsemble(\n",
    "    models=[model_xception, model_efficientnetb4, model_inceptionresnetv2],\n",
    "    num_classes=4\n",
    ")\n",
    "\n",
    "hard_ensemble.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "hard_ensemble.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = HardVotingEnsemble([model_efficientnetb4, model_segnet, model_inceptionresnetv2])\n",
    "\n",
    "# Evaluate like before (same evaluation function as used with soft voting)\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_ensemble = HardVotingEnsemble(\n",
    "    models=[model_efficientnetb4, model_segnet, model_inceptionresnetv2],\n",
    "    num_classes=4\n",
    ")\n",
    "\n",
    "hard_ensemble.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "hard_ensemble.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = HardVotingEnsemble([model_xception, model_segnet, model_inceptionresnetv2, model_efficientnetb4])\n",
    "\n",
    "# Evaluate like before (same evaluation function as used with soft voting)\n",
    "evaluate_classwise_metrics(ensemble_model, X_test, y_test, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_ensemble = HardVotingEnsemble(\n",
    "    models=[model_xception, model_segnet, model_inceptionresnetv2, model_efficientnetb4],\n",
    "    num_classes=4\n",
    ")\n",
    "\n",
    "hard_ensemble.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "hard_ensemble.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Weighted Soft Voting</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# âœ… Softmax wrapper\n",
    "def get_softmax_preds(model, dataset):\n",
    "    preds = []\n",
    "    for x_batch, _ in dataset:\n",
    "        logits = model(x_batch, training=False)\n",
    "        probs = tf.nn.softmax(logits)  # [B, H, W, C]\n",
    "        preds.append(probs)\n",
    "    return tf.concat(preds, axis=0)\n",
    "\n",
    "# âœ… One-hot true labels from dataset\n",
    "def get_ground_truth(dataset):\n",
    "    y_true_list = [y for _, y in dataset]\n",
    "    return tf.concat(y_true_list, axis=0)\n",
    "\n",
    "# âœ… Dice calculation\n",
    "def dice_score(y_true, y_pred, smooth=1e-6):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice).numpy()\n",
    "\n",
    "# âœ… Optuna objective function\n",
    "def objective(trial):\n",
    "    # Sample weights and normalize them\n",
    "    raw_weights = [trial.suggest_float(f'w{i}', 0.0, 1.0) for i in range(len(models))]\n",
    "    total = sum(raw_weights)\n",
    "    weights = [w / total for w in raw_weights]\n",
    "\n",
    "    # Weighted ensemble\n",
    "    ensemble_pred = sum(w * p for w, p in zip(weights, all_softmax_preds))\n",
    "    dice = dice_score(y_true, ensemble_pred)\n",
    "    return dice\n",
    "\n",
    "# Step 1: Get predictions from each model\n",
    "models = [model_xception, model_segnet, model_inceptionresnetv2, model_efficientnetb4]\n",
    "all_softmax_preds = [get_softmax_preds(m, val_dataset) for m in models]\n",
    "\n",
    "# Step 2: Get validation ground truth\n",
    "y_true = get_ground_truth(val_dataset)\n",
    "\n",
    "# Step 3: Optimize with Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Step 4: Get best weights, rounded\n",
    "best_raw = [study.best_trial.params[f'w{i}'] for i in range(len(models))]\n",
    "total = sum(best_raw)\n",
    "best_weights = [round(w / total, 4) for w in best_raw]\n",
    "\n",
    "print(\"âœ… Best weights (normalized, rounded):\", best_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class WeightedSoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, weights=None, apply_softmax=True):\n",
    "        super(WeightedSoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        if weights is None:\n",
    "            weights = [1.0 / len(models)] * len(models)\n",
    "        else:\n",
    "            total = sum(weights)\n",
    "            weights = [w / total for w in weights]\n",
    "\n",
    "        self.model_weights = tf.constant(weights, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        weighted_sum = 0\n",
    "        for i, model in enumerate(self.models):\n",
    "            output = model(x, training=training)\n",
    "\n",
    "            is_softmaxed = (\n",
    "                hasattr(model, \"name\") and \"efficientnet\" in model.name.lower()\n",
    "            )\n",
    "\n",
    "            if self.apply_softmax and not is_softmaxed:\n",
    "                probs = tf.nn.softmax(output, axis=-1)\n",
    "            else:\n",
    "                probs = output\n",
    "\n",
    "            weighted_sum += self.model_weights[i] * probs\n",
    "\n",
    "        avg_prob = weighted_sum  # shape: [B, H, W, C]\n",
    "\n",
    "        # ðŸ” Convert to one-hot for metric compatibility\n",
    "        one_hot_pred = tf.one_hot(tf.argmax(avg_prob, axis=-1), depth=avg_prob.shape[-1])\n",
    "        return one_hot_pred  # [B, H, W, C]\n",
    "\n",
    "        \n",
    "weights = [1, 1, 1, 1]\n",
    "\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=[model_xception, model_segnet, model_inceptionresnetv2, model_efficientnetb4],\n",
    "    weights=weights\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "# === YOUR TRAINED MODELS HERE ===\n",
    "models = [\n",
    "    model_xception,\n",
    "    model_segnet,\n",
    "    model_inceptionresnetv2,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "import tensorflow as tf\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "# === INPUTS ===\n",
    "# models: your list of trained models\n",
    "# X_val, y_val: validation data as numpy arrays or tensors (one-hot encoded y_val)\n",
    "# Example: y_val shape = [B, H, W, C], with one-hot encoding\n",
    "\n",
    "# === STEP 1: Batch-wise softmax predictions from each model ===\n",
    "def get_softmax_preds_from_array(model, X, batch_size=16):\n",
    "    soft_preds = []\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        x_batch = X[i:i+batch_size]\n",
    "        logits = model(x_batch, training=False)\n",
    "        probs = tf.nn.softmax(logits)\n",
    "        soft_preds.append(probs)\n",
    "    return tf.concat(soft_preds, axis=0)\n",
    "\n",
    "# === STEP 2: Mean Dice (one-hot predictions only) ===\n",
    "def mean_dice_per_class(y_true, y_pred_soft, smooth=1e-6):\n",
    "    y_pred_argmax = tf.argmax(y_pred_soft, axis=-1)                     # [B, H, W]\n",
    "    y_pred = tf.one_hot(y_pred_argmax, depth=y_pred_soft.shape[-1])    # [B, H, W, C]\n",
    "\n",
    "    dice_scores = []\n",
    "    for i in range(y_true.shape[-1]):\n",
    "        y_true_c = y_true[..., i]\n",
    "        y_pred_c = y_pred[..., i]\n",
    "        intersection = tf.reduce_sum(y_true_c * y_pred_c)\n",
    "        union = tf.reduce_sum(y_true_c) + tf.reduce_sum(y_pred_c)\n",
    "        dice = (2. * intersection + smooth) / (union + smooth)\n",
    "        dice_scores.append(dice)\n",
    "    return tf.reduce_mean(tf.stack(dice_scores)).numpy()\n",
    "\n",
    "# === STEP 3: Precompute softmax predictions ===\n",
    "print(\"âœ… Precomputing predictions from all models...\")\n",
    "soft_preds_all = [get_softmax_preds_from_array(m, X_val) for m in models]\n",
    "y_true_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "\n",
    "# === STEP 4: Optuna Objective Function ===\n",
    "def objective(trial):\n",
    "    raw_weights = [trial.suggest_float(f'w{i}', 0.0, 1.0) for i in range(len(models))]\n",
    "    total = sum(raw_weights)\n",
    "    weights = [w / total for w in raw_weights]\n",
    "\n",
    "    # Weighted average of soft predictions\n",
    "    weighted_avg = sum(w * p for w, p in zip(weights, soft_preds_all))\n",
    "\n",
    "    # âœ… Compute mean Dice with one-hot predictions\n",
    "    score = mean_dice_per_class(y_true_val, weighted_avg)\n",
    "    return score\n",
    "\n",
    "# === STEP 5: Run Optuna Search ===\n",
    "print(\"ðŸŽ¯ Running Optuna for best ensemble weights...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# === STEP 6: Extract & Format Best Weights ===\n",
    "best_raw_weights = [study.best_trial.params[f\"w{i}\"] for i in range(len(models))]\n",
    "total = sum(best_raw_weights)\n",
    "final_weights = [round(w / total, 4) for w in best_raw_weights]\n",
    "\n",
    "print(\"\\nâœ… Best Ensemble Weights (rounded):\", final_weights)\n",
    "print(\"âœ… Best Mean Dice Score:\", round(study.best_value, 5))\n",
    "\n",
    "# === Final WeightedSoftVotingEnsemble using best weights ===\n",
    "class WeightedSoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, weights=None, apply_softmax=True):\n",
    "        super(WeightedSoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        if weights is None:\n",
    "            weights = [1.0 / len(models)] * len(models)\n",
    "        else:\n",
    "            total = sum(weights)\n",
    "            weights = [w / total for w in weights]\n",
    "\n",
    "        self.model_weights = tf.constant(weights, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        weighted_sum = 0\n",
    "        for i, model in enumerate(self.models):\n",
    "            output = model(x, training=training)\n",
    "\n",
    "            is_softmaxed = (\n",
    "                hasattr(model, \"name\") and \"efficientnet\" in model.name.lower()\n",
    "            )\n",
    "\n",
    "            if self.apply_softmax and not is_softmaxed:\n",
    "                probs = tf.nn.softmax(output, axis=-1)\n",
    "            else:\n",
    "                probs = output\n",
    "\n",
    "            weighted_sum += self.model_weights[i] * probs\n",
    "\n",
    "        avg_prob = weighted_sum  # shape: [B, H, W, C]\n",
    "\n",
    "        # ðŸ” Convert to one-hot for metric compatibility\n",
    "        one_hot_pred = tf.one_hot(tf.argmax(avg_prob, axis=-1), depth=avg_prob.shape[-1])\n",
    "        return one_hot_pred  # [B, H, W, C]\n",
    "\n",
    "# === Create the final ensemble model ===\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Final WeightedSoftVotingEnsemble using best weights ===\n",
    "class WeightedSoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, weights=None, apply_softmax=True):\n",
    "        super(WeightedSoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        if weights is None:\n",
    "            weights = [1.0 / len(models)] * len(models)\n",
    "        else:\n",
    "            total = sum(weights)\n",
    "            weights = [w / total for w in weights]\n",
    "\n",
    "        self.model_weights = tf.constant(weights, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        weighted_sum = 0\n",
    "        for i, model in enumerate(self.models):\n",
    "            output = model(x, training=training)\n",
    "\n",
    "            is_softmaxed = (\n",
    "                hasattr(model, \"name\") and \"efficientnet\" in model.name.lower()\n",
    "            )\n",
    "\n",
    "            if self.apply_softmax and not is_softmaxed:\n",
    "                probs = tf.nn.softmax(output, axis=-1)\n",
    "            else:\n",
    "                probs = output\n",
    "\n",
    "            weighted_sum += self.model_weights[i] * probs\n",
    "\n",
    "        avg_prob = weighted_sum  # shape: [B, H, W, C]\n",
    "\n",
    "        # ðŸ” Convert to one-hot for metric compatibility\n",
    "        one_hot_pred = tf.one_hot(tf.argmax(avg_prob, axis=-1), depth=avg_prob.shape[-1])\n",
    "        return one_hot_pred  # [B, H, W, C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_xception,\n",
    "    model_segnet,\n",
    "    model_inceptionresnetv2,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "final_weights = [0.3717, 0.301, 0.1892, 0.1381]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_xception,\n",
    "    model_inceptionresnetv2,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "print(\"âœ… Precomputing predictions from all models...\")\n",
    "soft_preds_all = [get_softmax_preds_from_array(m, X_val) for m in models]\n",
    "y_true_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "\n",
    "print(\"ðŸŽ¯ Running Optuna for best ensemble weights...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# === STEP 6: Extract & Format Best Weights ===\n",
    "best_raw_weights = [study.best_trial.params[f\"w{i}\"] for i in range(len(models))]\n",
    "total = sum(best_raw_weights)\n",
    "final_weights = [round(w / total, 4) for w in best_raw_weights]\n",
    "\n",
    "print(\"\\nâœ… Best Ensemble Weights (rounded):\", final_weights)\n",
    "print(\"âœ… Best Mean Dice Score:\", round(study.best_value, 5))\n",
    "\n",
    "print(final_weights)\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_xception,\n",
    "    model_inceptionresnetv2,\n",
    "    model_segnet\n",
    "]\n",
    "\n",
    "print(\"âœ… Precomputing predictions from all models...\")\n",
    "soft_preds_all = [get_softmax_preds_from_array(m, X_val) for m in models]\n",
    "y_true_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "\n",
    "print(\"ðŸŽ¯ Running Optuna for best ensemble weights...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# === STEP 6: Extract & Format Best Weights ===\n",
    "best_raw_weights = [study.best_trial.params[f\"w{i}\"] for i in range(len(models))]\n",
    "total = sum(best_raw_weights)\n",
    "final_weights = [round(w / total, 4) for w in best_raw_weights]\n",
    "\n",
    "print(\"\\nâœ… Best Ensemble Weights (rounded):\", final_weights)\n",
    "print(\"âœ… Best Mean Dice Score:\", round(study.best_value, 5))\n",
    "\n",
    "print(final_weights)\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_segnet,\n",
    "    model_inceptionresnetv2,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "print(\"âœ… Precomputing predictions from all models...\")\n",
    "soft_preds_all = [get_softmax_preds_from_array(m, X_val) for m in models]\n",
    "y_true_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "\n",
    "print(\"ðŸŽ¯ Running Optuna for best ensemble weights...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# === STEP 6: Extract & Format Best Weights ===\n",
    "best_raw_weights = [study.best_trial.params[f\"w{i}\"] for i in range(len(models))]\n",
    "total = sum(best_raw_weights)\n",
    "final_weights = [round(w / total, 4) for w in best_raw_weights]\n",
    "\n",
    "print(\"\\nâœ… Best Ensemble Weights (rounded):\", final_weights)\n",
    "print(\"âœ… Best Mean Dice Score:\", round(study.best_value, 5))\n",
    "\n",
    "print(final_weights)\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_segnet,\n",
    "    model_xception,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "print(\"âœ… Precomputing predictions from all models...\")\n",
    "soft_preds_all = [get_softmax_preds_from_array(m, X_val) for m in models]\n",
    "y_true_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "\n",
    "print(\"ðŸŽ¯ Running Optuna for best ensemble weights...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# === STEP 6: Extract & Format Best Weights ===\n",
    "best_raw_weights = [study.best_trial.params[f\"w{i}\"] for i in range(len(models))]\n",
    "total = sum(best_raw_weights)\n",
    "final_weights = [round(w / total, 4) for w in best_raw_weights]\n",
    "\n",
    "print(\"\\nâœ… Best Ensemble Weights (rounded):\", final_weights)\n",
    "print(\"âœ… Best Mean Dice Score:\", round(study.best_value, 5))\n",
    "\n",
    "print(final_weights)\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_xception,\n",
    "    model_inceptionresnetv2\n",
    "]\n",
    "\n",
    "print(\"âœ… Precomputing predictions from all models...\")\n",
    "soft_preds_all = [get_softmax_preds_from_array(m, X_val) for m in models]\n",
    "y_true_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "\n",
    "print(\"ðŸŽ¯ Running Optuna for best ensemble weights...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# === STEP 6: Extract & Format Best Weights ===\n",
    "best_raw_weights = [study.best_trial.params[f\"w{i}\"] for i in range(len(models))]\n",
    "total = sum(best_raw_weights)\n",
    "final_weights = [round(w / total, 4) for w in best_raw_weights]\n",
    "\n",
    "print(\"\\nâœ… Best Ensemble Weights (rounded):\", final_weights)\n",
    "print(\"âœ… Best Mean Dice Score:\", round(study.best_value, 5))\n",
    "\n",
    "print(final_weights)\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_inceptionresnetv2,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "print(\"âœ… Precomputing predictions from all models...\")\n",
    "soft_preds_all = [get_softmax_preds_from_array(m, X_val) for m in models]\n",
    "y_true_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "\n",
    "print(\"ðŸŽ¯ Running Optuna for best ensemble weights...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# === STEP 6: Extract & Format Best Weights ===\n",
    "best_raw_weights = [study.best_trial.params[f\"w{i}\"] for i in range(len(models))]\n",
    "total = sum(best_raw_weights)\n",
    "final_weights = [round(w / total, 4) for w in best_raw_weights]\n",
    "\n",
    "print(\"\\nâœ… Best Ensemble Weights (rounded):\", final_weights)\n",
    "print(\"âœ… Best Mean Dice Score:\", round(study.best_value, 5))\n",
    "\n",
    "print(final_weights)\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_inceptionresnetv2,\n",
    "    model_segnet\n",
    "]\n",
    "\n",
    "print(\"âœ… Precomputing predictions from all models...\")\n",
    "soft_preds_all = [get_softmax_preds_from_array(m, X_val) for m in models]\n",
    "y_true_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "\n",
    "print(\"ðŸŽ¯ Running Optuna for best ensemble weights...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# === STEP 6: Extract & Format Best Weights ===\n",
    "best_raw_weights = [study.best_trial.params[f\"w{i}\"] for i in range(len(models))]\n",
    "total = sum(best_raw_weights)\n",
    "final_weights = [round(w / total, 4) for w in best_raw_weights]\n",
    "\n",
    "print(\"\\nâœ… Best Ensemble Weights (rounded):\", final_weights)\n",
    "print(\"âœ… Best Mean Dice Score:\", round(study.best_value, 5))\n",
    "\n",
    "print(final_weights)\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_xception,\n",
    "    model_segnet\n",
    "]\n",
    "\n",
    "print(\"âœ… Precomputing predictions from all models...\")\n",
    "soft_preds_all = [get_softmax_preds_from_array(m, X_val) for m in models]\n",
    "y_true_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "\n",
    "print(\"ðŸŽ¯ Running Optuna for best ensemble weights...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# === STEP 6: Extract & Format Best Weights ===\n",
    "best_raw_weights = [study.best_trial.params[f\"w{i}\"] for i in range(len(models))]\n",
    "total = sum(best_raw_weights)\n",
    "final_weights = [round(w / total, 4) for w in best_raw_weights]\n",
    "\n",
    "print(\"\\nâœ… Best Ensemble Weights (rounded):\", final_weights)\n",
    "print(\"âœ… Best Mean Dice Score:\", round(study.best_value, 5))\n",
    "\n",
    "print(final_weights)\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_xception,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "print(\"âœ… Precomputing predictions from all models...\")\n",
    "soft_preds_all = [get_softmax_preds_from_array(m, X_val) for m in models]\n",
    "y_true_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "\n",
    "print(\"ðŸŽ¯ Running Optuna for best ensemble weights...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# === STEP 6: Extract & Format Best Weights ===\n",
    "best_raw_weights = [study.best_trial.params[f\"w{i}\"] for i in range(len(models))]\n",
    "total = sum(best_raw_weights)\n",
    "final_weights = [round(w / total, 4) for w in best_raw_weights]\n",
    "\n",
    "print(\"\\nâœ… Best Ensemble Weights (rounded):\", final_weights)\n",
    "print(\"âœ… Best Mean Dice Score:\", round(study.best_value, 5))\n",
    "\n",
    "print(final_weights)\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_segnet,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "print(\"âœ… Precomputing predictions from all models...\")\n",
    "soft_preds_all = [get_softmax_preds_from_array(m, X_val) for m in models]\n",
    "y_true_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "\n",
    "print(\"ðŸŽ¯ Running Optuna for best ensemble weights...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# === STEP 6: Extract & Format Best Weights ===\n",
    "best_raw_weights = [study.best_trial.params[f\"w{i}\"] for i in range(len(models))]\n",
    "total = sum(best_raw_weights)\n",
    "final_weights = [round(w / total, 4) for w in best_raw_weights]\n",
    "\n",
    "print(\"\\nâœ… Best Ensemble Weights (rounded):\", final_weights)\n",
    "print(\"âœ… Best Mean Dice Score:\", round(study.best_value, 5))\n",
    "\n",
    "print(final_weights)\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_xception,\n",
    "    model_inceptionresnetv2,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "print(\"âœ… Precomputing predictions from all models...\")\n",
    "soft_preds_all = [get_softmax_preds_from_array(m, X_val) for m in models]\n",
    "y_true_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "\n",
    "print(\"ðŸŽ¯ Running Optuna for best ensemble weights...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# === STEP 6: Extract & Format Best Weights ===\n",
    "best_raw_weights = [study.best_trial.params[f\"w{i}\"] for i in range(len(models))]\n",
    "total = sum(best_raw_weights)\n",
    "final_weights = [round(w / total, 4) for w in best_raw_weights]\n",
    "\n",
    "print(\"\\nâœ… Best Ensemble Weights (rounded):\", final_weights)\n",
    "print(\"âœ… Best Mean Dice Score:\", round(study.best_value, 5))\n",
    "\n",
    "print(final_weights)\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_xception,\n",
    "    model_inceptionresnetv2,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "print(\"âœ… Precomputing predictions from all models...\")\n",
    "soft_preds_all = [get_softmax_preds_from_array(m, X_val) for m in models]\n",
    "y_true_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "\n",
    "print(\"ðŸŽ¯ Running Optuna for best ensemble weights...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# === STEP 6: Extract & Format Best Weights ===\n",
    "best_raw_weights = [study.best_trial.params[f\"w{i}\"] for i in range(len(models))]\n",
    "total = sum(best_raw_weights)\n",
    "final_weights = [round(w / total, 4) for w in best_raw_weights]\n",
    "\n",
    "print(\"\\nâœ… Best Ensemble Weights (rounded):\", final_weights)\n",
    "print(\"âœ… Best Mean Dice Score:\", round(study.best_value, 5))\n",
    "\n",
    "print(final_weights)\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_xception,\n",
    "    model_inceptionresnetv2,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "print(\"âœ… Precomputing predictions from all models...\")\n",
    "soft_preds_all = [get_softmax_preds_from_array(m, X_val) for m in models]\n",
    "y_true_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "\n",
    "print(\"ðŸŽ¯ Running Optuna for best ensemble weights...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# === STEP 6: Extract & Format Best Weights ===\n",
    "best_raw_weights = [study.best_trial.params[f\"w{i}\"] for i in range(len(models))]\n",
    "total = sum(best_raw_weights)\n",
    "final_weights = [round(w / total, 4) for w in best_raw_weights]\n",
    "\n",
    "print(\"\\nâœ… Best Ensemble Weights (rounded):\", final_weights)\n",
    "print(\"âœ… Best Mean Dice Score:\", round(study.best_value, 5))\n",
    "\n",
    "print(final_weights)\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_xception,\n",
    "    model_inceptionresnetv2,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "print(\"âœ… Precomputing predictions from all models...\")\n",
    "soft_preds_all = [get_softmax_preds_from_array(m, X_val) for m in models]\n",
    "y_true_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "\n",
    "print(\"ðŸŽ¯ Running Optuna for best ensemble weights...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# === STEP 6: Extract & Format Best Weights ===\n",
    "best_raw_weights = [study.best_trial.params[f\"w{i}\"] for i in range(len(models))]\n",
    "total = sum(best_raw_weights)\n",
    "final_weights = [round(w / total, 4) for w in best_raw_weights]\n",
    "\n",
    "print(\"\\nâœ… Best Ensemble Weights (rounded):\", final_weights)\n",
    "print(\"âœ… Best Mean Dice Score:\", round(study.best_value, 5))\n",
    "\n",
    "print(final_weights)\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    model_xception,\n",
    "    model_inceptionresnetv2,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "print(\"âœ… Precomputing predictions from all models...\")\n",
    "soft_preds_all = [get_softmax_preds_from_array(m, X_val) for m in models]\n",
    "y_true_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "\n",
    "print(\"ðŸŽ¯ Running Optuna for best ensemble weights...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# === STEP 6: Extract & Format Best Weights ===\n",
    "best_raw_weights = [study.best_trial.params[f\"w{i}\"] for i in range(len(models))]\n",
    "total = sum(best_raw_weights)\n",
    "final_weights = [round(w / total, 4) for w in best_raw_weights]\n",
    "\n",
    "print(\"\\nâœ… Best Ensemble Weights (rounded):\", final_weights)\n",
    "print(\"âœ… Best Mean Dice Score:\", round(study.best_value, 5))\n",
    "\n",
    "print(final_weights)\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def decode_segmentation(mask, num_classes=4):\n",
    "    \"\"\"\n",
    "    Converts a one-hot encoded mask or softmax prediction into a color image.\n",
    "    \"\"\"\n",
    "    label_mask = np.argmax(mask, axis=-1)  # shape: (H, W)\n",
    "    colors = [\n",
    "        (0, 0, 0),         # Background - Black\n",
    "        (255, 0, 0),       # Brain - Red\n",
    "        (0, 255, 0),       # CSP - Green\n",
    "        (0, 0, 255),       # LV - Blue\n",
    "    ]\n",
    "\n",
    "    color_mask = np.zeros((*label_mask.shape, 3), dtype=np.uint8)\n",
    "    for cls_idx, color in enumerate(colors):\n",
    "        color_mask[label_mask == cls_idx] = color\n",
    "    return color_mask\n",
    "\n",
    "def display_predictions(model, X, y_true, num_samples=5):\n",
    "    indices = random.sample(range(len(X)), num_samples)\n",
    "    X_samples = X[indices]\n",
    "    y_samples = y_true[indices]\n",
    "\n",
    "    preds = model.predict(X_samples)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        image = X_samples[i]\n",
    "        true_mask = decode_segmentation(y_samples[i])\n",
    "        pred_mask = decode_segmentation(preds[i])\n",
    "\n",
    "        # Plot side-by-side\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        # Ground truth overlay\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image.astype(np.uint8))\n",
    "        plt.imshow(true_mask, alpha=0.5)\n",
    "        plt.title(\"Ground Truth Overlay\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Prediction overlay\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(image.astype(np.uint8))\n",
    "        plt.imshow(pred_mask, alpha=0.5)\n",
    "        plt.title(\"Prediction Overlay\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_predictions(model, X_test, y_test, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Function to decode one-hot encoded mask or softmax prediction into RGB\n",
    "def decode_segmentation(mask, num_classes=4):\n",
    "    label_mask = np.argmax(mask, axis=-1)  # shape: (H, W)\n",
    "    \n",
    "    colors = [\n",
    "        (0, 0, 0),         # Background - Black\n",
    "        (255, 0, 0),       # Brain - Red\n",
    "        (0, 255, 0),       # CSP - Green\n",
    "        (0, 0, 255),       # LV - Blue\n",
    "    ]\n",
    "    \n",
    "    color_mask = np.zeros((*label_mask.shape, 3), dtype=np.uint8)\n",
    "    for cls_idx, color in enumerate(colors):\n",
    "        color_mask[label_mask == cls_idx] = color\n",
    "    return color_mask\n",
    "\n",
    "# Function to overlay mask on an image\n",
    "def overlay_mask_on_image(image, mask, alpha=0.5):\n",
    "    overlay = image.copy()\n",
    "    if overlay.max() <= 1.0:\n",
    "        overlay = (overlay * 255).astype(np.uint8)\n",
    "\n",
    "    if mask.max() <= 1.0:\n",
    "        mask = (mask * 255).astype(np.uint8)\n",
    "    \n",
    "    overlay = overlay.astype(np.float32)\n",
    "    mask = mask.astype(np.float32)\n",
    "    \n",
    "    combined = cv2.addWeighted(overlay, 1 - alpha, mask, alpha, 0)\n",
    "    return combined.astype(np.uint8)\n",
    "\n",
    "# Main display function for N samples\n",
    "def display_overlay_predictions(model, X, y_true, num_samples=5):\n",
    "    import cv2\n",
    "    indices = random.sample(range(len(X)), num_samples)\n",
    "    \n",
    "    X_batch = X[indices]\n",
    "    y_batch = y_true[indices]\n",
    "    y_pred_batch = model.predict(X_batch)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        image = X_batch[i]\n",
    "        true_mask = decode_segmentation(y_batch[i])\n",
    "        pred_mask = decode_segmentation(y_pred_batch[i])\n",
    "\n",
    "        # Make sure image is uint8\n",
    "        if image.max() <= 1.0:\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "\n",
    "        gt_overlay = overlay_mask_on_image(image, true_mask, alpha=0.5)\n",
    "        pred_overlay = overlay_mask_on_image(image, pred_mask, alpha=0.5)\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(gt_overlay)\n",
    "        plt.title(\"Ground Truth Overlay\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(pred_overlay)\n",
    "        plt.title(\"Predicted Overlay\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "display_overlay_predictions(model, X_test, y_test, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Knowledge Distillation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "image_dir = r\"D:\\augmented_dataset\\images\"\n",
    "mask_dir = r\"D:\\augmented_dataset\\masks\"\n",
    "\n",
    "# # âœ… Define destination directories\n",
    "train_image_dir = r\"D:\\Updated\\train\\images\"\n",
    "train_mask_dir = r\"D:\\Updated\\train\\masks\"\n",
    "val_image_dir = r\"D:\\Updated\\val\\images\"\n",
    "val_mask_dir = r\"D:\\Updated\\val\\masks\"\n",
    "test_image_dir = r\"D:\\Updated\\test\\images\"\n",
    "test_mask_dir = r\"D:\\Updated\\test\\masks\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import re\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# âœ… Constants for 224x224\n",
    "IMG_HEIGHT = 224  # Ensure height is 224\n",
    "IMG_WIDTH = 224   # Ensure width is 224\n",
    "CHANNELS = 3  # RGB images\n",
    "NUM_CLASSES = 4  # Brain, CSP, LV, Background\n",
    "\n",
    "# âœ… Class mapping from RGB to class index\n",
    "CLASS_MAP = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0,  # Background\n",
    "}\n",
    "\n",
    "# âœ… Fix sorting issue using natural sorting\n",
    "def natural_sort_key(s):\n",
    "    \"\"\"Sort filenames numerically instead of lexicographically.\"\"\"\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "# âœ… Convert RGB mask to class index mask\n",
    "def rgb_to_class(mask_array):\n",
    "    \"\"\"Convert RGB mask to single-channel class index mask.\"\"\"\n",
    "    height, width, _ = mask_array.shape\n",
    "    class_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    for rgb, class_idx in CLASS_MAP.items():\n",
    "        matches = np.all(mask_array == rgb, axis=-1)  # Ensure exact match\n",
    "        class_mask[matches] = class_idx\n",
    "\n",
    "    return class_mask\n",
    "\n",
    "# âœ… Preprocess Filtered Dataset for 224x224\n",
    "def preprocess_filtered_dataset(image_dir, mask_dir):\n",
    "    \"\"\"Preprocess images & masks: normalize, resize, and convert masks to one-hot encoding.\"\"\"\n",
    "\n",
    "    # âœ… Load and sort filenames correctly\n",
    "    image_filenames = sorted(os.listdir(image_dir), key=natural_sort_key)\n",
    "    mask_filenames = sorted(os.listdir(mask_dir), key=natural_sort_key)\n",
    "\n",
    "    valid_image_paths = []\n",
    "    valid_mask_paths = []\n",
    "\n",
    "    # âœ… Ensure each image has a corresponding mask\n",
    "    for img_file, mask_file in zip(image_filenames, mask_filenames):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "        if os.path.exists(img_path) and os.path.exists(mask_path):\n",
    "            valid_image_paths.append(img_path)\n",
    "            valid_mask_paths.append(mask_path)\n",
    "        else:\n",
    "            print(f\"âš ï¸ Skipping {img_file}: Missing image or mask\")\n",
    "\n",
    "    num_images = len(valid_image_paths)\n",
    "\n",
    "    # âœ… Initialize arrays\n",
    "    X = np.zeros((num_images, IMG_HEIGHT, IMG_WIDTH, CHANNELS), dtype=np.float32)\n",
    "    y = np.zeros((num_images, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES), dtype=np.float32)  # One-hot encoded masks\n",
    "\n",
    "    print(f\"ðŸš€ Processing {num_images} filtered images and masks...\")\n",
    "\n",
    "    for idx, (img_path, mask_path) in enumerate(zip(valid_image_paths, valid_mask_paths)):\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"âœ… Processed {idx}/{num_images} images\")\n",
    "\n",
    "        # âœ… Load and Resize Image\n",
    "        img = cv2.imread(img_path)  # Read image in BGR format\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))  # Resize to (224,224)\n",
    "        img = img.astype(np.float32) / 255.0  # Normalize\n",
    "\n",
    "        # âœ… Load and Resize Mask\n",
    "        mask = cv2.imread(mask_path)  # Read mask in BGR format\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)  # Resize mask correctly\n",
    "\n",
    "        # âœ… Convert RGB mask to class mask\n",
    "        class_mask = rgb_to_class(mask)\n",
    "\n",
    "        # âœ… One-hot encode the class mask\n",
    "        one_hot_mask = to_categorical(class_mask, num_classes=NUM_CLASSES)\n",
    "\n",
    "        # âœ… Store preprocessed data\n",
    "        X[idx] = img\n",
    "        y[idx] = one_hot_mask\n",
    "\n",
    "        # âœ… Clear memory to prevent memory leaks\n",
    "        del img, mask, class_mask, one_hot_mask\n",
    "        gc.collect()\n",
    "\n",
    "    return X, y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# âœ… Process dataset splits\n",
    "X_train, y_train = preprocess_filtered_dataset(train_image_dir, train_mask_dir)\n",
    "X_val, y_val = preprocess_filtered_dataset(val_image_dir, val_mask_dir)\n",
    "X_test, y_test = preprocess_filtered_dataset(test_image_dir, test_mask_dir)\n",
    "\n",
    "# âœ… Print dataset information\n",
    "print(\"\\nâœ… Dataset Splits:\")\n",
    "print(f\"  - Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"  - Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"  - Test set: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data Augmentation configuration for the training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "# Fit the augmentation parameters on the training data\n",
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Activation, UpSampling2D, Concatenate\n",
    "\n",
    "def conv_block(inputs, filters, kernel_size=(3, 3), padding=\"same\", use_batch_norm=True):\n",
    "    \"\"\"\n",
    "    Convolutional block with optional batch normalization\n",
    "    \"\"\"\n",
    "    x = Conv2D(filters, kernel_size, padding=padding)(inputs)\n",
    "    \n",
    "    if use_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size, padding=padding)(x)\n",
    "    \n",
    "    if use_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def UNetPlusPlus(input_shape=(224, 224, 3), num_classes=4, filters=[24, 48, 96, 192], use_batch_norm=True):\n",
    "    \"\"\"\n",
    "    UNet++ (Nested U-Net) model for multiclass segmentation\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Input image dimensions (height, width, channels)\n",
    "        num_classes: Number of output classes for segmentation\n",
    "        filters: List of filter dimensions for each level\n",
    "        use_batch_norm: Whether to use batch normalization\n",
    "        \n",
    "    Returns:\n",
    "        tf.keras.Model: UNet++ model\n",
    "    \"\"\"\n",
    "    # Input\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder (Downsampling path)\n",
    "    conv0_0 = conv_block(inputs, filters[0], use_batch_norm=use_batch_norm)\n",
    "    pool0 = MaxPooling2D(pool_size=(2, 2))(conv0_0)\n",
    "    \n",
    "    conv1_0 = conv_block(pool0, filters[1], use_batch_norm=use_batch_norm)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1_0)\n",
    "    \n",
    "    conv2_0 = conv_block(pool1, filters[2], use_batch_norm=use_batch_norm)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2_0)\n",
    "    \n",
    "    conv3_0 = conv_block(pool2, filters[3], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    # Decoder (Upsampling path with nested dense skip connections)\n",
    "    # Level 1 skip connections\n",
    "    up1_0 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv3_0)\n",
    "    conv2_1 = conv_block(Concatenate()([up1_0, conv2_0]), filters[2], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    up0_1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv2_0)\n",
    "    conv1_1 = conv_block(Concatenate()([up0_1, conv1_0]), filters[1], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    up0_2 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv1_0)\n",
    "    conv0_1 = conv_block(Concatenate()([up0_2, conv0_0]), filters[0], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    # Level 2 skip connections\n",
    "    up1_1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv2_1)\n",
    "    conv1_2 = conv_block(Concatenate()([up1_1, conv1_0, conv1_1]), filters[1], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    up0_3 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv1_1)\n",
    "    conv0_2 = conv_block(Concatenate()([up0_3, conv0_0, conv0_1]), filters[0], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    # Level 3 skip connections\n",
    "    up0_4 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv1_2)\n",
    "    conv0_3 = conv_block(Concatenate()([up0_4, conv0_0, conv0_1, conv0_2]), filters[0], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    # Output segmentation map\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(conv0_3)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "student_model = UNetPlusPlus(input_shape=(224, 224, 3), num_classes=4)\n",
    "student_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Activation, UpSampling2D, Concatenate, Add\n",
    "\n",
    "def res_conv_block(inputs, filters, kernel_size=(3, 3), padding=\"same\", use_batch_norm=True):\n",
    "    \"\"\"\n",
    "    Residual convolutional block with skip connections\n",
    "    \"\"\"\n",
    "    # Store input for residual connection\n",
    "    shortcut = inputs\n",
    "    \n",
    "    # First convolution\n",
    "    x = Conv2D(filters, kernel_size, padding=padding)(inputs)\n",
    "    if use_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    # Second convolution\n",
    "    x = Conv2D(filters, kernel_size, padding=padding)(x)\n",
    "    if use_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    \n",
    "    # If input channels don't match output channels, use 1x1 conv to match dimensions\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, (1, 1), padding=padding)(shortcut)\n",
    "        if use_batch_norm:\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    # Add residual connection\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def UNetPlusPlus(input_shape=(224, 224, 3), num_classes=4, filters=[24, 48, 96, 192], use_batch_norm=True):\n",
    "    \"\"\"\n",
    "    Enhanced UNet++ with residual connections\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Input image dimensions (height, width, channels)\n",
    "        num_classes: Number of output classes for segmentation\n",
    "        filters: List of filter dimensions for each level\n",
    "        use_batch_norm: Whether to use batch normalization\n",
    "    \"\"\"\n",
    "    # Input\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder (Downsampling path)\n",
    "    conv0_0 = res_conv_block(inputs, filters[0], use_batch_norm=use_batch_norm)\n",
    "    pool0 = MaxPooling2D(pool_size=(2, 2))(conv0_0)\n",
    "    \n",
    "    conv1_0 = res_conv_block(pool0, filters[1], use_batch_norm=use_batch_norm)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1_0)\n",
    "    \n",
    "    conv2_0 = res_conv_block(pool1, filters[2], use_batch_norm=use_batch_norm)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2_0)\n",
    "    \n",
    "    conv3_0 = res_conv_block(pool2, filters[3], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    # Decoder (Upsampling path with nested dense skip connections)\n",
    "    # Level 1 skip connections\n",
    "    up1_0 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv3_0)\n",
    "    concat2_1 = Concatenate()([up1_0, conv2_0])\n",
    "    conv2_1 = res_conv_block(concat2_1, filters[2], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    up0_1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv2_0)\n",
    "    concat1_1 = Concatenate()([up0_1, conv1_0])\n",
    "    conv1_1 = res_conv_block(concat1_1, filters[1], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    up0_2 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv1_0)\n",
    "    concat0_1 = Concatenate()([up0_2, conv0_0])\n",
    "    conv0_1 = res_conv_block(concat0_1, filters[0], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    # Level 2 skip connections\n",
    "    up1_1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv2_1)\n",
    "    concat1_2 = Concatenate()([up1_1, conv1_0, conv1_1])\n",
    "    conv1_2 = res_conv_block(concat1_2, filters[1], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    up0_3 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv1_1)\n",
    "    concat0_2 = Concatenate()([up0_3, conv0_0, conv0_1])\n",
    "    conv0_2 = res_conv_block(concat0_2, filters[0], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    # Level 3 skip connections\n",
    "    up0_4 = UpSampling2D(size=(2, 2), interpolation='bilinear')(conv1_2)\n",
    "    concat0_3 = Concatenate()([up0_4, conv0_0, conv0_1, conv0_2])\n",
    "    conv0_3 = res_conv_block(concat0_3, filters[0], use_batch_norm=use_batch_norm)\n",
    "    \n",
    "    # Output segmentation map (single output)\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(conv0_3)\n",
    "    \n",
    "    # Create model with single output\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    "\n",
    "student_model = UNetPlusPlus(input_shape=(224, 224, 3), num_classes=4)\n",
    "student_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "# === Config ===\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "\n",
    "# === Resize Layer ===\n",
    "class ResizeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, target_size, **kwargs):\n",
    "        super(ResizeLayer, self).__init__(**kwargs)\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.image.resize(inputs, self.target_size, method='bilinear')\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'target_size': self.target_size})\n",
    "        return config\n",
    "\n",
    "\n",
    "# === Conv Block ===\n",
    "def conv_block(x, filters, kernel_size=3, strides=1):\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same', strides=strides, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# === MBConv Block ===\n",
    "def mbconv_block(x, in_ch, out_ch, stride=1, expansion=4):\n",
    "    hidden_dim = in_ch * expansion\n",
    "    res = x\n",
    "    x = layers.Conv2D(hidden_dim, 1, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('swish')(x)\n",
    "\n",
    "    x = layers.DepthwiseConv2D(3, strides=stride, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('swish')(x)\n",
    "\n",
    "    x = layers.Conv2D(out_ch, 1, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if stride == 1 and in_ch == out_ch:\n",
    "        x = layers.Add()([res, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "# === MLA Block ===\n",
    "def mla_block(x, channels, stride=1):\n",
    "    residual = x\n",
    "\n",
    "    if stride > 1:\n",
    "        residual = layers.AveragePooling2D(pool_size=stride, strides=stride, padding='same')(residual)\n",
    "        x = layers.AveragePooling2D(pool_size=stride, strides=stride, padding='same')(x)\n",
    "\n",
    "    if x.shape[-1] != channels:\n",
    "        residual = layers.Conv2D(channels, 1, padding='same')(residual)\n",
    "\n",
    "    attn = layers.DepthwiseConv2D(5, padding='same')(x)\n",
    "    attn = layers.Conv2D(channels, 1, padding='same')(attn)\n",
    "    attn = layers.ReLU()(attn)\n",
    "\n",
    "    return layers.Add()([residual, attn])\n",
    "\n",
    "\n",
    "# === EfficientViT Block ===\n",
    "def efficientvit_block(x, in_ch, out_ch, stride=1):\n",
    "    local = mbconv_block(x, in_ch, out_ch, stride=stride)\n",
    "    global_ = mla_block(x, out_ch, stride=stride)\n",
    "    return layers.Add()([local, global_])\n",
    "\n",
    "\n",
    "# EfficientViT-B0 Encoder\n",
    "def efficientvit_b0_encoder(inputs):\n",
    "    x = layers.Conv2D(16, 3, strides=2, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('swish')(x)\n",
    "    e0 = x  # 112x112\n",
    "\n",
    "    x = efficientvit_block(x, 16, 32, stride=2)\n",
    "    e1 = x  # 56x56\n",
    "\n",
    "    x = efficientvit_block(x, 32, 64, stride=2)\n",
    "    e2 = x  # 28x28\n",
    "\n",
    "    x = efficientvit_block(x, 64, 96, stride=2)\n",
    "    e3 = x  # 14x14\n",
    "\n",
    "    x = efficientvit_block(x, 96, 128, stride=2)\n",
    "    e4 = x  # 7x7\n",
    "\n",
    "    return [e0, e1, e2, e3, e4]\n",
    "\n",
    "\n",
    "def attention_gate(x, g, inter_channels):\n",
    "    \"\"\"Standard attention gate block\"\"\"\n",
    "    x_shape = tf.keras.backend.int_shape(x)\n",
    "    g_shape = tf.keras.backend.int_shape(g)\n",
    "\n",
    "    if x_shape[1] != g_shape[1] or x_shape[2] != g_shape[2]:\n",
    "        g = ResizeLayer((x_shape[1], x_shape[2]))(g)\n",
    "\n",
    "    theta_x = layers.Conv2D(inter_channels, 1, padding='same')(x)\n",
    "    phi_g = layers.Conv2D(inter_channels, 1, padding='same')(g)\n",
    "    f = layers.Add()([theta_x, phi_g])\n",
    "    f = layers.Activation('relu')(f)\n",
    "    psi = layers.Conv2D(1, 1, padding='same')(f)\n",
    "    alpha = layers.Activation('sigmoid')(psi)\n",
    "    return layers.Multiply()([x, alpha])\n",
    "\n",
    "\n",
    "def build_attention_unet_with_efficientvit(input_shape=(224, 224, 3), num_classes=4):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # === EfficientViT Encoder ===\n",
    "    encoder_features = efficientvit_b0_encoder(inputs)\n",
    "    e0, e1, e2, e3, e4 = encoder_features  # e0: shallowest, e4: bottleneck\n",
    "\n",
    "    # === Decoder with Attention U-Net style ===\n",
    "    up_filters = [96, 64, 32, 16]\n",
    "    skip_connections = [e3, e2, e1, e0]  # deepest to shallowest\n",
    "    up = e4  # bottleneck\n",
    "\n",
    "    for i in range(4):\n",
    "        up = layers.Conv2DTranspose(up_filters[i], 3, strides=2, padding='same')(up)\n",
    "        up = layers.BatchNormalization()(up)\n",
    "        up = layers.Activation('relu')(up)\n",
    "        up = layers.Dropout(0.2)(up)\n",
    "\n",
    "        skip = skip_connections[i]\n",
    "        att_skip = attention_gate(skip, up, up_filters[i] // 2)\n",
    "\n",
    "        # Resize up to match skip if needed\n",
    "        if tf.keras.backend.int_shape(att_skip)[1:3] != tf.keras.backend.int_shape(up)[1:3]:\n",
    "            up = ResizeLayer((att_skip.shape[1], att_skip.shape[2]))(up)\n",
    "\n",
    "        up = layers.Concatenate()([up, att_skip])\n",
    "        up = conv_block(up, up_filters[i])\n",
    "        up = conv_block(up, up_filters[i])\n",
    "\n",
    "    # Final Upsampling to full resolution\n",
    "    up = layers.Conv2DTranspose(64, 3, strides=2, padding='same')(up)\n",
    "    up = conv_block(up, 64)\n",
    "    up = conv_block(up, 32)\n",
    "\n",
    "    if tf.keras.backend.int_shape(up)[1:3] != (input_shape[0], input_shape[1]):\n",
    "        up = ResizeLayer((input_shape[0], input_shape[1]))(up)\n",
    "\n",
    "    outputs = layers.Conv2D(num_classes, 1, activation='softmax')(up)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# === Build and Print Model ===\n",
    "tf.keras.backend.clear_session()\n",
    "student_model = build_attention_unet_with_efficientvit(\n",
    "    input_shape=(224, 224, 3),\n",
    "    num_classes=4\n",
    ")\n",
    "student_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def clone_metric(metric):\n",
    "    if isinstance(metric, DiceCoefficient):\n",
    "        return DiceCoefficient(class_idx=metric.class_idx)\n",
    "    else:\n",
    "        return type(metric)(**metric.get_config())\n",
    "\n",
    "class Distiller(tf.keras.Model):\n",
    "    def __init__(self, student, teacher, temperature=3.0, alpha=0.5, metrics=None):\n",
    "        super().__init__()\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.kl_loss_fn = tf.keras.losses.KLDivergence()\n",
    "        self.train_accuracy = tf.keras.metrics.CategoricalAccuracy(name=\"train_accuracy\")\n",
    "        self.val_accuracy = tf.keras.metrics.CategoricalAccuracy(name=\"val_accuracy\")\n",
    "        self.train_metrics = metrics or []\n",
    "        self.val_metrics = [clone_metric(m) for m in self.train_metrics]\n",
    "\n",
    "\n",
    "    def compile(self, optimizer):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y_true = data\n",
    "        teacher_soft = self.teacher(x, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_logits = self.student(x, training=True)\n",
    "            student_soft = tf.nn.softmax(student_logits / self.temperature)\n",
    "            distill_loss = self.kl_loss_fn(teacher_soft, student_soft)\n",
    "            supervised_loss = combined_loss(y_true, tf.nn.softmax(student_logits))\n",
    "            loss = self.alpha * supervised_loss + (1 - self.alpha) * distill_loss\n",
    "\n",
    "        grads = tape.gradient(loss, self.student.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.student.trainable_variables))\n",
    "\n",
    "        self.train_accuracy.update_state(y_true, tf.nn.softmax(student_logits))\n",
    "        for m in self.train_metrics:\n",
    "            m.update_state(y_true, tf.nn.softmax(student_logits))\n",
    "\n",
    "        logs = {\"loss\": loss, \"accuracy\": self.train_accuracy.result()}\n",
    "        for m in self.train_metrics:\n",
    "            logs[m.name] = m.result()\n",
    "        return logs\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y_true = data\n",
    "        y_pred = self.student(x, training=False)\n",
    "\n",
    "        self.val_accuracy.update_state(y_true, tf.nn.softmax(y_pred))\n",
    "        for m in self.val_metrics:\n",
    "            m.update_state(y_true, tf.nn.softmax(y_pred))\n",
    "\n",
    "        logs = {\"accuracy\": self.val_accuracy.result()}\n",
    "        for m in self.val_metrics:\n",
    "            logs[m.name] = m.result()\n",
    "        return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',  # You can also use 'val_loss' if you log it manually\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',  # Or 'val_loss'\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='best_student_unetplusplus.keras',\n",
    "        monitor='val_loss',  # Or 'val_loss'\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "def create_train_generator(X, y, batch_size=16):\n",
    "    data_gen_args = dict(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    \n",
    "    seed = 42\n",
    "    image_generator = image_datagen.flow(X, batch_size=batch_size, seed=seed)\n",
    "    mask_generator = mask_datagen.flow(y, batch_size=batch_size, seed=seed)\n",
    "    \n",
    "    while True:\n",
    "        X_batch = next(image_generator)\n",
    "        y_batch = next(mask_generator)\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "train_generator = create_train_generator(X_train, y_train, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
    "\n",
    "    dice_loss_val = 1 - (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss_val = tf.reduce_mean(dice_loss_val)\n",
    "\n",
    "    lovasz_loss_val = lovasz_softmax_loss(y_true, tf.nn.softmax(y_pred), ignore_background=False)\n",
    "    return lovasz_loss_val + dice_loss_val\n",
    "\n",
    "\n",
    "class HardVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, num_classes):\n",
    "        super(HardVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            logits = model(x, training=training)               # [B, H, W, C]\n",
    "            pred_mask = tf.argmax(logits, axis=-1)             # [B, H, W]\n",
    "            predictions.append(pred_mask)\n",
    "\n",
    "        stacked_preds = tf.stack(predictions, axis=0)          # [N_models, B, H, W]\n",
    "        stacked_preds = tf.transpose(stacked_preds, [1, 2, 3, 0])  # [B, H, W, N_models]\n",
    "\n",
    "        # Use numpy + scipy mode\n",
    "        def compute_mode(x):\n",
    "            mode, _ = stats.mode(x, axis=-1, keepdims=False)\n",
    "            return mode.astype(np.int32)\n",
    "\n",
    "        mode_preds = tf.numpy_function(\n",
    "            func=compute_mode,\n",
    "            inp=[stacked_preds],\n",
    "            Tout=tf.int32\n",
    "        )\n",
    "\n",
    "        # Manually set output shape: [B, H, W]\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        height = tf.shape(x)[1]\n",
    "        width = tf.shape(x)[2]\n",
    "        mode_preds.set_shape([None, None, None])  # Symbolic shape for [B, H, W]\n",
    "\n",
    "        one_hot_preds = tf.one_hot(mode_preds, depth=self.num_classes)  # [B, H, W, C]\n",
    "        return one_hot_preds\n",
    "\n",
    "hard_ensemble = HardVotingEnsemble(\n",
    "    models=[model_xception, model_segnet, model_inceptionresnetv2, model_efficientnetb4],\n",
    "    num_classes=4\n",
    ")\n",
    "\n",
    "hard_ensemble.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "# === Config ===\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "\n",
    "# === Resize Layer ===\n",
    "class ResizeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, target_size, **kwargs):\n",
    "        super(ResizeLayer, self).__init__(**kwargs)\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.image.resize(inputs, self.target_size, method='bilinear')\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'target_size': self.target_size})\n",
    "        return config\n",
    "\n",
    "\n",
    "# === Conv Block ===\n",
    "def conv_block(x, filters, kernel_size=3, strides=1):\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same', strides=strides, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# === MBConv Block ===\n",
    "def mbconv_block(x, in_ch, out_ch, stride=1, expansion=4):\n",
    "    hidden_dim = in_ch * expansion\n",
    "    res = x\n",
    "    x = layers.Conv2D(hidden_dim, 1, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('swish')(x)\n",
    "\n",
    "    x = layers.DepthwiseConv2D(3, strides=stride, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('swish')(x)\n",
    "\n",
    "    x = layers.Conv2D(out_ch, 1, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if stride == 1 and in_ch == out_ch:\n",
    "        x = layers.Add()([res, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "# === MLA Block ===\n",
    "def mla_block(x, channels, stride=1):\n",
    "    residual = x\n",
    "\n",
    "    if stride > 1:\n",
    "        residual = layers.AveragePooling2D(pool_size=stride, strides=stride, padding='same')(residual)\n",
    "        x = layers.AveragePooling2D(pool_size=stride, strides=stride, padding='same')(x)\n",
    "\n",
    "    if x.shape[-1] != channels:\n",
    "        residual = layers.Conv2D(channels, 1, padding='same')(residual)\n",
    "\n",
    "    attn = layers.DepthwiseConv2D(5, padding='same')(x)\n",
    "    attn = layers.Conv2D(channels, 1, padding='same')(attn)\n",
    "    attn = layers.ReLU()(attn)\n",
    "\n",
    "    return layers.Add()([residual, attn])\n",
    "\n",
    "\n",
    "# === EfficientViT Block ===\n",
    "def efficientvit_block(x, in_ch, out_ch, stride=1):\n",
    "    local = mbconv_block(x, in_ch, out_ch, stride=stride)\n",
    "    global_ = mla_block(x, out_ch, stride=stride)\n",
    "    return layers.Add()([local, global_])\n",
    "\n",
    "\n",
    "# EfficientViT-B0 Encoder\n",
    "def efficientvit_b0_encoder(inputs):\n",
    "    x = layers.Conv2D(16, 3, strides=2, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('swish')(x)\n",
    "    e0 = x  # 112x112\n",
    "\n",
    "    x = efficientvit_block(x, 16, 32, stride=2)\n",
    "    e1 = x  # 56x56\n",
    "\n",
    "    x = efficientvit_block(x, 32, 64, stride=2)\n",
    "    e2 = x  # 28x28\n",
    "\n",
    "    x = efficientvit_block(x, 64, 96, stride=2)\n",
    "    e3 = x  # 14x14\n",
    "\n",
    "    x = efficientvit_block(x, 96, 128, stride=2)\n",
    "    e4 = x  # 7x7\n",
    "\n",
    "    return [e0, e1, e2, e3, e4]\n",
    "\n",
    "\n",
    "def attention_gate(x, g, inter_channels):\n",
    "    \"\"\"Standard attention gate block\"\"\"\n",
    "    x_shape = tf.keras.backend.int_shape(x)\n",
    "    g_shape = tf.keras.backend.int_shape(g)\n",
    "\n",
    "    if x_shape[1] != g_shape[1] or x_shape[2] != g_shape[2]:\n",
    "        g = ResizeLayer((x_shape[1], x_shape[2]))(g)\n",
    "\n",
    "    theta_x = layers.Conv2D(inter_channels, 1, padding='same')(x)\n",
    "    phi_g = layers.Conv2D(inter_channels, 1, padding='same')(g)\n",
    "    f = layers.Add()([theta_x, phi_g])\n",
    "    f = layers.Activation('relu')(f)\n",
    "    psi = layers.Conv2D(1, 1, padding='same')(f)\n",
    "    alpha = layers.Activation('sigmoid')(psi)\n",
    "    return layers.Multiply()([x, alpha])\n",
    "\n",
    "\n",
    "def build_attention_unet_with_efficientvit(input_shape=(224, 224, 3), num_classes=4):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # === EfficientViT Encoder ===\n",
    "    encoder_features = efficientvit_b0_encoder(inputs)\n",
    "    e0, e1, e2, e3, e4 = encoder_features  # e0: shallowest, e4: bottleneck\n",
    "\n",
    "    # === Decoder with Attention U-Net style ===\n",
    "    up_filters = [96, 64, 32, 16]\n",
    "    skip_connections = [e3, e2, e1, e0]  # deepest to shallowest\n",
    "    up = e4  # bottleneck\n",
    "\n",
    "    for i in range(4):\n",
    "        up = layers.Conv2DTranspose(up_filters[i], 3, strides=2, padding='same')(up)\n",
    "        up = layers.BatchNormalization()(up)\n",
    "        up = layers.Activation('relu')(up)\n",
    "        up = layers.Dropout(0.2)(up)\n",
    "\n",
    "        skip = skip_connections[i]\n",
    "        att_skip = attention_gate(skip, up, up_filters[i] // 2)\n",
    "\n",
    "        # Resize up to match skip if needed\n",
    "        if tf.keras.backend.int_shape(att_skip)[1:3] != tf.keras.backend.int_shape(up)[1:3]:\n",
    "            up = ResizeLayer((att_skip.shape[1], att_skip.shape[2]))(up)\n",
    "\n",
    "        up = layers.Concatenate()([up, att_skip])\n",
    "        up = conv_block(up, up_filters[i])\n",
    "        up = conv_block(up, up_filters[i])\n",
    "\n",
    "    # Final Upsampling to full resolution\n",
    "    up = layers.Conv2DTranspose(64, 3, strides=2, padding='same')(up)\n",
    "    up = conv_block(up, 64)\n",
    "    up = conv_block(up, 32)\n",
    "\n",
    "    if tf.keras.backend.int_shape(up)[1:3] != (input_shape[0], input_shape[1]):\n",
    "        up = ResizeLayer((input_shape[0], input_shape[1]))(up)\n",
    "\n",
    "    outputs = layers.Conv2D(num_classes, 1, activation='softmax')(up)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "student_model = build_attention_unet_with_efficientvit(\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS),\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "student_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "models = [\n",
    "    model_xception,\n",
    "    model_segnet,\n",
    "    model_inceptionresnetv2,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "class WeightedSoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, weights=None, apply_softmax=True):\n",
    "        super(WeightedSoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        if weights is None:\n",
    "            weights = [1.0 / len(models)] * len(models)\n",
    "        else:\n",
    "            total = sum(weights)\n",
    "            weights = [w / total for w in weights]\n",
    "\n",
    "        self.model_weights = tf.constant(weights, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        weighted_sum = 0\n",
    "        for i, model in enumerate(self.models):\n",
    "            output = model(x, training=training)\n",
    "\n",
    "            is_softmaxed = (\n",
    "                hasattr(model, \"name\") and \"efficientnet\" in model.name.lower()\n",
    "            )\n",
    "\n",
    "            if self.apply_softmax and not is_softmaxed:\n",
    "                probs = tf.nn.softmax(output, axis=-1)\n",
    "            else:\n",
    "                probs = output\n",
    "\n",
    "            weighted_sum += self.model_weights[i] * probs\n",
    "\n",
    "        avg_prob = weighted_sum  # shape: [B, H, W, C]\n",
    "\n",
    "        # ðŸ” Convert to one-hot for metric compatibility\n",
    "        one_hot_pred = tf.one_hot(tf.argmax(avg_prob, axis=-1), depth=avg_prob.shape[-1])\n",
    "        return one_hot_pred  # [B, H, W, C]\n",
    "\n",
    "final_weights = [0.255, 0.2427, 0.2515, 0.2508]\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "teacher_model = ensemble_model \n",
    "\n",
    "def distillation_loss(y_true, y_student_logits, y_teacher_probs, alpha=0.5, temperature=3.0):\n",
    "    # Softened predictions for KL\n",
    "    student_soft = tf.nn.softmax(y_student_logits / temperature)\n",
    "    teacher_soft = tf.nn.softmax(y_teacher_probs / temperature)\n",
    "\n",
    "    # Soft loss: KL divergence\n",
    "    kl_loss = tf.keras.losses.KLDivergence()(teacher_soft, student_soft)\n",
    "\n",
    "    # Hard loss: Use your custom combined loss (Dice + Lovasz)\n",
    "    ce_loss = combined_loss(y_true, y_student_logits)\n",
    "\n",
    "    # Combine them\n",
    "    return alpha * ce_loss + (1 - alpha) * (temperature ** 2) * kl_loss\n",
    "\n",
    "# === KD Wrapper Model ===\n",
    "class KDTrainer(tf.keras.Model):\n",
    "    def __init__(self, student, teacher, alpha=0.5, temperature=3.0):\n",
    "        super(KDTrainer, self).__init__()\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def compile(self, optimizer, metrics):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.metrics_list = metrics\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y_true = data\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_logits = self.student(x, training=True)               # [B, H, W, C]\n",
    "            teacher_probs = self.teacher(x, training=False)               # Soft probs\n",
    "\n",
    "            loss = distillation_loss(\n",
    "                y_true, student_logits, teacher_probs,\n",
    "                alpha=self.alpha, temperature=self.temperature\n",
    "            )\n",
    "\n",
    "        grads = tape.gradient(loss, self.student.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.student.trainable_variables))\n",
    "\n",
    "        for metric in self.metrics_list:\n",
    "            metric.update_state(y_true, student_logits)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics_list} | {\"loss\": loss}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y_true = data\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = self.student(x, training=False)\n",
    "        loss = combined_loss(y_true, y_pred)\n",
    "\n",
    "        for metric in self.metrics_list:\n",
    "            metric.update_state(y_true, y_pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics_list} | {\"loss\": loss}\n",
    "\n",
    "# === Instantiate KDTrainer ===\n",
    "kd_model = KDTrainer(\n",
    "    student=student_model,\n",
    "    teacher=teacher_model,\n",
    "    alpha=0.5,\n",
    "    temperature=3.0\n",
    ")\n",
    "\n",
    "# === Compile ===\n",
    "kd_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "checkpoint_path = f\"best_student_unetplusplus_{timestamp}\"\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6\n",
    "    ), \n",
    "    ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    save_format='tf'  # âœ… use TF SavedModel format\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_train_generator(X, y, batch_size=16):\n",
    "    data_gen_args = dict(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    seed = 42\n",
    "    image_generator = image_datagen.flow(X, batch_size=batch_size, seed=seed)\n",
    "    mask_generator = mask_datagen.flow(y, batch_size=batch_size, seed=seed)\n",
    "\n",
    "    while True:\n",
    "        X_batch = next(image_generator)\n",
    "        y_batch = next(mask_generator)\n",
    "        yield X_batch.astype('float32'), y_batch.astype('float32')\n",
    "\n",
    "batch_size = 16\n",
    "train_generator = create_train_generator(X_train, y_train, batch_size=batch_size)\n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "\n",
    "\n",
    "history = kd_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# === Your ensemble setup ===\n",
    "models = [\n",
    "    model_xception,\n",
    "    model_segnet,\n",
    "    model_inceptionresnetv2,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "class WeightedSoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, weights=None, apply_softmax=True):\n",
    "        super(WeightedSoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        if weights is None:\n",
    "            weights = [1.0 / len(models)] * len(models)\n",
    "        else:\n",
    "            total = sum(weights)\n",
    "            weights = [w / total for w in weights]\n",
    "\n",
    "        self.model_weights = tf.constant(weights, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        weighted_sum = 0\n",
    "        for i, model in enumerate(self.models):\n",
    "            output = model(x, training=training)\n",
    "\n",
    "            is_softmaxed = (\n",
    "                hasattr(model, \"name\") and \"efficientnet\" in model.name.lower()\n",
    "            )\n",
    "\n",
    "            if self.apply_softmax and not is_softmaxed:\n",
    "                probs = tf.nn.softmax(output, axis=-1)\n",
    "            else:\n",
    "                probs = output\n",
    "\n",
    "            weighted_sum += self.model_weights[i] * probs\n",
    "\n",
    "        avg_prob = weighted_sum\n",
    "        one_hot_pred = tf.one_hot(tf.argmax(avg_prob, axis=-1), depth=avg_prob.shape[-1])\n",
    "        return one_hot_pred  # âš ï¸ returns one-hot\n",
    "\n",
    "final_weights = [0.255, 0.2427, 0.2515, 0.2508]\n",
    "ensemble_model = WeightedSoftVotingEnsemble(models=models, weights=final_weights, apply_softmax=True)\n",
    "\n",
    "# === SOFT OUTPUT EXTRACTOR (helper workaround) ===\n",
    "def get_teacher_soft_output(ensemble_model, x):\n",
    "    weighted_sum = 0\n",
    "    for i, model in enumerate(ensemble_model.models):\n",
    "        output = model(x, training=False)\n",
    "\n",
    "        is_softmaxed = (\n",
    "            hasattr(model, \"name\") and \"efficientnet\" in model.name.lower()\n",
    "        )\n",
    "\n",
    "        if ensemble_model.apply_softmax and not is_softmaxed:\n",
    "            probs = tf.nn.softmax(output, axis=-1)\n",
    "        else:\n",
    "            probs = output\n",
    "\n",
    "        weighted_sum += ensemble_model.model_weights[i] * probs\n",
    "\n",
    "    return weighted_sum  # soft probabilities\n",
    "\n",
    "# === Distillation Loss ===\n",
    "def distillation_loss(y_true, y_student_logits, y_teacher_probs, alpha=0.2, temperature=5.0):\n",
    "    student_soft = tf.nn.softmax(y_student_logits / temperature)\n",
    "    teacher_soft = tf.nn.softmax(y_teacher_probs / temperature)\n",
    "\n",
    "    kl_loss = tf.keras.losses.KLDivergence()(teacher_soft, student_soft)\n",
    "\n",
    "    # Option 1: Combined loss on hard labels\n",
    "    ce_loss = combined_loss(y_true, tf.nn.softmax(y_student_logits))\n",
    "    \n",
    "    # Option 2: Standard CE (more stable for KD) â€” you can switch if needed\n",
    "    # ce_loss = tf.keras.losses.CategoricalCrossentropy()(y_true, tf.nn.softmax(y_student_logits))\n",
    "\n",
    "    return alpha * ce_loss + (1 - alpha) * (temperature ** 2) * kl_loss\n",
    "\n",
    "# === KD Wrapper ===\n",
    "class KDTrainer(tf.keras.Model):\n",
    "    def __init__(self, student, teacher, alpha=0.2, temperature=5.0):\n",
    "        super(KDTrainer, self).__init__()\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def compile(self, optimizer, metrics):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.metrics_list = metrics\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y_true = data\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_logits = self.student(x, training=True)\n",
    "            teacher_probs = get_teacher_soft_output(self.teacher, x)  # âœ… SOFT OUTPUT FIX\n",
    "\n",
    "            loss = distillation_loss(\n",
    "                y_true, student_logits, teacher_probs,\n",
    "                alpha=self.alpha, temperature=self.temperature\n",
    "            )\n",
    "\n",
    "        grads = tape.gradient(loss, self.student.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.student.trainable_variables))\n",
    "\n",
    "        student_soft = tf.nn.softmax(student_logits)\n",
    "        for metric in self.metrics_list:\n",
    "            metric.update_state(y_true, student_soft)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics_list} | {\"loss\": loss}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y_true = data\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        student_logits = self.student(x, training=False)\n",
    "        student_soft = tf.nn.softmax(student_logits)\n",
    "        loss = combined_loss(y_true, student_soft)\n",
    "\n",
    "        for metric in self.metrics_list:\n",
    "            metric.update_state(y_true, student_soft)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics_list} | {\"loss\": loss}\n",
    "\n",
    "# === Compile KD Model ===\n",
    "kd_model = KDTrainer(\n",
    "    student=student_model,\n",
    "    teacher=ensemble_model,\n",
    "    alpha=0.2,\n",
    "    temperature=5.0\n",
    ")\n",
    "\n",
    "kd_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "# === Callbacks ===\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "checkpoint_path = f\"best_student_unetplusplus_{timestamp}\"\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6),\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', save_best_only=True,\n",
    "                    save_weights_only=True, save_format='tf')\n",
    "]\n",
    "\n",
    "# === Data Generator ===\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_train_generator(X, y, batch_size=16):\n",
    "    data_gen_args = dict(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    image_gen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_gen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    seed = 42\n",
    "    image_generator = image_gen.flow(X, batch_size=batch_size, seed=seed)\n",
    "    mask_generator = mask_gen.flow(y, batch_size=batch_size, seed=seed)\n",
    "\n",
    "    while True:\n",
    "        X_batch = next(image_generator)\n",
    "        y_batch = next(mask_generator)\n",
    "        yield X_batch.astype('float32'), y_batch.astype('float32')\n",
    "\n",
    "# === Train ===\n",
    "batch_size = 16\n",
    "train_generator = create_train_generator(X_train, y_train, batch_size=batch_size)\n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "\n",
    "history = kd_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "models = [\n",
    "    model_xception,\n",
    "    model_segnet,\n",
    "    model_inceptionresnetv2,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "class WeightedSoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, weights=None, apply_softmax=True):\n",
    "        super(WeightedSoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        if weights is None:\n",
    "            weights = [1.0 / len(models)] * len(models)\n",
    "        else:\n",
    "            total = sum(weights)\n",
    "            weights = [w / total for w in weights]\n",
    "\n",
    "        self.model_weights = tf.constant(weights, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        weighted_sum = 0\n",
    "        for i, model in enumerate(self.models):\n",
    "            output = model(x, training=training)\n",
    "\n",
    "            is_softmaxed = (\n",
    "                hasattr(model, \"name\") and \"efficientnet\" in model.name.lower()\n",
    "            )\n",
    "\n",
    "            if self.apply_softmax and not is_softmaxed:\n",
    "                probs = tf.nn.softmax(output, axis=-1)\n",
    "            else:\n",
    "                probs = output\n",
    "\n",
    "            weighted_sum += self.model_weights[i] * probs\n",
    "\n",
    "        avg_prob = weighted_sum  # shape: [B, H, W, C]\n",
    "\n",
    "        # ðŸ” Convert to one-hot for metric compatibility\n",
    "        one_hot_pred = tf.one_hot(tf.argmax(avg_prob, axis=-1), depth=avg_prob.shape[-1])\n",
    "        return one_hot_pred  # [B, H, W, C]\n",
    "\n",
    "final_weights = [0.255, 0.2427, 0.2515, 0.2508]\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "teacher_model = ensemble_model \n",
    "\n",
    "def distillation_loss(y_true, y_student_logits, y_teacher_probs, alpha=0.5, temperature=3.0):\n",
    "    # Softened predictions for KL\n",
    "    student_soft = tf.nn.softmax(y_student_logits / temperature)\n",
    "    teacher_soft = tf.nn.softmax(y_teacher_probs / temperature)\n",
    "\n",
    "    # Soft loss: KL divergence\n",
    "    kl_loss = tf.keras.losses.KLDivergence()(teacher_soft, student_soft)\n",
    "\n",
    "    # Hard loss: Use your custom combined loss (Dice + Lovasz)\n",
    "    ce_loss = combined_loss(y_true, y_student_logits) + tf.keras.losses.CategoricalCrossentropy()(y_true, y_student_logits)\n",
    "\n",
    "    # Combine them\n",
    "    return alpha * ce_loss + (1 - alpha) * (temperature ** 2) * kl_loss\n",
    "\n",
    "# === KD Wrapper Model ===\n",
    "class KDTrainer(tf.keras.Model):\n",
    "    def __init__(self, student, teacher, alpha=0.5, temperature=3.0):\n",
    "        super(KDTrainer, self).__init__()\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def compile(self, optimizer, metrics):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.metrics_list = metrics\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y_true = data\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_logits = self.student(x, training=True)               # [B, H, W, C]\n",
    "            teacher_probs = self.teacher(x, training=False)               # Soft probs\n",
    "\n",
    "            loss = distillation_loss(\n",
    "                y_true, student_logits, teacher_probs,\n",
    "                alpha=self.alpha, temperature=self.temperature\n",
    "            )\n",
    "\n",
    "        grads = tape.gradient(loss, self.student.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.student.trainable_variables))\n",
    "\n",
    "        for metric in self.metrics_list:\n",
    "            metric.update_state(y_true, student_logits)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics_list} | {\"loss\": loss}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y_true = data\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = self.student(x, training=False)\n",
    "        loss = combined_loss(y_true, y_pred)\n",
    "\n",
    "        for metric in self.metrics_list:\n",
    "            metric.update_state(y_true, y_pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics_list} | {\"loss\": loss}\n",
    "\n",
    "# === Instantiate KDTrainer ===\n",
    "kd_model = KDTrainer(\n",
    "    student=student_model,\n",
    "    teacher=teacher_model,\n",
    "    alpha=0.5,\n",
    "    temperature=3.0\n",
    ")\n",
    "\n",
    "# === Compile ===\n",
    "kd_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "checkpoint_path = f\"best_student_unetplusplus_{timestamp}\"\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6\n",
    "    ), \n",
    "    ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    save_format='tf'  # âœ… use TF SavedModel format\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_train_generator(X, y, batch_size=16):\n",
    "    data_gen_args = dict(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    seed = 42\n",
    "    image_generator = image_datagen.flow(X, batch_size=batch_size, seed=seed)\n",
    "    mask_generator = mask_datagen.flow(y, batch_size=batch_size, seed=seed)\n",
    "\n",
    "    while True:\n",
    "        X_batch = next(image_generator)\n",
    "        y_batch = next(mask_generator)\n",
    "        yield X_batch.astype('float32'), y_batch.astype('float32')\n",
    "\n",
    "batch_size = 16\n",
    "train_generator = create_train_generator(X_train, y_train, batch_size=batch_size)\n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "\n",
    "\n",
    "# history = kd_model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     epochs=100,\n",
    "#     callbacks=callbacks\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "    temperature = trial.suggest_categorical(\"temperature\", [1, 3, 5, 10])\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"Nadam\", \"SGD\"])\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.1, 0.9, step=0.2)\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
    "\n",
    "    if optimizer_name == \"Adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer_name == \"RMSprop\":\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    elif optimizer_name == \"SGD\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer_name == \"Nadam\":\n",
    "        optimizer = tf.keras.optimizers.Nadam(learning_rate=lr)\n",
    "\n",
    "    \n",
    "    student_copy = tf.keras.models.clone_model(student_model)\n",
    "\n",
    "    kd_model = KDTrainer(\n",
    "        student=student_copy,\n",
    "        teacher=teacher_model,\n",
    "        alpha=alpha,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    kd_model.compile(\n",
    "        optimizer=optimizer,\n",
    "        metrics=class_wise_metrics(num_classes=4)\n",
    "    )\n",
    "\n",
    "    train_gen = create_train_generator(X_train, y_train, batch_size=batch_size)\n",
    "    val_data = (X_val, y_val)\n",
    "\n",
    "    try:\n",
    "        history = kd_model.fit(\n",
    "            train_gen,\n",
    "            steps_per_epoch=len(X_train) // batch_size,\n",
    "            validation_data=val_data,\n",
    "            epochs=5,\n",
    "            verbose=0\n",
    "        )\n",
    "    except tf.errors.ResourceExhaustedError:\n",
    "        print(f\"OOM at batch_size={batch_size}\")\n",
    "        tf.keras.backend.clear_session()\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return history.history['val_loss'][-1]\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=48)  # or 48 for full grid coverage\n",
    "print(\"Best params:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "models = [\n",
    "    model_xception,\n",
    "    model_segnet,\n",
    "    model_inceptionresnetv2,\n",
    "    model_efficientnetb4\n",
    "]\n",
    "\n",
    "class WeightedSoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, weights=None, apply_softmax=True):\n",
    "        super(WeightedSoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        if weights is None:\n",
    "            weights = [1.0 / len(models)] * len(models)\n",
    "        else:\n",
    "            total = sum(weights)\n",
    "            weights = [w / total for w in weights]\n",
    "\n",
    "        self.model_weights = tf.constant(weights, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        weighted_sum = 0\n",
    "        for i, model in enumerate(self.models):\n",
    "            output = model(x, training=training)\n",
    "\n",
    "            is_softmaxed = (\n",
    "                hasattr(model, \"name\") and \"efficientnet\" in model.name.lower()\n",
    "            )\n",
    "\n",
    "            if self.apply_softmax and not is_softmaxed:\n",
    "                probs = tf.nn.softmax(output, axis=-1)\n",
    "            else:\n",
    "                probs = output\n",
    "\n",
    "            weighted_sum += self.model_weights[i] * probs\n",
    "\n",
    "        avg_prob = weighted_sum  # shape: [B, H, W, C]\n",
    "\n",
    "        # ðŸ” Convert to one-hot for metric compatibility\n",
    "        one_hot_pred = tf.one_hot(tf.argmax(avg_prob, axis=-1), depth=avg_prob.shape[-1])\n",
    "        return one_hot_pred  # [B, H, W, C]\n",
    "\n",
    "final_weights = [0.255, 0.2427, 0.2515, 0.2508]\n",
    "ensemble_model = WeightedSoftVotingEnsemble(\n",
    "    models=models,\n",
    "    weights=final_weights,\n",
    "    apply_softmax=True\n",
    ")\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "teacher_model = ensemble_model \n",
    "\n",
    "def distillation_loss(y_true, y_student_logits, y_teacher_probs, alpha=0.5, temperature=3.0):\n",
    "    # Softened predictions for KL\n",
    "    student_soft = tf.nn.softmax(y_student_logits / temperature)\n",
    "    teacher_soft = tf.nn.softmax(y_teacher_probs / temperature)\n",
    "\n",
    "    # Soft loss: KL divergence\n",
    "    kl_loss = tf.keras.losses.KLDivergence()(teacher_soft, student_soft)\n",
    "\n",
    "    # Hard loss: Use your custom combined loss (Dice + Lovasz)\n",
    "    ce_loss = combined_loss(y_true, y_student_logits) + tf.keras.losses.CategoricalCrossentropy()(y_true, y_student_logits)\n",
    "\n",
    "    # Combine them\n",
    "    return alpha * ce_loss + (1 - alpha) * (temperature ** 2) * kl_loss\n",
    "\n",
    "# === KD Wrapper Model ===\n",
    "class KDTrainer(tf.keras.Model):\n",
    "    def __init__(self, student, teacher, alpha=0.5, temperature=3.0):\n",
    "        super(KDTrainer, self).__init__()\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def compile(self, optimizer, metrics):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.metrics_list = metrics\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y_true = data\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_logits = self.student(x, training=True)               # [B, H, W, C]\n",
    "            teacher_probs = self.teacher(x, training=False)               # Soft probs\n",
    "\n",
    "            loss = distillation_loss(\n",
    "                y_true, student_logits, teacher_probs,\n",
    "                alpha=self.alpha, temperature=self.temperature\n",
    "            )\n",
    "\n",
    "        grads = tape.gradient(loss, self.student.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.student.trainable_variables))\n",
    "\n",
    "        for metric in self.metrics_list:\n",
    "            metric.update_state(y_true, student_logits)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics_list} | {\"loss\": loss}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y_true = data\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = self.student(x, training=False)\n",
    "        loss = combined_loss(y_true, y_pred)\n",
    "\n",
    "        for metric in self.metrics_list:\n",
    "            metric.update_state(y_true, y_pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics_list} | {\"loss\": loss}\n",
    "\n",
    "# === Instantiate KDTrainer ===\n",
    "kd_model = KDTrainer(\n",
    "    student=student_model,\n",
    "    teacher=teacher_model,\n",
    "    alpha=0.5,\n",
    "    temperature=3.0\n",
    ")\n",
    "\n",
    "# === Compile ===\n",
    "kd_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "checkpoint_path = f\"best_student_unetplusplus_{timestamp}\"\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6\n",
    "    ), \n",
    "    ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    save_format='tf'  # âœ… use TF SavedModel format\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_train_generator(X, y, batch_size=16):\n",
    "    data_gen_args = dict(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    seed = 42\n",
    "    image_generator = image_datagen.flow(X, batch_size=batch_size, seed=seed)\n",
    "    mask_generator = mask_datagen.flow(y, batch_size=batch_size, seed=seed)\n",
    "\n",
    "    while True:\n",
    "        X_batch = next(image_generator)\n",
    "        y_batch = next(mask_generator)\n",
    "        yield X_batch.astype('float32'), y_batch.astype('float32')\n",
    "\n",
    "batch_size = 16\n",
    "train_generator = create_train_generator(X_train, y_train, batch_size=batch_size)\n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "\n",
    "\n",
    "history = kd_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extracting data from the history object\n",
    "history_dict = history.history\n",
    "\n",
    "# Plotting the training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plotting loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_dict['loss'], label='Training Loss')\n",
    "plt.plot(history_dict['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# If accuracy is available, plot training and validation accuracy\n",
    "if 'accuracy' in history_dict:\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_dict['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history_dict['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Curves')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# âœ… RGB to Class Index Conversion (for the test masks)\n",
    "RGB_TO_CLASS = {\n",
    "    (255, 0, 0): 1,  # Brain\n",
    "    (0, 255, 0): 2,  # CSP\n",
    "    (0, 0, 255): 3,  # LV\n",
    "    (0, 0, 0): 0     # Background\n",
    "}\n",
    "\n",
    "# âœ… Function to convert RGB masks to class index masks\n",
    "def rgb_to_class_mask(rgb_mask):\n",
    "    # Create a mask initialized with zeros (for background class)\n",
    "    class_mask = np.zeros(rgb_mask.shape[:2], dtype=int)\n",
    "\n",
    "    # Loop through the RGB_TO_CLASS dictionary\n",
    "    for rgb, class_idx in RGB_TO_CLASS.items():\n",
    "        # Identify the pixels with the current RGB value and assign them the class index\n",
    "        match_mask = np.all(rgb_mask == np.array(rgb), axis=-1)\n",
    "        class_mask[match_mask] = class_idx\n",
    "\n",
    "    return class_mask\n",
    "\n",
    "# âœ… Function to calculate Dice Similarity Coefficient (DSC)\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-15\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# âœ… Function to calculate IoU (Intersection over Union)\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-15)\n",
    "\n",
    "# âœ… Function to calculate Hausdorff Distance\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')  # Return inf if no points for either true or pred class\n",
    "\n",
    "    forward_hausdorff = directed_hausdorff(true_points, pred_points)[0]\n",
    "    reverse_hausdorff = directed_hausdorff(pred_points, true_points)[0]\n",
    "    return max(forward_hausdorff, reverse_hausdorff)\n",
    "\n",
    "# âœ… Function to calculate Average Surface Distance (ASD)\n",
    "def average_surface_distance(y_true, y_pred):\n",
    "    true_points = np.array(np.where(y_true == 1)).T\n",
    "    pred_points = np.array(np.where(y_pred == 1)).T\n",
    "\n",
    "    if len(true_points) == 0 or len(pred_points) == 0:\n",
    "        return float('inf')  # Return inf if no points for either true or pred class\n",
    "\n",
    "    distances = []\n",
    "    for true_point in true_points:\n",
    "        distances.append(np.min(np.linalg.norm(pred_points - true_point, axis=1)))\n",
    "    return np.mean(distances)\n",
    "\n",
    "# âœ… Function to evaluate the model on the test set class-wise\n",
    "def evaluate_classwise_metrics(model, X_test, y_test, num_classes=4, batch_size=16):\n",
    "    # Predict in batches\n",
    "    y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)  # Convert to class index prediction\n",
    "\n",
    "    # Convert y_test to class index format (since it's one-hot encoded)\n",
    "    y_test_class = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    # Initialize lists to store class-wise metrics\n",
    "    class_metrics = {i: {'dice': [], 'iou': [], 'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'hausdorff': [], 'asd': []} for i in range(num_classes)}\n",
    "\n",
    "    # Calculate metrics for each test sample\n",
    "    for i in range(len(X_test)):\n",
    "        true_mask = y_test_class[i]  # one-hot -> class index\n",
    "        pred_mask = y_pred[i]\n",
    "\n",
    "        # For each class (0: Background, 1: Brain, 2: CSP, 3: LV)\n",
    "        for class_idx in range(num_classes):\n",
    "            true_class_mask = (true_mask == class_idx).astype(int)\n",
    "            pred_class_mask = (pred_mask == class_idx).astype(int)\n",
    "\n",
    "            # Dice Coefficient\n",
    "            class_metrics[class_idx]['dice'].append(dice_coefficient(true_class_mask, pred_class_mask))\n",
    "            # IoU\n",
    "            class_metrics[class_idx]['iou'].append(iou(true_class_mask, pred_class_mask))\n",
    "            # Precision\n",
    "            class_metrics[class_idx]['precision'].append(precision_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # Recall\n",
    "            class_metrics[class_idx]['recall'].append(recall_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # F1 Score\n",
    "            class_metrics[class_idx]['f1'].append(f1_score(true_class_mask.flatten(), pred_class_mask.flatten(), zero_division=0))\n",
    "            # Accuracy\n",
    "            class_metrics[class_idx]['accuracy'].append(accuracy_score(true_class_mask.flatten(), pred_class_mask.flatten()))\n",
    "            # # Hausdorff Distance\n",
    "            # class_metrics[class_idx]['hausdorff'].append(hausdorff_distance(true_class_mask, pred_class_mask))\n",
    "            # # Average Surface Distance\n",
    "            # class_metrics[class_idx]['asd'].append(average_surface_distance(true_class_mask, pred_class_mask))\n",
    "\n",
    "    # Print class-wise metrics in percentage\n",
    "    print(f\"{'Class':<10}{'Dice Coefficient (%)':<20}{'IoU (%)':<20}{'Precision (%)':<20}{'Recall (%)':<20}{'F1 Score (%)':<20}{'Accuracy (%)':<20}{'Hausdorff Distance':<20}{'Avg Surface Distance':<20}\")\n",
    "    print('-' * 180)\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        print(f\"Class {class_idx}:\")\n",
    "        print(f\"  Dice Coefficient: {np.mean(class_metrics[class_idx]['dice']) * 100:.2f}%\")\n",
    "        print(f\"  IoU: {np.mean(class_metrics[class_idx]['iou']) * 100:.2f}%\")\n",
    "        print(f\"  Precision: {np.mean(class_metrics[class_idx]['precision']) * 100:.2f}%\")\n",
    "        print(f\"  Recall: {np.mean(class_metrics[class_idx]['recall']) * 100:.2f}%\")\n",
    "        print(f\"  F1 Score: {np.mean(class_metrics[class_idx]['f1']) * 100:.2f}%\")\n",
    "        print(f\"  Accuracy: {np.mean(class_metrics[class_idx]['accuracy']) * 100:.2f}%\")\n",
    "        # print(f\"  Hausdorff Distance: {np.mean(class_metrics[class_idx]['hausdorff']):.4f}\")\n",
    "        # print(f\"  Average Surface Distance: {np.mean(class_metrics[class_idx]['asd']):.4f}\")\n",
    "        print(\"-\" * 180)\n",
    "\n",
    "    # Evaluate on test set to print overall test accuracy and loss\n",
    "    test_loss, *test_metrics = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    for metric, value in zip(model.metrics_names[1:], test_metrics):\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# âœ… Call the evaluation function on the test set class-wise\n",
    "evaluate_classwise_metrics(kd_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSoftVotingEnsemble(tf.keras.Model):\n",
    "    def __init__(self, models, weights=None, apply_softmax=True):\n",
    "        super(WeightedSoftVotingEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        if weights is None:\n",
    "            weights = [1.0 / len(models)] * len(models)\n",
    "        else:\n",
    "            total = sum(weights)\n",
    "            weights = [w / total for w in weights]\n",
    "\n",
    "        self.model_weights = tf.constant(weights, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        weighted_sum = 0\n",
    "        for i, model in enumerate(self.models):\n",
    "            output = model(x, training=training)\n",
    "\n",
    "            is_softmaxed = (\n",
    "                hasattr(model, \"name\") and \"efficientnet\" in model.name.lower()\n",
    "            )\n",
    "\n",
    "            if self.apply_softmax and not is_softmaxed:\n",
    "                probs = tf.nn.softmax(output, axis=-1)\n",
    "            else:\n",
    "                probs = output\n",
    "\n",
    "            weighted_sum += self.model_weights[i] * probs\n",
    "\n",
    "        avg_prob = weighted_sum\n",
    "        one_hot_pred = tf.one_hot(tf.argmax(avg_prob, axis=-1), depth=avg_prob.shape[-1])\n",
    "        return one_hot_pred \n",
    "\n",
    "final_weights = [0.255, 0.2427, 0.2515, 0.2508]\n",
    "ensemble_model = WeightedSoftVotingEnsemble(models=models, weights=final_weights, apply_softmax=True)\n",
    "\n",
    "ensemble_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=class_wise_metrics(num_classes=4)\n",
    ")\n",
    "\n",
    "ensemble_model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists(\"best_student_unetplusplus_distilled.weights.h5\"):\n",
    "    os.remove(\"best_student_unetplusplus_distilled.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6804412,
     "sourceId": 10941215,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
